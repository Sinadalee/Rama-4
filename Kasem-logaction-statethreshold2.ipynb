{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "junction_id = {'KLONGTEI': 'cluster_1892287670_272491964_272492178',\n",
    "      'RAMA4': 'cluster_272488163_282390730_66263210_66263222',\n",
    "      'NARANONG': 'cluster_272488164_272492179_3457051443_61907354',\n",
    "      'SUNLAKAKHON': 'gneJ83',\n",
    "      'KASEMRAT': 'cluster_272448137_272555800_272555808_7660045934_7710268409',\n",
    "      'ATTHAKAWI_RAMA4' : '270329335'}\n",
    "junction_name = list(junction_id.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gym\n",
    "# from gym import error, spaces\n",
    "import gym\n",
    "import lxml.etree as ET\n",
    "import csv\n",
    "import json\n",
    "import os, sys\n",
    "os.environ['SUMO_HOME']='/usr/share/sumo'\n",
    "tools = os.path.join(os.environ['SUMO_HOME'],'tools')\n",
    "sys.path.append(tools)\n",
    "import traci\n",
    "import traci.constants as tc\n",
    "import numpy as np\n",
    "from sumolib import checkBinary\n",
    "import datetime\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import copy\n",
    "import random\n",
    "import pandas as pd\n",
    "from multiprocessing.pool import ThreadPool\n",
    "from itertools import zip_longest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "namelane_csv = pd.read_csv('namelane_KASEMRAT.csv')\n",
    "namelane_df = pd.DataFrame(namelane_csv, columns = ['name' , 'id'])\n",
    "NAME = namelane_df.set_index('name')\n",
    "ID = namelane_df.set_index('id')\n",
    "if NAME.loc['KASEMRAT_EB_0_0_XSXX','id'] == '459551209#3_0':\n",
    "    print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name\n",
       "KASEMRAT_EB_0_0_XSXX                      459551209#3_0\n",
       "KASEMRAT_EB_0_1_XSXX                      459551209#3_1\n",
       "KASEMRAT_EB_0_2_XSXX                      459551209#3_2\n",
       "KASEMRAT_EB_0_3_XSRT                      459551209#3_3\n",
       "KASEMRAT_EB_1_0_LSXX                      459551209#0_0\n",
       "                                              ...      \n",
       "MASUKGRIDLOCK_ATTHAKAWI_SB_2_1_LXXX        27702347#6_1\n",
       "MASUKGRIDLOCK_ATTHAKAWI_SB_1_0_LSXT        27702347#4_0\n",
       "MASUKGRIDLOCK_ATTHAKAWI_SB_2_0_LXXX        27702347#6_0\n",
       "MASUKGRIDLOCK_SUKHUMVUT22_SB_0_0_XSXX    -453669106#1_0\n",
       "MASUKGRIDLOCK_SUKHUMVUT24_SB_0_0_XSXX     328942767#2_0\n",
       "Name: id, Length: 425, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NAME.loc[:,'id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RAMA4_WB_2_3_XSXX'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ID.loc['820373198#0_3', 'name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "namedetector_csv = pd.read_csv('namedetector_KASEMRAT_flow.csv')\n",
    "namedetector_df = pd.DataFrame(namedetector_csv, columns = ['name' , 'id'])\n",
    "NAME_D = namedetector_df.set_index('name')\n",
    "ID_D = namedetector_df.set_index('id')\n",
    "listdetector = open(\"namedetector_KASEMRAT_flow.txt\", \"r\")\n",
    "detector = {}\n",
    "for l in listdetector:\n",
    "    l = l.strip().split(' ')\n",
    "    if len(l)> 1:\n",
    "        d = []\n",
    "        for detec in l[2:]:\n",
    "            if type(NAME_D.loc[detec,'id']) == str:\n",
    "                d.append(NAME_D.loc[detec,'id'])\n",
    "            else : d.append(NAME_D.loc[detec,'id'][0])\n",
    "    if str(l[0])!= '':\n",
    "        detector[str(l[0])] = d\n",
    "list_detector= list(detector.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RAMA4_EB_1_4_XSXX</th>\n",
       "      <td>D459492917#0_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KLONGTEI_EB_0_0_XSXX</th>\n",
       "      <td>D825786400_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KLONGTEI_EB_0_1_XSXX</th>\n",
       "      <td>D825786400_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KLONGTEI_EB_0_2_XSXX</th>\n",
       "      <td>D825786400_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KLONGTEI_EB_0_3_XSXX</th>\n",
       "      <td>D825786400_3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  id\n",
       "name                                \n",
       "RAMA4_EB_1_4_XSXX     D459492917#0_4\n",
       "KLONGTEI_EB_0_0_XSXX    D825786400_0\n",
       "KLONGTEI_EB_0_1_XSXX    D825786400_1\n",
       "KLONGTEI_EB_0_2_XSXX    D825786400_2\n",
       "KLONGTEI_EB_0_3_XSXX    D825786400_3"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NAME_D.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(NAME_D.loc['KLONGTEI_EB_0_0_XSXX','id'])\n",
    "# for i in range(len(list(detector.keys()))):\n",
    "#     print(i , list(detector.keys())[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hot_encoding_current_phase():\n",
    "    number_phase = [4,9,7,5,4,3]\n",
    "    current_phase = [traci.trafficlight.getPhase(junction_id[key]) for key in junction_id.keys()]\n",
    "#     current_phase = [0,2,1,1,1,1]\n",
    "    hot_encoding_current_phase = np.array([])\n",
    "    for i in range(len(current_phase)):\n",
    "        binary_phase = np.zeros(number_phase[i])\n",
    "        binary_phase[current_phase[i]] = 1\n",
    "        hot_encoding_current_phase = np.concatenate((hot_encoding_current_phase, binary_phase), axis=None)\n",
    "    return current_phase, hot_encoding_current_phase\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ID.loc['']#, '820373198#0', '820373196#0', '482209831#0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAP_JUNCTIONNAME = dict \n",
    "# \tkey = current phase\n",
    "# \tvalue = list compose of\n",
    "# \t\t1. name of detector at a particular critical spot that traffic police pay attention to\n",
    "# \t\t\t(detector at that phase (check to end phase) + detector at priority phase(change to priority phase))\n",
    "# \t\t2. threshold or -threshold of that spot:\n",
    "# \t\t\t occupancy = get_occupancy_average_percent(detector_name)\n",
    "# \t\t\tthreshold#1 -threshold\n",
    "# \t\t\t\tif -threshold  <= 0:\n",
    "#                 \t\t\t\t\tif occupancy >= (-1)* -threshold :\n",
    "#                     \t\t\t\t\tIndex_detector = list_detector.index(detector_name) \n",
    "#                     \t\t\t\t\tstate_attention[Index_detector] = 1\n",
    "#           threshold#2 threshold\n",
    "# \t\t\t\telif occupancy <= threshold :\n",
    "#                 \t\t\t\t\tIndex_detector = list_detector.index(detector_name) \n",
    "#                 \t\t\t\t\tstate_attention[Index_detector] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_state_attention(current_phase, hot_encoding_current_phase):\n",
    "#     current_phase = [KLONGTEI phase, RAMA4 phase,NARANONG phase, SUNLAKAKHON phase, KASEMRAT phase, ATTHAKAWI_RAMA4 phase]\n",
    "    MAP_RAMA4 = {0: [['RAMA4_EB_FPX_TP1',-50] , ['KASEMRAT_EB_FPX_TP2_RAMA4',-20], ['NARANONG_SW_FPX_TP1',-20]],\n",
    "                 1: [['RAMA4_EB_FP1_TP3',10], ['RAMA4_NB_FPX_TP5',-83]],\n",
    "                 2: [['RAMA4_WB_FP2_TP4',10], ['RAMA4_EB_FPX_TP1',-50], ['RAMA4_NB_FPX_TP5',-83]],\n",
    "                3: [['RAMA4_EB_FP3_TP2',40], ['RAMA4_WB_FP3_TP2',8.8], ['RAMA4_EB_FPX_TP1',-50],\n",
    "                    ['RAMA4_NB_FPX_TP5',-83]],\n",
    "                4: [['RAMA4_SB_FP4_TP5',10], ['RAMA4_EB_FPX_TP1',-50], ['RAMA4_NB_FPX_TP5',-83 ]],\n",
    "                5: [['RAMA4_NB_FP5_TP1',5], ['RAMA4_EB_FPX_TP1',-50]],\n",
    "                6: [['KASEMRAT_EB_FPX_TP2_RAMA4',-20]],\n",
    "                7: [['KASEMRAT_EB_FPX_TP2_RAMA4',-20]],\n",
    "                8: [['KASEMRAT_EB_FPX_TP2_RAMA4',-20]]}\n",
    "    MAP_KLONGTEI = {0: [['NARANONG_SB_FP5_TP6',-20], ['RAMA4_EB_FP1_TP3',10]],\n",
    "                    1: [['RAMA4_EB_FP3_TP2',40], ['RAMA4_EB_FP1_TP3',10]],\n",
    "                    2: [['KLONGTEI_NB_FP3_TPX',10]],\n",
    "                   3: [['RAMA4_EB_FP3_TP2',40], ['RAMA4_EB_FP1_TP3',10]] }\n",
    "    MAP_NARANONG = {0: [['RAMA4_NB_FPX_TP5',-83]],\n",
    "                1: [['NARANONG_SB_FP1_TP2',30], ['NARANONG_EB_FP1_TP2',10], ['NARANONG_WB_FPX_TP2',-50]],\n",
    "                2: [['NARANONG_WB_FP2_TP3',5], ['NARANONG_WB_FP2_TP3_FLOW',10], ['NARANONG_SW_FPX_TP1',-30],\n",
    "                   ['NARANONG_WB_FPX_TP2',-50]],\n",
    "                3: [['NARANONG_EB_FP3_TP4',10], ['NARANONG_SW_FPX_TP1',-30], ['NARANONG_WB_FPX_TP2',-50]],\n",
    "                4: [['NARANONG_WB_FP4_TP5',5], ['NARANONG_SW_FPX_TP1',-30], ['NARANONG_WB_FPX_TP2',-50]],\n",
    "                5: [['NARANONG_SB_FP5_TP6',5], ['NARANONG_SW_FPX_TP1',-30],['NARANONG_WB_FPX_TP2',-50]],\n",
    "                6: [['NARANONG_NB_FP6_TP1',5], ['NARANONG_SW_FPX_TP1',-30], ['NARANONG_WB_FPX_TP2',-50]] }\n",
    "    MAP_SUNLAKAKHON = {0: [['NARANONG_WB_FPX_TP2',-50]],\n",
    "                    1: [['SUNLAKAKHON_SB_FP1_TPX',10]],\n",
    "                    2: [['SUNLAKAKHON_NB_FP2_TP3',10], ['SUNLAKAKHON_SB_FPX_TP1',-27.5]],\n",
    "                    3:[['SUNLAKAKHON_EB_FP3_TP4',10], ['SUNLAKAKHON_WB_FP3_TP4',-45], ['SUNLAKAKHON_SB_FPX_TP1',-27.5]],\n",
    "                    4:[['SUNLAKAKHON_SB_FP4_TP1',10], ['SUNLAKAKHON_SB_FPX_TP1',-27.5]] }\n",
    "    MAP_KASEMRAT = {0: [['SUNLAKAKHON_SB_FPX_TP1',-20], ['MASUKGRIDLOCK_ARI_NB_FPX_TP2',20]],\n",
    "                    1:[['KASEMRAT_EB_FPX_TP2',35.83], ['KASEMRAT_NB_FPX_TP3',-30], ['MASUKGRIDLOCK_ARI_NB_FPX_TP2',-50],\\\n",
    "                       ['MASUKGRIDLOCK_SUKHUMVUT_FPX_TP2',-50]],\n",
    "                    2:[['KASEMRAT_EB_FP2_TP1',20], ['KASEMRAT_NB_FPX_TP3',-30]],\n",
    "                    3:[['KASEMRAT_EB_FPX_TP2',35.83], ['MASUKGRIDLOCK_ARI_NB_FPX_TP2',-50], ['MASUKGRIDLOCK_SUKHUMVUT_FPX_TP2',-50]]}\n",
    "    MAP_ATTHAKAWI_RAMA4 = {0:[['KASEMRAT_EB_FPX_TP2',-50]],\n",
    "                           1: [['MASUKGRIDLOCK_SUKHUMVUT_FPX_TP2',-50], ['MASUKGRIDLOCK_ARI_NB_FPX_TP2', -50], ['KASEMRAT_EB_FPX_TP2_RAMA4',-50]],\n",
    "                          2:[['KASEMRAT_EB_FPX_TP2_RAMA4',-50]]}\n",
    "\n",
    "#     current_phase = [KLONGTEI phase, RAMA4 phase,NARANONG phase, SUNLAKAKHON phase, KASEMRAT phase, ATTHAKAWI_RAMA4 phase]\n",
    "#     MAP_RAMA4 = {0: [['RAMA4_EB_FPX_TP1',-8] , ['KASEMRAT_EB_FPX_TP2_RAMA4',-20], ['NARANONG_SW_FPX_TP1',-20]],\n",
    "#                  1: [['RAMA4_EB_FP1_TP3',10], ['RAMA4_NB_FPX_TP5',-83]],\n",
    "#                  2: [['RAMA4_WB_FP2_TP4',10], ['RAMA4_EB_FPX_TP1',-8], ['RAMA4_NB_FPX_TP5',-83]],\n",
    "#                 3: [['RAMA4_EB_FP3_TP2',40], ['RAMA4_WB_FP3_TP2',8.8], ['RAMA4_EB_FPX_TP1',-8], \n",
    "#                     ['RAMA4_NB_FPX_TP5',-83]],\n",
    "#                 4: [['RAMA4_SB_FP4_TP5',10], ['RAMA4_EB_FPX_TP1',-8], ['RAMA4_NB_FPX_TP5',-83 ]],\n",
    "#                 5: [['RAMA4_NB_FP5_TP1',5], ['RAMA4_EB_FPX_TP1',-8]],\n",
    "#                 6: [['KASEMRAT_EB_FPX_TP2_RAMA4',-20]],\n",
    "#                 7: [['KASEMRAT_EB_FPX_TP2_RAMA4',-20]],\n",
    "#                 8: [['KASEMRAT_EB_FPX_TP2_RAMA4',-20]]}\n",
    "#     MAP_KLONGTEI = {0: [['NARANONG_SB_FP5_TP6',-20], ['RAMA4_EB_FP1_TP3',10]],\n",
    "#                     1: [['RAMA4_EB_FP3_TP2',40], ['RAMA4_EB_FP1_TP3',10]],\n",
    "#                     2: [['KLONGTEI_NB_FP3_TPX',10]],\n",
    "#                    3: [['RAMA4_EB_FP3_TP2',40], ['RAMA4_EB_FP1_TP3',10]] }\n",
    "#     MAP_NARANONG = {0: [['RAMA4_NB_FPX_TP5',-83]],\n",
    "#                 1: [['NARANONG_SB_FP1_TP2',30], ['NARANONG_EB_FP1_TP2',10], ['NARANONG_WB_FPX_TP2',-17]],\n",
    "#                 2: [['NARANONG_WB_FP2_TP3',5], ['NARANONG_WB_FP2_TP3_FLOW',-30], ['NARANONG_SW_FPX_TP1',-30], \n",
    "#                    ['NARANONG_WB_FPX_TP2',-17]],\n",
    "#                 3: [['NARANONG_EB_FP3_TP4',10], ['NARANONG_SW_FPX_TP1',-30], ['NARANONG_WB_FPX_TP2',-17]],\n",
    "#                 4: [['NARANONG_WB_FP4_TP5',5], ['NARANONG_SW_FPX_TP1',-30], ['NARANONG_WB_FPX_TP2',-17]],\n",
    "#                 5: [['NARANONG_SB_FP5_TP6',5], ['NARANONG_SW_FPX_TP1',-30],['NARANONG_WB_FPX_TP2',-17]], \n",
    "#                 6: [['NARANONG_NB_FP6_TP1',5], ['NARANONG_SW_FPX_TP1',-30], ['NARANONG_WB_FPX_TP2',-17]] }\n",
    "#     MAP_SUNLAKAKHON = {0: [['NARANONG_WB_FPX_TP2',-17]],\n",
    "#                     1: [['SUNLAKAKHON_SB_FP1_TPX',10]],\n",
    "#                     2: [['SUNLAKAKHON_NB_FP2_TP3',10], ['SUNLAKAKHON_SB_FPX_TP1',-27.5]],\n",
    "#                     3:[['SUNLAKAKHON_EB_FP3_TP4',10], ['SUNLAKAKHON_WB_FP3_TP4',-45], ['SUNLAKAKHON_SB_FPX_TP1',-27.5]],\n",
    "#                     4:[['SUNLAKAKHON_SB_FP4_TP1',10], ['SUNLAKAKHON_SB_FPX_TP1',-27.5]] }\n",
    "#     MAP_KASEMRAT = {0: [['SUNLAKAKHON_SB_FPX_TP1',-20], ['MASUKGRIDLOCK_ARI_NB_FPX_TP2',20]],\n",
    "#                     1:[['KASEMRAT_EB_FPX_TP2',35.83], ['KASEMRAT_NB_FPX_TP3',-10], ['MASUKGRIDLOCK_ARI_NB_FPX_TP2',20],\\\n",
    "#                        ['MASUKGRIDLOCK_SUKHUMVUT_FPX_TP2',-50]],\n",
    "#                     2:[['KASEMRAT_EB_FP2_TP1',20], ['KASEMRAT_NB_FPX_TP3',-10]],\n",
    "#                     3:[['KASEMRAT_EB_FPX_TP2',35.83], ['MASUKGRIDLOCK_ARI_NB_FPX_TP2',20], ['MASUKGRIDLOCK_SUKHUMVUT_FPX_TP2',50]]}\n",
    "#     MAP_ATTHAKAWI_RAMA4 = {0:[['KASEMRAT_EB_FPX_TP2',-50]],\n",
    "#                            1: [['MASUKGRIDLOCK_SUKHUMVUT_FPX_TP2',-50], ['MASUKGRIDLOCK_ARI_NB_FPX_TP2', 20]],\n",
    "#                           2:[['KASEMRAT_EB_FPX_TP2_RAMA4',-15]]}\n",
    "    MAP = [MAP_KLONGTEI, MAP_RAMA4, MAP_NARANONG, MAP_SUNLAKAKHON,  MAP_KASEMRAT, MAP_ATTHAKAWI_RAMA4]\n",
    "    state_attention = np.zeros(31)\n",
    "    for i in range(len(current_phase)):\n",
    "        for e in MAP[i][current_phase[i]]:\n",
    "            occupancy = get_occupancy_average_percent(detector[e[0]]) \n",
    "            if e[1] <= 0:\n",
    "                if occupancy >= (-1)*e[1]:\n",
    "                    Index_detector = list_detector.index(e[0]) \n",
    "                    state_attention[Index_detector] = 1\n",
    "            elif occupancy <= e[1]:\n",
    "                Index_detector = list_detector.index(e[0]) \n",
    "                state_attention[Index_detector] = 1\n",
    "#     print(state_attention)\n",
    "    state = np.concatenate((state_attention, hot_encoding_current_phase), axis=None)\n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_summary_xml(dateTimeObj):\n",
    "    meanWaitingTime = []\n",
    "    meanTravelTime = []\n",
    "    meanSpeed = []\n",
    "    tree = ET.parse('summary/summary3'+dateTimeObj+'.xml')\n",
    "    summary = tree.getroot()\n",
    "    for step in summary:\n",
    "        list1 = step.attrib\n",
    "        meanWaitingTime.append(float(list1[\"meanWaitingTime\"]))\n",
    "        meanTravelTime.append(float(list1[\"meanTravelTime\"]))\n",
    "        meanSpeed.append(float(list1[\"meanSpeed\"]))\n",
    "    meanWaitingTime_avg = sum(meanWaitingTime)/len(meanWaitingTime)\n",
    "    meanTravelTime_avg = sum(meanTravelTime)/len(meanTravelTime)\n",
    "    meanSpeed_avg = sum(meanSpeed)/len(meanSpeed)\n",
    "    os.remove('summary/summary3'+dateTimeObj+'.xml')\n",
    "    return meanWaitingTime_avg,meanTravelTime_avg,meanSpeed_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reset the environment\n",
    "def start(dateTimeObj):\n",
    "    sumoBinary = checkBinary('sumo')\n",
    "    traci.start([sumoBinary, \"-c\", \"KASEMRAT-SUMO-UsingBookNetFile/osm.sumocfg\",\n",
    "#                              \"--summary-output\"\n",
    "#                  , \"summary/summary3\"+dateTimeObj+\".xml\"\n",
    "#                  ,\n",
    "                 '--start','true','--quit-on-end','true','--time-to-teleport','-1',\n",
    "                '--lanechange.duration', '0.1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_occupancy_average_percent(detector_id): \n",
    "    #get occupancy average for all detector in list of detector_id and scale by (Vehicle Length + MinimumGap)/MinimumGap \n",
    "    #Vehicle Length = 4.62 MinimumGap = 2.37\n",
    "    occupancy = (sum([traci.lanearea.getLastStepOccupancy(e)*traci.lanearea.getLength(e) for e in detector_id]))/\\\n",
    "                 sum([traci.lanearea.getLength(e) for e in detector_id])*((4.62+2.37)/4.62)\n",
    "#     print(occupancy)\n",
    "    return occupancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_throughput():\n",
    "    loopID = traci.inductionloop.getIDList()\n",
    "    throughput = sum([traci.inductionloop.getLastStepVehicleNumber(i) for i in loopID if traci.inductionloop.getLastStepMeanSpeed(i) > 0])  #if traci.inductionloop.getLastStepMeanSpeed(i) > 0\n",
    "    return throughput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_drawback():\n",
    "#     laneID = traci.lane.getIDList()\n",
    "    drawback = sum([traci.lanearea.getLastStepVehicleNumber(i) for i in NAME.loc[:,'id']])\n",
    "    return drawback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reward():\n",
    "    throughput = 0\n",
    "    for i in range(5):\n",
    "        traci.simulationStep()\n",
    "        throughput += get_throughput()\n",
    "    \n",
    "    drawback = get_drawback()\n",
    "    reward = throughput - 0.004*drawback\n",
    "    return reward, throughput, drawback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_phase = [4,9,7,5,4,3]\n",
    "def set_current_phase(action, current_phase):\n",
    "    if action < 4:\n",
    "        phase = action\n",
    "        current_phase[0] = phase\n",
    "    elif action < 13:\n",
    "        phase = (action-4)\n",
    "        current_phase[1] = phase\n",
    "    elif action < 20:\n",
    "        phase = (action-13)\n",
    "        current_phase[2] = phase\n",
    "    elif action < 25:\n",
    "        phase = (action-20)\n",
    "        current_phase[3] = phase\n",
    "    elif action < 29:\n",
    "        phase = (action-25)\n",
    "        current_phase[4] = phase\n",
    "    else:\n",
    "        phase = (action-29)\n",
    "        current_phase[5] = phase\n",
    "    for i in range (6):\n",
    "        traci.trafficlight.setPhase(junction_id[junction_name[i]], current_phase[i])\n",
    "    \n",
    "    if current_phase[5] == 2:\n",
    "        traci.lane.setAllowed(NAME.loc['MASUKGRIDLOCK_ATTHAKAWI_SB_1_0_LSXT', 'id'], ['passenger'])\n",
    "        traci.lane.setAllowed(NAME.loc['MASUKGRIDLOCK_ATTHAKAWI_SB_2_0_LXXX', 'id'], ['passenger'])\n",
    "        traci.lane.setAllowed(NAME.loc['MASUKGRIDLOCK_ATTHAKAWI_SB_0_0_XSRT', 'id'], ['passenger'])\n",
    "    elif current_phase[5] == 1:\n",
    "        traci.lane.setDisallowed(NAME.loc['MASUKGRIDLOCK_ATTHAKAWI_SB_1_0_LSXT', 'id'], ['passenger'])         \n",
    "        traci.lane.setDisallowed(NAME.loc['MASUKGRIDLOCK_ATTHAKAWI_SB_2_0_LXXX', 'id'], ['passenger'])\n",
    "        traci.lane.setDisallowed(NAME.loc['MASUKGRIDLOCK_ATTHAKAWI_SB_0_0_XSRT', 'id'], ['passenger'])\n",
    "        \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2021-04-2217:00:14.619876'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(str(datetime.datetime.now()).split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_memory = []\n",
    "def plot_durations():\n",
    "    print('show')\n",
    "    plt.figure(2)\n",
    "    plt.clf()\n",
    "    durations_t = torch.tensor(reward_memory, dtype=torch.float)\n",
    "    plt.title('Training...')\n",
    "    plt.xlabel('Step')\n",
    "    plt.ylabel('Reward')\n",
    "    plt.plot(durations_t.numpy())\n",
    "    # Take 100 episode averages and plot them too\n",
    "    if len(durations_t) >= 100:\n",
    "        means = durations_t.unfold(0, 100, 1).mean(1).view(-1)\n",
    "        means = torch.cat((torch.zeros(99), means))\n",
    "        plt.plot(means.numpy())\n",
    "\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyEnv3(gym.Env):\n",
    "    def __init__(self, env_config):\n",
    "        self.episode = 0\n",
    "        self.count = 0\n",
    "        self.reward = 0\n",
    "        self.rewards = 0\n",
    "        self.throughputs = 0\n",
    "        self.drawbacks = 0\n",
    "        self.current_phase = [1,1,1,1,1,1]\n",
    "        self.done = False\n",
    "        self.reward_memory = []\n",
    "        self.log_action = []\n",
    "        self.action_space = gym.spaces.Discrete(32)\n",
    "        self.observation_space = gym.spaces.Box(low=0, high=1, shape=(63,), dtype=np.int8)\n",
    "        self.dateTimeObj = ''\n",
    "        print(self.dateTimeObj)\n",
    "        with open( \"./Raytest/ray_results/resultstatethreshold2.csv\" , 'w', newline='') as csv_file:\n",
    "                header = ['rewards', 'throughput','backlog',\"meanWaitingTime\", \"meanTravelTime\",\"meanSpeed\",\"action\"]\n",
    "                writer = csv.DictWriter(csv_file, fieldnames = header)\n",
    "                writer.writeheader()\n",
    "        \n",
    "    def reset(self):\n",
    "        \n",
    "        self.episode += 1\n",
    "        self.log_action = []\n",
    "        self.reward_memory.append(self.rewards)\n",
    "        self.count = 0\n",
    "        dateTimeObj = datetime.datetime.now()\n",
    "        self.dateTimeObj = dateTimeObj.strftime(\"%d-%b-%Y-%H-%M-%S-%f\")\n",
    "#         print(type(self.dateTimeObj))\n",
    "        start(self.dateTimeObj)\n",
    "        self.reward = 0\n",
    "        self.rewards = 0\n",
    "        self.throughputs = 0\n",
    "        self.backlogs = 0\n",
    "        print(self.reward_memory)\n",
    "        current_phase, hot_encoding_current_phase = get_hot_encoding_current_phase()\n",
    "        state = get_state_attention(current_phase, hot_encoding_current_phase)\n",
    "#         print(state)\n",
    "        self.done = False\n",
    "        self.current_phase = current_phase\n",
    "        if len(self.reward_memory)%100 == 0:\n",
    "            print('memory',self.reward_memory[-10:])\n",
    "        return state \n",
    "    \n",
    "    \n",
    "    def step(self, action):\n",
    "        set_current_phase(action, self.current_phase)\n",
    "#         print(action)\n",
    "        current_phase, hot_encoding_current_phase = get_hot_encoding_current_phase()\n",
    "        self.reward, throughput, drawback= get_reward()\n",
    "        self.rewards += self.reward\n",
    "        self.throughputs += throughput\n",
    "        self.drawbacks += drawback\n",
    "        state = get_state_attention(current_phase, hot_encoding_current_phase)\n",
    "        if np.isnan(self.reward) == True:\n",
    "            print('HELP', type(self.reward))\n",
    "        self.count += 1\n",
    "        self.current_phase = current_phase\n",
    "        self.log_action.append(str(action))\n",
    "#         print('count', self.count)\n",
    "        self.done = False\n",
    "        if self.count >= 2880: #2880\n",
    "            traci.close()\n",
    "            self.done = True\n",
    "#             meanWaitingTime_avg,meanTravelTime_avg,meanSpeed_avg = read_summary_xml(self.dateTimeObj)\n",
    "            meanWaitingTime_avg = 0\n",
    "            meanTravelTime_avg = 0\n",
    "            meanSpeed_avg = 0\n",
    "            data_set = {\"rewards\": self.rewards, \"meanWaitingTime\": meanWaitingTime_avg, \"meanTravelTime\": meanTravelTime_avg,\n",
    "                       \"meanSpeed\": meanSpeed_avg, \"throughput\": self.throughputs, \"backlog\": self.backlogs/2880, \n",
    "                        \"action\":self.log_action\n",
    "                       }\n",
    "            \n",
    "            self.json_dump = json.dumps(data_set)\n",
    "#             if self.episode%20 == 0:\n",
    "#                 self.log_action_json = json.dumps(self.log_action)\n",
    "#                 with open( \"./Raytest/ray_results/action\"+self.dateTimeObj+\".csv\" , 'a', newline='') as csv_file:\n",
    "#                     header = ['action']\n",
    "#                     writer = csv.DictWriter(csv_file, fieldnames = header)\n",
    "#                     writer.writerow({'action': self.log_action})\n",
    "                                 \n",
    "            with open( \"./Raytest/ray_results/resultstatethreshold2.csv\" , 'a', newline='') as csv_file:\n",
    "                header = ['rewards', 'throughput','backlog',\"meanWaitingTime\", \"meanTravelTime\",\"meanSpeed\",\"action\"]\n",
    "                writer = csv.DictWriter(csv_file, fieldnames = header)\n",
    "                writer.writerow({'rewards': self.rewards, \n",
    "                                 'throughput': self.throughputs,\n",
    "                                'backlog': self.backlogs/2880,\n",
    "                                \"meanWaitingTime\": meanWaitingTime_avg, \"meanTravelTime\": meanTravelTime_avg,\n",
    "                       \"meanSpeed\": meanSpeed_avg, \"action\":self.log_action})\n",
    "\n",
    "        \n",
    "        return_state = np.array(state).astype(np.float16)\n",
    "#         print(return_state)\n",
    "        info = {\"throughput\": throughput,\n",
    "                \"drawback\":drawback\n",
    "                }\n",
    "        info = {**info}\n",
    "#         print(info)\n",
    "        return np.int8(return_state) , self.reward, self.done, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == \"__main__\":\n",
    "#     print(\"asd\")\n",
    "#     env = MyEnv3(env_config=None)\n",
    "\n",
    "#     for i_episode in range(1):\n",
    "#         observation = env.reset()\n",
    "#         for t in range(1000):\n",
    "#             # env.render()\n",
    "# #             print(observation)\n",
    "#             action = env.action_space.sample()\n",
    "# #             print('action' ,action)\n",
    "#             observation, reward, done, info = env.step(action)\n",
    "#             if done:\n",
    "#                 print(\"Episode finished after {} timesteps\")\n",
    "#                 break\n",
    "#     env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# traci.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-22 17:00:27,860\tINFO services.py:1172 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8269\u001b[39m\u001b[22m\n",
      "2021-04-22 17:00:27,871\tWARNING services.py:1619 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 67096576 bytes available. This will harm performance! You may be able to free up space by deleting files in /dev/shm. If you are inside a Docker container, you can increase /dev/shm size by passing '--shm-size=Xgb' to 'docker run' (or add it to the run_options list in a Ray cluster config). Make sure to set this to more than 2gb.\n",
      "2021-04-22 17:00:34,762\tERROR syncer.py:72 -- Log sync requires rsync to be installed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am in callback. This is iteration 0 inside trial APEX_40c8b_00000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 87.7/251.4 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 32/32 CPUs, 0/0 GPUs, 0.0/15.09 GiB heap, 0.0/5.18 GiB objects<br>Result logdir: /Raytest/Raytest/ray_results/experiment_apex6<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name      </th><th>status  </th><th>loc  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>APEX_40c8b_00000</td><td>RUNNING </td><td>     </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2336)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=2336)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=2336)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=2336)\u001b[0m 2021-04-22 17:00:44,911\tINFO trainer.py:616 -- Tip: set framework=tfe or the --eager flag to enable TensorFlow eager execution\n",
      "\u001b[2m\u001b[36m(pid=2336)\u001b[0m 2021-04-22 17:00:44,912\tINFO trainer.py:641 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=2300)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=2300)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=2300)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=2296)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=2296)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=2296)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=2310)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=2310)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=2310)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=2298)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=2298)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=2298)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=2293)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=2293)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=2293)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=2327)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=2327)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=2327)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=2286)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=2286)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=2286)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=2305)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=2305)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=2305)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=2332)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=2332)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=2332)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=2280)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=2280)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=2280)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=2288)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=2288)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=2288)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=2314)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=2314)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=2314)\u001b[0m non-resource variables are not supported in the long term\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2300)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=2296)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2300)\u001b[0m 2021-04-22 17:01:00,850\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=2296)\u001b[0m 2021-04-22 17:01:00,906\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=2294)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=2294)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=2294)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=2318)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=2318)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=2318)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=2301)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=2301)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=2301)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=2296)\u001b[0m 2021-04-22 17:01:02,014\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=2310)\u001b[0m 2021-04-22 17:01:02,109\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2310)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2300)\u001b[0m 2021-04-22 17:01:02,403\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=2285)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=2285)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=2285)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=2295)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=2295)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=2295)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=2287)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=2287)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=2287)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=2284)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=2284)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=2284)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=2330)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=2330)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=2330)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=2310)\u001b[0m 2021-04-22 17:01:03,383\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=2292)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=2292)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=2292)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=2289)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=2289)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=2289)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=2283)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=2283)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=2283)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=2281)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=2281)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=2281)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=2298)\u001b[0m 2021-04-22 17:01:04,860\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2298)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=2293)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2293)\u001b[0m 2021-04-22 17:01:04,985\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=2308)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=2308)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=2308)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=2282)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=2282)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=2282)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=2320)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=2320)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=2320)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=2298)\u001b[0m 2021-04-22 17:01:05,946\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=2334)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=2334)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=2334)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=2313)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=2313)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=2313)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=2293)\u001b[0m 2021-04-22 17:01:06,419\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=2288)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2305)\u001b[0m 2021-04-22 17:01:07,044\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=2288)\u001b[0m 2021-04-22 17:01:07,156\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=2299)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=2299)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=2299)\u001b[0m non-resource variables are not supported in the long term\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2332)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2332)\u001b[0m 2021-04-22 17:01:07,705\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2314)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2314)\u001b[0m 2021-04-22 17:01:08,007\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2294)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2290)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=2290)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=2290)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=2294)\u001b[0m 2021-04-22 17:01:08,301\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2280)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2280)\u001b[0m 2021-04-22 17:01:08,608\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2330)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2330)\u001b[0m 2021-04-22 17:01:08,918\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=2305)\u001b[0m 2021-04-22 17:01:09,003\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2318)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=2286)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2288)\u001b[0m 2021-04-22 17:01:09,159\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=2318)\u001b[0m 2021-04-22 17:01:09,183\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=2286)\u001b[0m 2021-04-22 17:01:09,334\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2327)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2327)\u001b[0m 2021-04-22 17:01:09,475\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=2332)\u001b[0m 2021-04-22 17:01:09,661\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=2285)\u001b[0m 2021-04-22 17:01:09,796\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2285)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2314)\u001b[0m 2021-04-22 17:01:09,886\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=2289)\u001b[0m 2021-04-22 17:01:10,039\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2289)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2294)\u001b[0m 2021-04-22 17:01:10,099\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=2280)\u001b[0m 2021-04-22 17:01:10,180\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=2330)\u001b[0m 2021-04-22 17:01:10,229\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=2318)\u001b[0m 2021-04-22 17:01:10,423\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=2301)\u001b[0m 2021-04-22 17:01:10,457\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=2286)\u001b[0m 2021-04-22 17:01:10,624\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2301)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2327)\u001b[0m 2021-04-22 17:01:10,987\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=2285)\u001b[0m 2021-04-22 17:01:11,068\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=2289)\u001b[0m 2021-04-22 17:01:11,376\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2292)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2292)\u001b[0m 2021-04-22 17:01:11,733\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=2301)\u001b[0m 2021-04-22 17:01:11,854\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2287)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=2281)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2287)\u001b[0m 2021-04-22 17:01:12,123\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=2281)\u001b[0m 2021-04-22 17:01:12,199\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=2284)\u001b[0m 2021-04-22 17:01:12,284\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2284)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=2334)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=2308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=2295)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2334)\u001b[0m 2021-04-22 17:01:12,641\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=2308)\u001b[0m 2021-04-22 17:01:12,752\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=2295)\u001b[0m 2021-04-22 17:01:12,804\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=2283)\u001b[0m 2021-04-22 17:01:12,878\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2283)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=2282)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2284)\u001b[0m 2021-04-22 17:01:13,081\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=2282)\u001b[0m 2021-04-22 17:01:13,069\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=2292)\u001b[0m 2021-04-22 17:01:13,299\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=2281)\u001b[0m 2021-04-22 17:01:13,388\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=2308)\u001b[0m 2021-04-22 17:01:13,405\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=2283)\u001b[0m 2021-04-22 17:01:13,513\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=2287)\u001b[0m 2021-04-22 17:01:13,616\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=2320)\u001b[0m 2021-04-22 17:01:13,862\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=2334)\u001b[0m 2021-04-22 17:01:13,892\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=2299)\u001b[0m 2021-04-22 17:01:13,870\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2299)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=2320)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2313)\u001b[0m 2021-04-22 17:01:14,078\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=2295)\u001b[0m 2021-04-22 17:01:14,169\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2313)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2282)\u001b[0m 2021-04-22 17:01:14,391\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=2320)\u001b[0m 2021-04-22 17:01:14,494\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=2313)\u001b[0m 2021-04-22 17:01:14,674\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=2299)\u001b[0m 2021-04-22 17:01:14,962\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=2290)\u001b[0m 2021-04-22 17:01:15,331\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2290)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2290)\u001b[0m 2021-04-22 17:01:15,931\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=2336)\u001b[0m 2021-04-22 17:01:21,055\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=2336)\u001b[0m 2021-04-22 17:01:21,752\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=3148)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=3148)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=3148)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=3151)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=3151)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=3151)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=3149)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=3149)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=3149)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=3150)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=3150)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=3150)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=2336)\u001b[0m 2021-04-22 17:01:32,166\tINFO trainable.py:100 -- Trainable.setup took 47.262 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(pid=2336)\u001b[0m 2021-04-22 17:01:32,166\tWARNING util.py:47 -- Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2289)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2320)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2293)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2332)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2314)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2294)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2280)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2318)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2286)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2327)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2285)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2287)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2284)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2334)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2282)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2299)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2313)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2290)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2300)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2310)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2298)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2288)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2314)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2330)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2289)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2292)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2281)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2283)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2318)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2301)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2334)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2295)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2305)\u001b[0m Loading configuration ... \n",
      "\u001b[2m\u001b[36m(pid=2296)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2305)\u001b[0m done.\n",
      "\u001b[2m\u001b[36m(pid=2294)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2280)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2286)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2327)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2308)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2298)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2332)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2285)\u001b[0m Loading configuration ... \n",
      "\u001b[2m\u001b[36m(pid=2284)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2283)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2282)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2320)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2313)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2290)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2285)\u001b[0m done.\n",
      "\u001b[2m\u001b[36m(pid=2299)\u001b[0m Loading configuration ... \n",
      "\u001b[2m\u001b[36m(pid=2300)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2310)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2293)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2287)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2281)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2295)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2299)\u001b[0m done.\n",
      "\u001b[2m\u001b[36m(pid=2330)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2288)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2292)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2296)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2296)\u001b[0m [0]\n",
      "\u001b[2m\u001b[36m(pid=2286)\u001b[0m [0]\n",
      "\u001b[2m\u001b[36m(pid=2280)\u001b[0m [0]\n",
      "\u001b[2m\u001b[36m(pid=2289)\u001b[0m [0]\n",
      "\u001b[2m\u001b[36m(pid=2318)\u001b[0m [0]\n",
      "\u001b[2m\u001b[36m(pid=2294)\u001b[0m [0]\n",
      "\u001b[2m\u001b[36m(pid=2281)\u001b[0m [0]\n",
      "\u001b[2m\u001b[36m(pid=2292)\u001b[0m [0]\n",
      "\u001b[2m\u001b[36m(pid=2301)\u001b[0m [0]\n",
      "\u001b[2m\u001b[36m(pid=2310)\u001b[0m [0]\n",
      "\u001b[2m\u001b[36m(pid=2293)\u001b[0m [0]\n",
      "\u001b[2m\u001b[36m(pid=2283)\u001b[0m [0]\n",
      "\u001b[2m\u001b[36m(pid=2314)\u001b[0m [0]\n",
      "\u001b[2m\u001b[36m(pid=2330)\u001b[0m [0]\n",
      "\u001b[2m\u001b[36m(pid=2334)\u001b[0m [0]\n",
      "\u001b[2m\u001b[36m(pid=2290)\u001b[0m [0]\n",
      "\u001b[2m\u001b[36m(pid=2308)\u001b[0m [0]\n",
      "\u001b[2m\u001b[36m(pid=2298)\u001b[0m [0]\n",
      "\u001b[2m\u001b[36m(pid=2305)\u001b[0m [0]\n",
      "\u001b[2m\u001b[36m(pid=2320)\u001b[0m [0]\n",
      "\u001b[2m\u001b[36m(pid=2313)\u001b[0m [0]\n",
      "\u001b[2m\u001b[36m(pid=2300)\u001b[0m [0]\n",
      "\u001b[2m\u001b[36m(pid=2288)\u001b[0m [0]\n",
      "\u001b[2m\u001b[36m(pid=2287)\u001b[0m [0]\n",
      "\u001b[2m\u001b[36m(pid=2299)\u001b[0m [0]\n",
      "\u001b[2m\u001b[36m(pid=2284)\u001b[0m [0]\n",
      "\u001b[2m\u001b[36m(pid=2295)\u001b[0m [0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2332)\u001b[0m 2021-04-22 17:01:38,320\tWARNING deprecation.py:33 -- DeprecationWarning: `env_index` has been deprecated. Use `episode.env_id` instead. This will raise an error in the future!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2332)\u001b[0m [0]\n",
      "\u001b[2m\u001b[36m(pid=2282)\u001b[0m [0]\n",
      "\u001b[2m\u001b[36m(pid=2327)\u001b[0m [0]\n",
      "\u001b[2m\u001b[36m(pid=2285)\u001b[0m [0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3150)\u001b[0m 2021-04-22 17:01:59,726\tINFO replay_buffer.py:44 -- Estimated max memory usage for replay buffer is 0.0224 GB (25000.0 batches of size 1, 896 bytes each), available system memory is 269.913104384 GB\n",
      "\u001b[2m\u001b[36m(pid=3151)\u001b[0m 2021-04-22 17:02:01,257\tINFO replay_buffer.py:44 -- Estimated max memory usage for replay buffer is 0.0224 GB (25000.0 batches of size 1, 896 bytes each), available system memory is 269.913104384 GB\n",
      "\u001b[2m\u001b[36m(pid=3148)\u001b[0m 2021-04-22 17:02:01,707\tINFO replay_buffer.py:44 -- Estimated max memory usage for replay buffer is 0.0224 GB (25000.0 batches of size 1, 896 bytes each), available system memory is 269.913104384 GB\n",
      "\u001b[2m\u001b[36m(pid=3149)\u001b[0m 2021-04-22 17:02:01,862\tINFO replay_buffer.py:44 -- Estimated max memory usage for replay buffer is 0.0224 GB (25000.0 batches of size 1, 896 bytes each), available system memory is 269.913104384 GB\n",
      "\u001b[2m\u001b[36m(pid=2292)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/ray/rllib/policy/tf_policy.py:926: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=2292)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=2292)\u001b[0m Prefer Variable.assign which has equivalent behavior in 2.X.\n",
      "\u001b[2m\u001b[36m(pid=2296)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/ray/rllib/policy/tf_policy.py:926: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=2296)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=2296)\u001b[0m Prefer Variable.assign which has equivalent behavior in 2.X.\n",
      "\u001b[2m\u001b[36m(pid=2293)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/ray/rllib/policy/tf_policy.py:926: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=2293)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=2293)\u001b[0m Prefer Variable.assign which has equivalent behavior in 2.X.\n",
      "\u001b[2m\u001b[36m(pid=2330)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/ray/rllib/policy/tf_policy.py:926: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=2330)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=2330)\u001b[0m Prefer Variable.assign which has equivalent behavior in 2.X.\n",
      "\u001b[2m\u001b[36m(pid=2299)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/ray/rllib/policy/tf_policy.py:926: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=2299)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=2299)\u001b[0m Prefer Variable.assign which has equivalent behavior in 2.X.\n",
      "\u001b[2m\u001b[36m(pid=2320)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/ray/rllib/policy/tf_policy.py:926: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=2320)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=2320)\u001b[0m Prefer Variable.assign which has equivalent behavior in 2.X.\n",
      "\u001b[2m\u001b[36m(pid=2284)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/ray/rllib/policy/tf_policy.py:926: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=2284)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=2284)\u001b[0m Prefer Variable.assign which has equivalent behavior in 2.X.\n",
      "\u001b[2m\u001b[36m(pid=2334)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/ray/rllib/policy/tf_policy.py:926: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=2334)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=2334)\u001b[0m Prefer Variable.assign which has equivalent behavior in 2.X.\n",
      "\u001b[2m\u001b[36m(pid=2305)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/ray/rllib/policy/tf_policy.py:926: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=2305)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=2305)\u001b[0m Prefer Variable.assign which has equivalent behavior in 2.X.\n",
      "\u001b[2m\u001b[36m(pid=2298)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/ray/rllib/policy/tf_policy.py:926: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=2298)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=2298)\u001b[0m Prefer Variable.assign which has equivalent behavior in 2.X.\n",
      "\u001b[2m\u001b[36m(pid=2281)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/ray/rllib/policy/tf_policy.py:926: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=2281)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=2281)\u001b[0m Prefer Variable.assign which has equivalent behavior in 2.X.\n",
      "\u001b[2m\u001b[36m(pid=2310)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/ray/rllib/policy/tf_policy.py:926: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=2310)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=2310)\u001b[0m Prefer Variable.assign which has equivalent behavior in 2.X.\n",
      "\u001b[2m\u001b[36m(pid=2289)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/ray/rllib/policy/tf_policy.py:926: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=2289)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=2289)\u001b[0m Prefer Variable.assign which has equivalent behavior in 2.X.\n",
      "\u001b[2m\u001b[36m(pid=2308)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/ray/rllib/policy/tf_policy.py:926: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=2308)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=2308)\u001b[0m Prefer Variable.assign which has equivalent behavior in 2.X.\n",
      "\u001b[2m\u001b[36m(pid=2282)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/ray/rllib/policy/tf_policy.py:926: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=2282)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=2282)\u001b[0m Prefer Variable.assign which has equivalent behavior in 2.X.\n",
      "\u001b[2m\u001b[36m(pid=2287)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/ray/rllib/policy/tf_policy.py:926: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=2287)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=2287)\u001b[0m Prefer Variable.assign which has equivalent behavior in 2.X.\n",
      "\u001b[2m\u001b[36m(pid=2300)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/ray/rllib/policy/tf_policy.py:926: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=2300)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=2300)\u001b[0m Prefer Variable.assign which has equivalent behavior in 2.X.\n",
      "\u001b[2m\u001b[36m(pid=2327)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/ray/rllib/policy/tf_policy.py:926: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=2327)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=2327)\u001b[0m Prefer Variable.assign which has equivalent behavior in 2.X.\n",
      "\u001b[2m\u001b[36m(pid=2285)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/ray/rllib/policy/tf_policy.py:926: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=2285)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=2285)\u001b[0m Prefer Variable.assign which has equivalent behavior in 2.X.\n",
      "\u001b[2m\u001b[36m(pid=2290)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/ray/rllib/policy/tf_policy.py:926: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=2290)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=2290)\u001b[0m Prefer Variable.assign which has equivalent behavior in 2.X.\n",
      "\u001b[2m\u001b[36m(pid=2301)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/ray/rllib/policy/tf_policy.py:926: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=2301)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=2301)\u001b[0m Prefer Variable.assign which has equivalent behavior in 2.X.\n",
      "\u001b[2m\u001b[36m(pid=2318)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/ray/rllib/policy/tf_policy.py:926: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=2318)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=2318)\u001b[0m Prefer Variable.assign which has equivalent behavior in 2.X.\n",
      "\u001b[2m\u001b[36m(pid=2288)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/ray/rllib/policy/tf_policy.py:926: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=2288)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=2288)\u001b[0m Prefer Variable.assign which has equivalent behavior in 2.X.\n",
      "\u001b[2m\u001b[36m(pid=2332)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/ray/rllib/policy/tf_policy.py:926: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=2332)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=2332)\u001b[0m Prefer Variable.assign which has equivalent behavior in 2.X.\n",
      "\u001b[2m\u001b[36m(pid=2295)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/ray/rllib/policy/tf_policy.py:926: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=2295)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=2295)\u001b[0m Prefer Variable.assign which has equivalent behavior in 2.X.\n",
      "\u001b[2m\u001b[36m(pid=2294)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/ray/rllib/policy/tf_policy.py:926: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=2294)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=2294)\u001b[0m Prefer Variable.assign which has equivalent behavior in 2.X.\n",
      "\u001b[2m\u001b[36m(pid=2313)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/ray/rllib/policy/tf_policy.py:926: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=2313)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=2313)\u001b[0m Prefer Variable.assign which has equivalent behavior in 2.X.\n",
      "\u001b[2m\u001b[36m(pid=2283)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/ray/rllib/policy/tf_policy.py:926: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=2283)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=2283)\u001b[0m Prefer Variable.assign which has equivalent behavior in 2.X.\n",
      "\u001b[2m\u001b[36m(pid=2286)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/ray/rllib/policy/tf_policy.py:926: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=2286)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=2286)\u001b[0m Prefer Variable.assign which has equivalent behavior in 2.X.\n",
      "\u001b[2m\u001b[36m(pid=2314)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/ray/rllib/policy/tf_policy.py:926: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=2314)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=2314)\u001b[0m Prefer Variable.assign which has equivalent behavior in 2.X.\n",
      "\u001b[2m\u001b[36m(pid=2280)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/ray/rllib/policy/tf_policy.py:926: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=2280)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=2280)\u001b[0m Prefer Variable.assign which has equivalent behavior in 2.X.\n",
      "2021-04-22 17:44:15,364\tWARNING logger.py:650 -- You are trying to log an invalid value (ray/tune/info/exploration_infos=[{'cur_epsilon': 0.0}, {'cur_epsilon': 0.4}, {'cur_epsilon': 0.32300356}, {'cur_epsilon': 0.26082826}, {'cur_epsilon': 0.21062115}, {'cur_epsilon': 0.17007846}, {'cur_epsilon': 0.13733988}, {'cur_epsilon': 0.11090317}, {'cur_epsilon': 0.0895553}, {'cur_epsilon': 0.072316706}, {'cur_epsilon': 0.058396388}, {'cur_epsilon': 0.047155604}, {'cur_epsilon': 0.03807857}, {'cur_epsilon': 0.030748786}, {'cur_epsilon': 0.024829919}, {'cur_epsilon': 0.02005038}, {'cur_epsilon': 0.016190862}, {'cur_epsilon': 0.013074265}, {'cur_epsilon': 0.010557586}, {'cur_epsilon': 0.008525345}, {'cur_epsilon': 0.0068842922}, {'cur_epsilon': 0.0055591273}, {'cur_epsilon': 0.004489045}, {'cur_epsilon': 0.0036249438}, {'cur_epsilon': 0.0029271746}, {'cur_epsilon': 0.0023637195}, {'cur_epsilon': 0.0019087247}, {'cur_epsilon': 0.0015413122}, {'cur_epsilon': 0.0012446233}, {'cur_epsilon': 0.0010050444}, {'cur_epsilon': 0.0008115824}, {'cur_epsilon': 0.00065536}]) via TBXLoggerCallback!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am in second callback. Got result: {}\n",
      "Result for APEX_40c8b_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-04-22_17-44-15\n",
      "  done: false\n",
      "  episode_len_mean: .nan\n",
      "  episode_reward_max: .nan\n",
      "  episode_reward_mean: .nan\n",
      "  episode_reward_min: .nan\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 0\n",
      "  experiment_id: d21118775ed24ec1819dd8ebeb7c9122\n",
      "  hostname: raytest3-644cc68dc4-mcsqh\n",
      "  info:\n",
      "    exploration_infos:\n",
      "    - cur_epsilon: 0.0\n",
      "    - cur_epsilon: 0.4000000059604645\n",
      "    - cur_epsilon: 0.3230035603046417\n",
      "    - cur_epsilon: 0.26082825660705566\n",
      "    - cur_epsilon: 0.21062114834785461\n",
      "    - cur_epsilon: 0.17007845640182495\n",
      "    - cur_epsilon: 0.13733987510204315\n",
      "    - cur_epsilon: 0.11090317368507385\n",
      "    - cur_epsilon: 0.0895553007721901\n",
      "    - cur_epsilon: 0.07231670618057251\n",
      "    - cur_epsilon: 0.058396387845277786\n",
      "    - cur_epsilon: 0.047155603766441345\n",
      "    - cur_epsilon: 0.03807856887578964\n",
      "    - cur_epsilon: 0.03074878640472889\n",
      "    - cur_epsilon: 0.024829918518662453\n",
      "    - cur_epsilon: 0.020050380378961563\n",
      "    - cur_epsilon: 0.01619086228311062\n",
      "    - cur_epsilon: 0.013074264861643314\n",
      "    - cur_epsilon: 0.010557586327195168\n",
      "    - cur_epsilon: 0.008525344543159008\n",
      "    - cur_epsilon: 0.006884292233735323\n",
      "    - cur_epsilon: 0.005559127312153578\n",
      "    - cur_epsilon: 0.00448904512450099\n",
      "    - cur_epsilon: 0.003624943783506751\n",
      "    - cur_epsilon: 0.002927174558863044\n",
      "    - cur_epsilon: 0.0023637195117771626\n",
      "    - cur_epsilon: 0.0019087246619164944\n",
      "    - cur_epsilon: 0.0015413122018799186\n",
      "    - cur_epsilon: 0.0012446233304217458\n",
      "    - cur_epsilon: 0.0010050444398075342\n",
      "    - cur_epsilon: 0.0008115823729895055\n",
      "    - cur_epsilon: 0.0006553599960170686\n",
      "    last_target_update_ts: 0\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: 0.15825802087783813\n",
      "        mean_q: -1.9703080654144287\n",
      "        mean_td_error: 24.665977478027344\n",
      "        min_q: -2.9903016090393066\n",
      "        model: {}\n",
      "    learner_queue:\n",
      "      size_count: 5\n",
      "      size_mean: 2.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.4\n",
      "      - 2.0\n",
      "      - 3.6\n",
      "      - 4.0\n",
      "      size_std: 1.4142135623730951\n",
      "    num_steps_sampled: 28300\n",
      "    num_steps_trained: 2880\n",
      "    num_weight_syncs: 62\n",
      "    replay_shard_0:\n",
      "      add_batch_time_ms: 6.821\n",
      "      policy_default_policy:\n",
      "        added_count: 7050\n",
      "        est_size_bytes: 6316800\n",
      "        num_entries: 7050\n",
      "        sampled_count: 0\n",
      "      replay_time_ms: 0.0\n",
      "      update_priorities_time_ms: 0.0\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 10.42.1.113\n",
      "  num_healthy_workers: 31\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 99.98594654174704\n",
      "    ram_util_percent: 37.927776246899974\n",
      "  pid: 2336\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf: {}\n",
      "  time_since_restore: 2563.0658366680145\n",
      "  time_this_iter_s: 2563.0658366680145\n",
      "  time_total_s: 2563.0658366680145\n",
      "  timers:\n",
      "    learner_dequeue_time_ms: 464006.949\n",
      "    learner_grad_throughput: 3391.254\n",
      "    learner_grad_time_ms: 849.243\n",
      "    learner_overall_throughput: 6.195\n",
      "    learner_overall_time_ms: 464856.237\n",
      "  timestamp: 1619113455\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 28300\n",
      "  training_iteration: 1\n",
      "  trial_id: 40c8b_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 94.9/251.4 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 32/32 CPUs, 0/0 GPUs, 0.0/15.09 GiB heap, 0.0/5.18 GiB objects<br>Result logdir: /Raytest/Raytest/ray_results/experiment_apex6<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name      </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>APEX_40c8b_00000</td><td>RUNNING </td><td>10.42.1.113:2336</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         2563.07</td><td style=\"text-align: right;\">28300</td><td style=\"text-align: right;\">     nan</td><td style=\"text-align: right;\">                 nan</td><td style=\"text-align: right;\">                 nan</td><td style=\"text-align: right;\">               nan</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am in second callback. Got result: {}\n",
      "Result for APEX_40c8b_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-04-22_18-13-31\n",
      "  done: false\n",
      "  episode_len_mean: .nan\n",
      "  episode_reward_max: .nan\n",
      "  episode_reward_mean: .nan\n",
      "  episode_reward_min: .nan\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 0\n",
      "  experiment_id: d21118775ed24ec1819dd8ebeb7c9122\n",
      "  hostname: raytest3-644cc68dc4-mcsqh\n",
      "  info:\n",
      "    exploration_infos:\n",
      "    - cur_epsilon: 0.0\n",
      "    - cur_epsilon: 0.4000000059604645\n",
      "    - cur_epsilon: 0.3230035603046417\n",
      "    - cur_epsilon: 0.26082825660705566\n",
      "    - cur_epsilon: 0.21062114834785461\n",
      "    - cur_epsilon: 0.17007845640182495\n",
      "    - cur_epsilon: 0.13733987510204315\n",
      "    - cur_epsilon: 0.11090317368507385\n",
      "    - cur_epsilon: 0.0895553007721901\n",
      "    - cur_epsilon: 0.07231670618057251\n",
      "    - cur_epsilon: 0.058396387845277786\n",
      "    - cur_epsilon: 0.047155603766441345\n",
      "    - cur_epsilon: 0.03807856887578964\n",
      "    - cur_epsilon: 0.03074878640472889\n",
      "    - cur_epsilon: 0.024829918518662453\n",
      "    - cur_epsilon: 0.020050380378961563\n",
      "    - cur_epsilon: 0.01619086228311062\n",
      "    - cur_epsilon: 0.013074264861643314\n",
      "    - cur_epsilon: 0.010557586327195168\n",
      "    - cur_epsilon: 0.008525344543159008\n",
      "    - cur_epsilon: 0.006884292233735323\n",
      "    - cur_epsilon: 0.005559127312153578\n",
      "    - cur_epsilon: 0.00448904512450099\n",
      "    - cur_epsilon: 0.003624943783506751\n",
      "    - cur_epsilon: 0.002927174558863044\n",
      "    - cur_epsilon: 0.0023637195117771626\n",
      "    - cur_epsilon: 0.0019087246619164944\n",
      "    - cur_epsilon: 0.0015413122018799186\n",
      "    - cur_epsilon: 0.0012446233304217458\n",
      "    - cur_epsilon: 0.0010050444398075342\n",
      "    - cur_epsilon: 0.0008115823729895055\n",
      "    - cur_epsilon: 0.0006553599960170686\n",
      "    last_target_update_ts: 6050880\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: 225.7627410888672\n",
      "        mean_q: -43.31452941894531\n",
      "        mean_td_error: -2.8586153984069824\n",
      "        min_q: -129.28085327148438\n",
      "        model: {}\n",
      "    learner_queue:\n",
      "      size_count: 2105\n",
      "      size_mean: 0.22\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 1.0\n",
      "      - 1.0\n",
      "      size_std: 0.41424630354415964\n",
      "    num_steps_sampled: 39900\n",
      "    num_steps_trained: 6059520\n",
      "    num_target_updates: 191\n",
      "    num_weight_syncs: 93\n",
      "    replay_shard_0:\n",
      "      add_batch_time_ms: 20.605\n",
      "      policy_default_policy:\n",
      "        added_count: 10150\n",
      "        est_size_bytes: 9094400\n",
      "        num_entries: 10150\n",
      "        sampled_count: 1491840\n",
      "      replay_time_ms: 943.791\n",
      "      update_priorities_time_ms: 2202.95\n",
      "  iterations_since_restore: 2\n",
      "  node_ip: 10.42.1.113\n",
      "  num_healthy_workers: 31\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 99.99349919743177\n",
      "    ram_util_percent: 38.34803370786517\n",
      "  pid: 2336\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf: {}\n",
      "  time_since_restore: 4319.457270860672\n",
      "  time_this_iter_s: 1756.3914341926575\n",
      "  time_total_s: 4319.457270860672\n",
      "  timers:\n",
      "    learner_dequeue_time_ms: 645.668\n",
      "    learner_grad_throughput: 11741.589\n",
      "    learner_grad_time_ms: 245.282\n",
      "    learner_overall_throughput: 3232.335\n",
      "    learner_overall_time_ms: 890.997\n",
      "  timestamp: 1619115211\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 39900\n",
      "  training_iteration: 2\n",
      "  trial_id: 40c8b_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 97.7/251.4 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 32/32 CPUs, 0/0 GPUs, 0.0/15.09 GiB heap, 0.0/5.18 GiB objects<br>Result logdir: /Raytest/Raytest/ray_results/experiment_apex6<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name      </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>APEX_40c8b_00000</td><td>RUNNING </td><td>10.42.1.113:2336</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         4319.46</td><td style=\"text-align: right;\">39900</td><td style=\"text-align: right;\">     nan</td><td style=\"text-align: right;\">                 nan</td><td style=\"text-align: right;\">                 nan</td><td style=\"text-align: right;\">               nan</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am in second callback. Got result: {}\n",
      "Result for APEX_40c8b_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-04-22_18-41-27\n",
      "  done: false\n",
      "  episode_len_mean: .nan\n",
      "  episode_reward_max: .nan\n",
      "  episode_reward_mean: .nan\n",
      "  episode_reward_min: .nan\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 0\n",
      "  experiment_id: d21118775ed24ec1819dd8ebeb7c9122\n",
      "  hostname: raytest3-644cc68dc4-mcsqh\n",
      "  info:\n",
      "    exploration_infos:\n",
      "    - cur_epsilon: 0.0\n",
      "    - cur_epsilon: 0.4000000059604645\n",
      "    - cur_epsilon: 0.3230035603046417\n",
      "    - cur_epsilon: 0.26082825660705566\n",
      "    - cur_epsilon: 0.21062114834785461\n",
      "    - cur_epsilon: 0.17007845640182495\n",
      "    - cur_epsilon: 0.13733987510204315\n",
      "    - cur_epsilon: 0.11090317368507385\n",
      "    - cur_epsilon: 0.0895553007721901\n",
      "    - cur_epsilon: 0.07231670618057251\n",
      "    - cur_epsilon: 0.058396387845277786\n",
      "    - cur_epsilon: 0.047155603766441345\n",
      "    - cur_epsilon: 0.03807856887578964\n",
      "    - cur_epsilon: 0.03074878640472889\n",
      "    - cur_epsilon: 0.024829918518662453\n",
      "    - cur_epsilon: 0.020050380378961563\n",
      "    - cur_epsilon: 0.01619086228311062\n",
      "    - cur_epsilon: 0.013074264861643314\n",
      "    - cur_epsilon: 0.010557586327195168\n",
      "    - cur_epsilon: 0.008525344543159008\n",
      "    - cur_epsilon: 0.006884292233735323\n",
      "    - cur_epsilon: 0.005559127312153578\n",
      "    - cur_epsilon: 0.00448904512450099\n",
      "    - cur_epsilon: 0.003624943783506751\n",
      "    - cur_epsilon: 0.002927174558863044\n",
      "    - cur_epsilon: 0.0023637195117771626\n",
      "    - cur_epsilon: 0.0019087246619164944\n",
      "    - cur_epsilon: 0.0015413122018799186\n",
      "    - cur_epsilon: 0.0012446233304217458\n",
      "    - cur_epsilon: 0.0010050444398075342\n",
      "    - cur_epsilon: 0.0008115823729895055\n",
      "    - cur_epsilon: 0.0006553599960170686\n",
      "    last_target_update_ts: 12545280\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: 165.79702758789062\n",
      "        mean_q: -54.41328048706055\n",
      "        mean_td_error: -3.278183698654175\n",
      "        min_q: -141.3987579345703\n",
      "        model: {}\n",
      "    learner_queue:\n",
      "      size_count: 4363\n",
      "      size_mean: 0.3\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 1.0\n",
      "      - 2.0\n",
      "      size_std: 0.49999999999999994\n",
      "    num_steps_sampled: 51450\n",
      "    num_steps_trained: 12565440\n",
      "    num_target_updates: 396\n",
      "    num_weight_syncs: 124\n",
      "    replay_shard_0:\n",
      "      add_batch_time_ms: 27.112\n",
      "      policy_default_policy:\n",
      "        added_count: 13100\n",
      "        est_size_bytes: 11737600\n",
      "        num_entries: 13100\n",
      "        sampled_count: 3121920\n",
      "      replay_time_ms: 455.859\n",
      "      update_priorities_time_ms: 745.004\n",
      "  iterations_since_restore: 3\n",
      "  node_ip: 10.42.1.113\n",
      "  num_healthy_workers: 31\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 99.99142857142857\n",
      "    ram_util_percent: 38.39247899159664\n",
      "  pid: 2336\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf: {}\n",
      "  time_since_restore: 5995.038616895676\n",
      "  time_this_iter_s: 1675.5813460350037\n",
      "  time_total_s: 5995.038616895676\n",
      "  timers:\n",
      "    learner_dequeue_time_ms: 258.82\n",
      "    learner_grad_throughput: 21914.891\n",
      "    learner_grad_time_ms: 131.417\n",
      "    learner_overall_throughput: 7379.274\n",
      "    learner_overall_time_ms: 390.282\n",
      "  timestamp: 1619116887\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 51450\n",
      "  training_iteration: 3\n",
      "  trial_id: 40c8b_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 97.4/251.4 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 32/32 CPUs, 0/0 GPUs, 0.0/15.09 GiB heap, 0.0/5.18 GiB objects<br>Result logdir: /Raytest/Raytest/ray_results/experiment_apex6<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name      </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>APEX_40c8b_00000</td><td>RUNNING </td><td>10.42.1.113:2336</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         5995.04</td><td style=\"text-align: right;\">51450</td><td style=\"text-align: right;\">     nan</td><td style=\"text-align: right;\">                 nan</td><td style=\"text-align: right;\">                 nan</td><td style=\"text-align: right;\">               nan</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am in second callback. Got result: {}\n",
      "Result for APEX_40c8b_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-04-22_19-13-35\n",
      "  done: false\n",
      "  episode_len_mean: .nan\n",
      "  episode_reward_max: .nan\n",
      "  episode_reward_mean: .nan\n",
      "  episode_reward_min: .nan\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 0\n",
      "  experiment_id: d21118775ed24ec1819dd8ebeb7c9122\n",
      "  hostname: raytest3-644cc68dc4-mcsqh\n",
      "  info:\n",
      "    exploration_infos:\n",
      "    - cur_epsilon: 0.0\n",
      "    - cur_epsilon: 0.4000000059604645\n",
      "    - cur_epsilon: 0.3230035603046417\n",
      "    - cur_epsilon: 0.26082825660705566\n",
      "    - cur_epsilon: 0.21062114834785461\n",
      "    - cur_epsilon: 0.17007845640182495\n",
      "    - cur_epsilon: 0.13733987510204315\n",
      "    - cur_epsilon: 0.11090317368507385\n",
      "    - cur_epsilon: 0.0895553007721901\n",
      "    - cur_epsilon: 0.07231670618057251\n",
      "    - cur_epsilon: 0.058396387845277786\n",
      "    - cur_epsilon: 0.047155603766441345\n",
      "    - cur_epsilon: 0.03807856887578964\n",
      "    - cur_epsilon: 0.03074878640472889\n",
      "    - cur_epsilon: 0.024829918518662453\n",
      "    - cur_epsilon: 0.020050380378961563\n",
      "    - cur_epsilon: 0.01619086228311062\n",
      "    - cur_epsilon: 0.013074264861643314\n",
      "    - cur_epsilon: 0.010557586327195168\n",
      "    - cur_epsilon: 0.008525344543159008\n",
      "    - cur_epsilon: 0.006884292233735323\n",
      "    - cur_epsilon: 0.005559127312153578\n",
      "    - cur_epsilon: 0.00448904512450099\n",
      "    - cur_epsilon: 0.003624943783506751\n",
      "    - cur_epsilon: 0.002927174558863044\n",
      "    - cur_epsilon: 0.0023637195117771626\n",
      "    - cur_epsilon: 0.0019087246619164944\n",
      "    - cur_epsilon: 0.0015413122018799186\n",
      "    - cur_epsilon: 0.0012446233304217458\n",
      "    - cur_epsilon: 0.0010050444398075342\n",
      "    - cur_epsilon: 0.0008115823729895055\n",
      "    - cur_epsilon: 0.0006553599960170686\n",
      "    last_target_update_ts: 19609920\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: 160.892822265625\n",
      "        mean_q: -60.25970458984375\n",
      "        mean_td_error: -3.074869155883789\n",
      "        min_q: -145.64053344726562\n",
      "        model: {}\n",
      "    learner_queue:\n",
      "      size_count: 6811\n",
      "      size_mean: 0.4\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 1.0\n",
      "      - 2.0\n",
      "      size_std: 0.5656854249492381\n",
      "    num_steps_sampled: 63000\n",
      "    num_steps_trained: 19612800\n",
      "    num_target_updates: 619\n",
      "    num_weight_syncs: 150\n",
      "    replay_shard_0:\n",
      "      add_batch_time_ms: 15.843\n",
      "      policy_default_policy:\n",
      "        added_count: 15750\n",
      "        est_size_bytes: 14112000\n",
      "        num_entries: 15750\n",
      "        sampled_count: 4904640\n",
      "      replay_time_ms: 859.257\n",
      "      update_priorities_time_ms: 1985.548\n",
      "  iterations_since_restore: 4\n",
      "  node_ip: 10.42.1.113\n",
      "  num_healthy_workers: 31\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 99.97538405267008\n",
      "    ram_util_percent: 39.50329188002926\n",
      "  pid: 2336\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf: {}\n",
      "  time_since_restore: 7922.817899227142\n",
      "  time_this_iter_s: 1927.7792823314667\n",
      "  time_total_s: 7922.817899227142\n",
      "  timers:\n",
      "    learner_dequeue_time_ms: 360.114\n",
      "    learner_grad_throughput: 8432.045\n",
      "    learner_grad_time_ms: 341.554\n",
      "    learner_overall_throughput: 4104.233\n",
      "    learner_overall_time_ms: 701.715\n",
      "  timestamp: 1619118815\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 63000\n",
      "  training_iteration: 4\n",
      "  trial_id: 40c8b_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 101.0/251.4 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 32/32 CPUs, 0/0 GPUs, 0.0/15.09 GiB heap, 0.0/5.18 GiB objects<br>Result logdir: /Raytest/Raytest/ray_results/experiment_apex6<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name      </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>APEX_40c8b_00000</td><td>RUNNING </td><td>10.42.1.113:2336</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         7922.82</td><td style=\"text-align: right;\">63000</td><td style=\"text-align: right;\">     nan</td><td style=\"text-align: right;\">                 nan</td><td style=\"text-align: right;\">                 nan</td><td style=\"text-align: right;\">               nan</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am in second callback. Got result: {}\n",
      "Result for APEX_40c8b_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-04-22_19-44-08\n",
      "  done: false\n",
      "  episode_len_mean: .nan\n",
      "  episode_reward_max: .nan\n",
      "  episode_reward_mean: .nan\n",
      "  episode_reward_min: .nan\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 0\n",
      "  experiment_id: d21118775ed24ec1819dd8ebeb7c9122\n",
      "  hostname: raytest3-644cc68dc4-mcsqh\n",
      "  info:\n",
      "    exploration_infos:\n",
      "    - cur_epsilon: 0.0\n",
      "    - cur_epsilon: 0.4000000059604645\n",
      "    - cur_epsilon: 0.3230035603046417\n",
      "    - cur_epsilon: 0.26082825660705566\n",
      "    - cur_epsilon: 0.21062114834785461\n",
      "    - cur_epsilon: 0.17007845640182495\n",
      "    - cur_epsilon: 0.13733987510204315\n",
      "    - cur_epsilon: 0.11090317368507385\n",
      "    - cur_epsilon: 0.0895553007721901\n",
      "    - cur_epsilon: 0.07231670618057251\n",
      "    - cur_epsilon: 0.058396387845277786\n",
      "    - cur_epsilon: 0.047155603766441345\n",
      "    - cur_epsilon: 0.03807856887578964\n",
      "    - cur_epsilon: 0.03074878640472889\n",
      "    - cur_epsilon: 0.024829918518662453\n",
      "    - cur_epsilon: 0.020050380378961563\n",
      "    - cur_epsilon: 0.01619086228311062\n",
      "    - cur_epsilon: 0.013074264861643314\n",
      "    - cur_epsilon: 0.010557586327195168\n",
      "    - cur_epsilon: 0.008525344543159008\n",
      "    - cur_epsilon: 0.006884292233735323\n",
      "    - cur_epsilon: 0.005559127312153578\n",
      "    - cur_epsilon: 0.00448904512450099\n",
      "    - cur_epsilon: 0.003624943783506751\n",
      "    - cur_epsilon: 0.002927174558863044\n",
      "    - cur_epsilon: 0.0023637195117771626\n",
      "    - cur_epsilon: 0.0019087246619164944\n",
      "    - cur_epsilon: 0.0015413122018799186\n",
      "    - cur_epsilon: 0.0012446233304217458\n",
      "    - cur_epsilon: 0.0010050444398075342\n",
      "    - cur_epsilon: 0.0008115823729895055\n",
      "    - cur_epsilon: 0.0006553599960170686\n",
      "    last_target_update_ts: 26896320\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: 186.74972534179688\n",
      "        mean_q: -66.71793365478516\n",
      "        mean_td_error: -3.426468849182129\n",
      "        min_q: -146.6907958984375\n",
      "        model: {}\n",
      "    learner_queue:\n",
      "      size_count: 9345\n",
      "      size_mean: 0.6\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 1.1000000000000014\n",
      "      - 3.0\n",
      "      size_std: 0.7211102550927979\n",
      "    num_steps_sampled: 74550\n",
      "    num_steps_trained: 26913600\n",
      "    num_target_updates: 849\n",
      "    num_weight_syncs: 176\n",
      "    replay_shard_0:\n",
      "      add_batch_time_ms: 24.336\n",
      "      policy_default_policy:\n",
      "        added_count: 18800\n",
      "        est_size_bytes: 16844800\n",
      "        num_entries: 18800\n",
      "        sampled_count: 6776640\n",
      "      replay_time_ms: 243.807\n",
      "      update_priorities_time_ms: 534.763\n",
      "  iterations_since_restore: 5\n",
      "  node_ip: 10.42.1.113\n",
      "  num_healthy_workers: 31\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 99.98651555897041\n",
      "    ram_util_percent: 39.887245485977715\n",
      "  pid: 2336\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf: {}\n",
      "  time_since_restore: 9755.566592216492\n",
      "  time_this_iter_s: 1832.7486929893494\n",
      "  time_total_s: 9755.566592216492\n",
      "  timers:\n",
      "    learner_dequeue_time_ms: 133.576\n",
      "    learner_grad_throughput: 23716.136\n",
      "    learner_grad_time_ms: 121.436\n",
      "    learner_overall_throughput: 11291.614\n",
      "    learner_overall_time_ms: 255.057\n",
      "  timestamp: 1619120648\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 74550\n",
      "  training_iteration: 5\n",
      "  trial_id: 40c8b_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 100.0/251.4 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 32/32 CPUs, 0/0 GPUs, 0.0/15.09 GiB heap, 0.0/5.18 GiB objects<br>Result logdir: /Raytest/Raytest/ray_results/experiment_apex6<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name      </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>APEX_40c8b_00000</td><td>RUNNING </td><td>10.42.1.113:2336</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         9755.57</td><td style=\"text-align: right;\">74550</td><td style=\"text-align: right;\">     nan</td><td style=\"text-align: right;\">                 nan</td><td style=\"text-align: right;\">                 nan</td><td style=\"text-align: right;\">               nan</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2327)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2327)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2327)\u001b[0m [0, -32619.000000000084]\n",
      "\u001b[2m\u001b[36m(pid=2330)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2330)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2330)\u001b[0m [0, -32399.699999999884]\n",
      "\u001b[2m\u001b[36m(pid=2334)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2334)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2334)\u001b[0m [0, -36127.58000000004]\n",
      "\u001b[2m\u001b[36m(pid=2320)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2320)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2320)\u001b[0m [0, -35179.10800000002]\n",
      "\u001b[2m\u001b[36m(pid=2332)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2332)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2332)\u001b[0m [0, -32142.135999999875]\n",
      "\u001b[2m\u001b[36m(pid=2289)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2289)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2289)\u001b[0m [0, -35655.32399999989]\n",
      "\u001b[2m\u001b[36m(pid=2285)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2285)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2288)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2288)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2285)\u001b[0m [0, -34190.85600000016]\n",
      "\u001b[2m\u001b[36m(pid=2288)\u001b[0m [0, -33656.53600000012]\n",
      "\u001b[2m\u001b[36m(pid=2282)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2282)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2282)\u001b[0m [0, -33344.976]\n",
      "\u001b[2m\u001b[36m(pid=2284)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2284)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2284)\u001b[0m [0, -36046.4520000001]\n",
      "\u001b[2m\u001b[36m(pid=2287)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2287)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2287)\u001b[0m [0, -33610.327999999994]\n",
      "\u001b[2m\u001b[36m(pid=2293)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2293)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2293)\u001b[0m [0, -34719.38000000016]\n",
      "I am in second callback. Got result: {}\n",
      "Result for APEX_40c8b_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-04-22_20-17-29\n",
      "  done: false\n",
      "  episode_len_mean: 2880.0\n",
      "  episode_reward_max: -34190.85600000016\n",
      "  episode_reward_mean: -35288.217000000026\n",
      "  episode_reward_min: -36127.58000000004\n",
      "  episodes_this_iter: 4\n",
      "  episodes_total: 4\n",
      "  experiment_id: d21118775ed24ec1819dd8ebeb7c9122\n",
      "  hostname: raytest3-644cc68dc4-mcsqh\n",
      "  info:\n",
      "    exploration_infos:\n",
      "    - cur_epsilon: 0.0\n",
      "    - cur_epsilon: 0.4000000059604645\n",
      "    - cur_epsilon: 0.3230035603046417\n",
      "    - cur_epsilon: 0.26082825660705566\n",
      "    - cur_epsilon: 0.21062114834785461\n",
      "    - cur_epsilon: 0.17007845640182495\n",
      "    - cur_epsilon: 0.13733987510204315\n",
      "    - cur_epsilon: 0.11090317368507385\n",
      "    - cur_epsilon: 0.0895553007721901\n",
      "    - cur_epsilon: 0.07231670618057251\n",
      "    - cur_epsilon: 0.058396387845277786\n",
      "    - cur_epsilon: 0.047155603766441345\n",
      "    - cur_epsilon: 0.03807856887578964\n",
      "    - cur_epsilon: 0.03074878640472889\n",
      "    - cur_epsilon: 0.024829918518662453\n",
      "    - cur_epsilon: 0.020050380378961563\n",
      "    - cur_epsilon: 0.01619086228311062\n",
      "    - cur_epsilon: 0.013074264861643314\n",
      "    - cur_epsilon: 0.010557586327195168\n",
      "    - cur_epsilon: 0.008525344543159008\n",
      "    - cur_epsilon: 0.006884292233735323\n",
      "    - cur_epsilon: 0.005559127312153578\n",
      "    - cur_epsilon: 0.00448904512450099\n",
      "    - cur_epsilon: 0.003624943783506751\n",
      "    - cur_epsilon: 0.002927174558863044\n",
      "    - cur_epsilon: 0.0023637195117771626\n",
      "    - cur_epsilon: 0.0019087246619164944\n",
      "    - cur_epsilon: 0.0015413122018799186\n",
      "    - cur_epsilon: 0.0012446233304217458\n",
      "    - cur_epsilon: 0.0010050444398075342\n",
      "    - cur_epsilon: 0.0008115823729895055\n",
      "    - cur_epsilon: 0.0006553599960170686\n",
      "    last_target_update_ts: 34467840\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: 177.60118103027344\n",
      "        mean_q: -66.1719970703125\n",
      "        mean_td_error: -2.5271267890930176\n",
      "        min_q: -152.144287109375\n",
      "        model: {}\n",
      "    learner_queue:\n",
      "      size_count: 11970\n",
      "      size_mean: 0.3\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 1.0\n",
      "      - 1.0\n",
      "      size_std: 0.458257569495584\n",
      "    num_steps_sampled: 86150\n",
      "    num_steps_trained: 34470720\n",
      "    num_target_updates: 1088\n",
      "    num_weight_syncs: 198\n",
      "    replay_shard_0:\n",
      "      add_batch_time_ms: 17.624\n",
      "      policy_default_policy:\n",
      "        added_count: 21400\n",
      "        est_size_bytes: 19174400\n",
      "        num_entries: 21400\n",
      "        sampled_count: 8683200\n",
      "      replay_time_ms: 713.729\n",
      "      update_priorities_time_ms: 1365.291\n",
      "  iterations_since_restore: 6\n",
      "  node_ip: 10.42.1.113\n",
      "  num_healthy_workers: 31\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 99.98988367994362\n",
      "    ram_util_percent: 40.40927035600987\n",
      "  pid: 2336\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.22489904726211168\n",
      "    mean_env_wait_ms: 3788.4633824571683\n",
      "    mean_inference_ms: 7.0364026344719335\n",
      "    mean_raw_obs_processing_ms: 2.147075919538027\n",
      "  time_since_restore: 11756.591999292374\n",
      "  time_this_iter_s: 2001.025407075882\n",
      "  time_total_s: 11756.591999292374\n",
      "  timers:\n",
      "    learner_dequeue_time_ms: 350.971\n",
      "    learner_grad_throughput: 13494.434\n",
      "    learner_grad_time_ms: 213.421\n",
      "    learner_overall_throughput: 5102.405\n",
      "    learner_overall_time_ms: 564.44\n",
      "  timestamp: 1619122649\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 86150\n",
      "  training_iteration: 6\n",
      "  trial_id: 40c8b_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 101.5/251.4 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 32/32 CPUs, 0/0 GPUs, 0.0/15.09 GiB heap, 0.0/5.18 GiB objects<br>Result logdir: /Raytest/Raytest/ray_results/experiment_apex6<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name      </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>APEX_40c8b_00000</td><td>RUNNING </td><td>10.42.1.113:2336</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         11756.6</td><td style=\"text-align: right;\">86150</td><td style=\"text-align: right;\">-35288.2</td><td style=\"text-align: right;\">            -34190.9</td><td style=\"text-align: right;\">            -36127.6</td><td style=\"text-align: right;\">              2880</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2298)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2298)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2298)\u001b[0m [0, -32108.683999999947]\n",
      "\u001b[2m\u001b[36m(pid=2286)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2286)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2286)\u001b[0m [0, -35142.13599999992]\n",
      "\u001b[2m\u001b[36m(pid=2295)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2295)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2300)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2300)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2295)\u001b[0m [0, -32016.084]\n",
      "\u001b[2m\u001b[36m(pid=2300)\u001b[0m [0, -32197.943999999992]\n",
      "\u001b[2m\u001b[36m(pid=2281)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2281)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2281)\u001b[0m [0, -37499.47199999996]\n",
      "\u001b[2m\u001b[36m(pid=2310)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2296)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2296)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2310)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2292)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2292)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2296)\u001b[0m [0, -32732.987999999987]\n",
      "\u001b[2m\u001b[36m(pid=2314)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2318)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2318)\u001b[0m Loading configuration ... \n",
      "\u001b[2m\u001b[36m(pid=2314)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2318)\u001b[0m done.\n",
      "\u001b[2m\u001b[36m(pid=2292)\u001b[0m [0, -36141.031999999934]\n",
      "\u001b[2m\u001b[36m(pid=2310)\u001b[0m [0, -31777.859999999968]\n",
      "\u001b[2m\u001b[36m(pid=2318)\u001b[0m [0, -33839.92400000001]\n",
      "\u001b[2m\u001b[36m(pid=2314)\u001b[0m [0, -33841.65599999999]\n",
      "\u001b[2m\u001b[36m(pid=2308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2308)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2308)\u001b[0m [0, -37665.248000000014]\n",
      "\u001b[2m\u001b[36m(pid=2301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2301)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2301)\u001b[0m [0, -36976.89600000002]\n",
      "\u001b[2m\u001b[36m(pid=2305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2305)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2305)\u001b[0m [0, -35051.15999999992]\n",
      "\u001b[2m\u001b[36m(pid=2283)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2283)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2283)\u001b[0m [0, -38095.69200000007]\n",
      "\u001b[2m\u001b[36m(pid=2290)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2290)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2290)\u001b[0m [0, -37412.03999999967]\n",
      "\u001b[2m\u001b[36m(pid=2299)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2299)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2280)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2280)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2280)\u001b[0m [0, -36657.05200000004]\n",
      "\u001b[2m\u001b[36m(pid=2299)\u001b[0m [0, -38824.871999999894]\n",
      "\u001b[2m\u001b[36m(pid=2313)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2313)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2313)\u001b[0m [0, -37938.45199999979]\n",
      "\u001b[2m\u001b[36m(pid=2294)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2294)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2294)\u001b[0m [0, -38233.66800000016]\n",
      "I am in second callback. Got result: {}\n",
      "Result for APEX_40c8b_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-04-22_20-32-03\n",
      "  done: false\n",
      "  episode_len_mean: 2880.0\n",
      "  episode_reward_max: -34190.85600000016\n",
      "  episode_reward_mean: -36233.83249999996\n",
      "  episode_reward_min: -37665.248000000014\n",
      "  episodes_this_iter: 4\n",
      "  episodes_total: 8\n",
      "  experiment_id: d21118775ed24ec1819dd8ebeb7c9122\n",
      "  hostname: raytest3-644cc68dc4-mcsqh\n",
      "  info:\n",
      "    exploration_infos:\n",
      "    - cur_epsilon: 0.0\n",
      "    - cur_epsilon: 0.4000000059604645\n",
      "    - cur_epsilon: 0.3230035603046417\n",
      "    - cur_epsilon: 0.26082825660705566\n",
      "    - cur_epsilon: 0.21062114834785461\n",
      "    - cur_epsilon: 0.17007845640182495\n",
      "    - cur_epsilon: 0.13733987510204315\n",
      "    - cur_epsilon: 0.11090317368507385\n",
      "    - cur_epsilon: 0.0895553007721901\n",
      "    - cur_epsilon: 0.07231670618057251\n",
      "    - cur_epsilon: 0.058396387845277786\n",
      "    - cur_epsilon: 0.047155603766441345\n",
      "    - cur_epsilon: 0.03807856887578964\n",
      "    - cur_epsilon: 0.03074878640472889\n",
      "    - cur_epsilon: 0.024829918518662453\n",
      "    - cur_epsilon: 0.020050380378961563\n",
      "    - cur_epsilon: 0.01619086228311062\n",
      "    - cur_epsilon: 0.013074264861643314\n",
      "    - cur_epsilon: 0.010557586327195168\n",
      "    - cur_epsilon: 0.008525344543159008\n",
      "    - cur_epsilon: 0.006884292233735323\n",
      "    - cur_epsilon: 0.005559127312153578\n",
      "    - cur_epsilon: 0.00448904512450099\n",
      "    - cur_epsilon: 0.003624943783506751\n",
      "    - cur_epsilon: 0.002927174558863044\n",
      "    - cur_epsilon: 0.0023637195117771626\n",
      "    - cur_epsilon: 0.0019087246619164944\n",
      "    - cur_epsilon: 0.0015413122018799186\n",
      "    - cur_epsilon: 0.0012446233304217458\n",
      "    - cur_epsilon: 0.0010050444398075342\n",
      "    - cur_epsilon: 0.0008115823729895055\n",
      "    - cur_epsilon: 0.0006553599960170686\n",
      "    last_target_update_ts: 37509120\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: 177.99496459960938\n",
      "        mean_q: -52.44217300415039\n",
      "        mean_td_error: -3.190598964691162\n",
      "        min_q: -153.81198120117188\n",
      "        model: {}\n",
      "    learner_queue:\n",
      "      size_count: 13031\n",
      "      size_mean: 0.26\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 1.0\n",
      "      - 1.0\n",
      "      size_std: 0.4386342439892262\n",
      "    num_steps_sampled: 97700\n",
      "    num_steps_trained: 37526400\n",
      "    num_target_updates: 1184\n",
      "    num_weight_syncs: 233\n",
      "    replay_shard_0:\n",
      "      add_batch_time_ms: 22.74\n",
      "      policy_default_policy:\n",
      "        added_count: 24550\n",
      "        est_size_bytes: 21996800\n",
      "        num_entries: 24550\n",
      "        sampled_count: 9437760\n",
      "      replay_time_ms: 950.722\n",
      "      update_priorities_time_ms: 2009.693\n",
      "  iterations_since_restore: 7\n",
      "  node_ip: 10.42.1.113\n",
      "  num_healthy_workers: 31\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 99.96158192090395\n",
      "    ram_util_percent: 39.90258272800646\n",
      "  pid: 2336\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.22376665620574537\n",
      "    mean_env_wait_ms: 3763.9833217791256\n",
      "    mean_inference_ms: 7.102463672348556\n",
      "    mean_raw_obs_processing_ms: 2.143142420895625\n",
      "  time_since_restore: 12630.459682703018\n",
      "  time_this_iter_s: 873.8676834106445\n",
      "  time_total_s: 12630.459682703018\n",
      "  timers:\n",
      "    learner_dequeue_time_ms: 439.736\n",
      "    learner_grad_throughput: 8649.723\n",
      "    learner_grad_time_ms: 332.959\n",
      "    learner_overall_throughput: 3726.988\n",
      "    learner_overall_time_ms: 772.742\n",
      "  timestamp: 1619123523\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 97700\n",
      "  training_iteration: 7\n",
      "  trial_id: 40c8b_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 97.9/251.4 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 32/32 CPUs, 0/0 GPUs, 0.0/15.09 GiB heap, 0.0/5.18 GiB objects<br>Result logdir: /Raytest/Raytest/ray_results/experiment_apex6<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name      </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>APEX_40c8b_00000</td><td>RUNNING </td><td>10.42.1.113:2336</td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">         12630.5</td><td style=\"text-align: right;\">97700</td><td style=\"text-align: right;\">-36233.8</td><td style=\"text-align: right;\">            -34190.9</td><td style=\"text-align: right;\">            -37665.2</td><td style=\"text-align: right;\">              2880</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am in second callback. Got result: {}\n",
      "Result for APEX_40c8b_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-04-22_20-46-00\n",
      "  done: false\n",
      "  episode_len_mean: 2880.0\n",
      "  episode_reward_max: -34190.85600000016\n",
      "  episode_reward_mean: -36806.15018181814\n",
      "  episode_reward_min: -38824.871999999894\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 11\n",
      "  experiment_id: d21118775ed24ec1819dd8ebeb7c9122\n",
      "  hostname: raytest3-644cc68dc4-mcsqh\n",
      "  info:\n",
      "    exploration_infos:\n",
      "    - cur_epsilon: 0.0\n",
      "    - cur_epsilon: 0.4000000059604645\n",
      "    - cur_epsilon: 0.3230035603046417\n",
      "    - cur_epsilon: 0.26082825660705566\n",
      "    - cur_epsilon: 0.21062114834785461\n",
      "    - cur_epsilon: 0.17007845640182495\n",
      "    - cur_epsilon: 0.13733987510204315\n",
      "    - cur_epsilon: 0.11090317368507385\n",
      "    - cur_epsilon: 0.0895553007721901\n",
      "    - cur_epsilon: 0.07231670618057251\n",
      "    - cur_epsilon: 0.058396387845277786\n",
      "    - cur_epsilon: 0.047155603766441345\n",
      "    - cur_epsilon: 0.03807856887578964\n",
      "    - cur_epsilon: 0.03074878640472889\n",
      "    - cur_epsilon: 0.024829918518662453\n",
      "    - cur_epsilon: 0.020050380378961563\n",
      "    - cur_epsilon: 0.01619086228311062\n",
      "    - cur_epsilon: 0.013074264861643314\n",
      "    - cur_epsilon: 0.010557586327195168\n",
      "    - cur_epsilon: 0.008525344543159008\n",
      "    - cur_epsilon: 0.006884292233735323\n",
      "    - cur_epsilon: 0.005559127312153578\n",
      "    - cur_epsilon: 0.00448904512450099\n",
      "    - cur_epsilon: 0.003624943783506751\n",
      "    - cur_epsilon: 0.002927174558863044\n",
      "    - cur_epsilon: 0.0023637195117771626\n",
      "    - cur_epsilon: 0.0019087246619164944\n",
      "    - cur_epsilon: 0.0015413122018799186\n",
      "    - cur_epsilon: 0.0012446233304217458\n",
      "    - cur_epsilon: 0.0010050444398075342\n",
      "    - cur_epsilon: 0.0008115823729895055\n",
      "    - cur_epsilon: 0.0006553599960170686\n",
      "    last_target_update_ts: 41152320\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: 214.6812286376953\n",
      "        mean_q: -69.18675994873047\n",
      "        mean_td_error: -3.310293674468994\n",
      "        min_q: -152.18862915039062\n",
      "        model: {}\n",
      "    learner_queue:\n",
      "      size_count: 14293\n",
      "      size_mean: 0.28\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 1.0\n",
      "      - 2.0\n",
      "      size_std: 0.4915282290977803\n",
      "    num_steps_sampled: 109250\n",
      "    num_steps_trained: 41160960\n",
      "    num_target_updates: 1299\n",
      "    num_weight_syncs: 260\n",
      "    replay_shard_0:\n",
      "      add_batch_time_ms: 13.422\n",
      "      policy_default_policy:\n",
      "        added_count: 28050\n",
      "        est_size_bytes: 22400000\n",
      "        num_entries: 25000\n",
      "        sampled_count: 10342080\n",
      "      replay_time_ms: 1077.107\n",
      "      update_priorities_time_ms: 1863.489\n",
      "  iterations_since_restore: 8\n",
      "  node_ip: 10.42.1.113\n",
      "  num_healthy_workers: 31\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 99.94882352941177\n",
      "    ram_util_percent: 38.82050420168067\n",
      "  pid: 2336\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.22079250720164564\n",
      "    mean_env_wait_ms: 3850.2920529126086\n",
      "    mean_inference_ms: 7.130592863299068\n",
      "    mean_raw_obs_processing_ms: 2.3237147166273395\n",
      "  time_since_restore: 13467.221982479095\n",
      "  time_this_iter_s: 836.7622997760773\n",
      "  time_total_s: 13467.221982479095\n",
      "  timers:\n",
      "    learner_dequeue_time_ms: 506.641\n",
      "    learner_grad_throughput: 11156.945\n",
      "    learner_grad_time_ms: 258.135\n",
      "    learner_overall_throughput: 3765.568\n",
      "    learner_overall_time_ms: 764.825\n",
      "  timestamp: 1619124360\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 109250\n",
      "  training_iteration: 8\n",
      "  trial_id: 40c8b_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 97.7/251.4 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 32/32 CPUs, 0/0 GPUs, 0.0/15.09 GiB heap, 0.0/5.18 GiB objects<br>Result logdir: /Raytest/Raytest/ray_results/experiment_apex6<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name      </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>APEX_40c8b_00000</td><td>RUNNING </td><td>10.42.1.113:2336</td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         13467.2</td><td style=\"text-align: right;\">109250</td><td style=\"text-align: right;\">-36806.2</td><td style=\"text-align: right;\">            -34190.9</td><td style=\"text-align: right;\">            -38824.9</td><td style=\"text-align: right;\">              2880</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am in second callback. Got result: {}\n",
      "Result for APEX_40c8b_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-04-22_21-09-22\n",
      "  done: false\n",
      "  episode_len_mean: 2880.0\n",
      "  episode_reward_max: -34190.85600000016\n",
      "  episode_reward_mean: -36806.15018181814\n",
      "  episode_reward_min: -38824.871999999894\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 11\n",
      "  experiment_id: d21118775ed24ec1819dd8ebeb7c9122\n",
      "  hostname: raytest3-644cc68dc4-mcsqh\n",
      "  info:\n",
      "    exploration_infos:\n",
      "    - cur_epsilon: 0.0\n",
      "    - cur_epsilon: 0.4000000059604645\n",
      "    - cur_epsilon: 0.3230035603046417\n",
      "    - cur_epsilon: 0.26082825660705566\n",
      "    - cur_epsilon: 0.21062114834785461\n",
      "    - cur_epsilon: 0.17007845640182495\n",
      "    - cur_epsilon: 0.13733987510204315\n",
      "    - cur_epsilon: 0.11090317368507385\n",
      "    - cur_epsilon: 0.0895553007721901\n",
      "    - cur_epsilon: 0.07231670618057251\n",
      "    - cur_epsilon: 0.058396387845277786\n",
      "    - cur_epsilon: 0.047155603766441345\n",
      "    - cur_epsilon: 0.03807856887578964\n",
      "    - cur_epsilon: 0.03074878640472889\n",
      "    - cur_epsilon: 0.024829918518662453\n",
      "    - cur_epsilon: 0.020050380378961563\n",
      "    - cur_epsilon: 0.01619086228311062\n",
      "    - cur_epsilon: 0.013074264861643314\n",
      "    - cur_epsilon: 0.010557586327195168\n",
      "    - cur_epsilon: 0.008525344543159008\n",
      "    - cur_epsilon: 0.006884292233735323\n",
      "    - cur_epsilon: 0.005559127312153578\n",
      "    - cur_epsilon: 0.00448904512450099\n",
      "    - cur_epsilon: 0.003624943783506751\n",
      "    - cur_epsilon: 0.002927174558863044\n",
      "    - cur_epsilon: 0.0023637195117771626\n",
      "    - cur_epsilon: 0.0019087246619164944\n",
      "    - cur_epsilon: 0.0015413122018799186\n",
      "    - cur_epsilon: 0.0012446233304217458\n",
      "    - cur_epsilon: 0.0010050444398075342\n",
      "    - cur_epsilon: 0.0008115823729895055\n",
      "    - cur_epsilon: 0.0006553599960170686\n",
      "    last_target_update_ts: 46157760\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: 213.48309326171875\n",
      "        mean_q: -66.81832885742188\n",
      "        mean_td_error: -4.52613639831543\n",
      "        min_q: -151.82730102539062\n",
      "        model: {}\n",
      "    learner_queue:\n",
      "      size_count: 16035\n",
      "      size_mean: 0.32\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 1.0\n",
      "      - 2.0\n",
      "      size_std: 0.5075431016179808\n",
      "    num_steps_sampled: 120800\n",
      "    num_steps_trained: 46180800\n",
      "    num_target_updates: 1457\n",
      "    num_weight_syncs: 287\n",
      "    replay_shard_0:\n",
      "      add_batch_time_ms: 23.147\n",
      "      policy_default_policy:\n",
      "        added_count: 30850\n",
      "        est_size_bytes: 22400000\n",
      "        num_entries: 25000\n",
      "        sampled_count: 11606400\n",
      "      replay_time_ms: 1256.74\n",
      "      update_priorities_time_ms: 2728.799\n",
      "  iterations_since_restore: 9\n",
      "  node_ip: 10.42.1.113\n",
      "  num_healthy_workers: 31\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 99.98564977420973\n",
      "    ram_util_percent: 39.33442047165078\n",
      "  pid: 2336\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.22079250720164564\n",
      "    mean_env_wait_ms: 3850.2920529126077\n",
      "    mean_inference_ms: 7.130592863299069\n",
      "    mean_raw_obs_processing_ms: 2.3237147166273395\n",
      "  time_since_restore: 14869.600170850754\n",
      "  time_this_iter_s: 1402.3781883716583\n",
      "  time_total_s: 14869.600170850754\n",
      "  timers:\n",
      "    learner_dequeue_time_ms: 644.189\n",
      "    learner_grad_throughput: 9379.298\n",
      "    learner_grad_time_ms: 307.059\n",
      "    learner_overall_throughput: 3027.451\n",
      "    learner_overall_time_ms: 951.295\n",
      "  timestamp: 1619125762\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 120800\n",
      "  training_iteration: 9\n",
      "  trial_id: 40c8b_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 98.2/251.4 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 32/32 CPUs, 0/0 GPUs, 0.0/15.09 GiB heap, 0.0/5.18 GiB objects<br>Result logdir: /Raytest/Raytest/ray_results/experiment_apex6<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name      </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>APEX_40c8b_00000</td><td>RUNNING </td><td>10.42.1.113:2336</td><td style=\"text-align: right;\">     9</td><td style=\"text-align: right;\">         14869.6</td><td style=\"text-align: right;\">120800</td><td style=\"text-align: right;\">-36806.2</td><td style=\"text-align: right;\">            -34190.9</td><td style=\"text-align: right;\">            -38824.9</td><td style=\"text-align: right;\">              2880</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am in second callback. Got result: {}\n",
      "Result for APEX_40c8b_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-04-22_21-37-00\n",
      "  done: false\n",
      "  episode_len_mean: 2880.0\n",
      "  episode_reward_max: -34190.85600000016\n",
      "  episode_reward_mean: -36806.15018181814\n",
      "  episode_reward_min: -38824.871999999894\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 11\n",
      "  experiment_id: d21118775ed24ec1819dd8ebeb7c9122\n",
      "  hostname: raytest3-644cc68dc4-mcsqh\n",
      "  info:\n",
      "    exploration_infos:\n",
      "    - cur_epsilon: 0.0\n",
      "    - cur_epsilon: 0.4000000059604645\n",
      "    - cur_epsilon: 0.3230035603046417\n",
      "    - cur_epsilon: 0.26082825660705566\n",
      "    - cur_epsilon: 0.21062114834785461\n",
      "    - cur_epsilon: 0.17007845640182495\n",
      "    - cur_epsilon: 0.13733987510204315\n",
      "    - cur_epsilon: 0.11090317368507385\n",
      "    - cur_epsilon: 0.0895553007721901\n",
      "    - cur_epsilon: 0.07231670618057251\n",
      "    - cur_epsilon: 0.058396387845277786\n",
      "    - cur_epsilon: 0.047155603766441345\n",
      "    - cur_epsilon: 0.03807856887578964\n",
      "    - cur_epsilon: 0.03074878640472889\n",
      "    - cur_epsilon: 0.024829918518662453\n",
      "    - cur_epsilon: 0.020050380378961563\n",
      "    - cur_epsilon: 0.01619086228311062\n",
      "    - cur_epsilon: 0.013074264861643314\n",
      "    - cur_epsilon: 0.010557586327195168\n",
      "    - cur_epsilon: 0.008525344543159008\n",
      "    - cur_epsilon: 0.006884292233735323\n",
      "    - cur_epsilon: 0.005559127312153578\n",
      "    - cur_epsilon: 0.00448904512450099\n",
      "    - cur_epsilon: 0.003624943783506751\n",
      "    - cur_epsilon: 0.002927174558863044\n",
      "    - cur_epsilon: 0.0023637195117771626\n",
      "    - cur_epsilon: 0.0019087246619164944\n",
      "    - cur_epsilon: 0.0015413122018799186\n",
      "    - cur_epsilon: 0.0012446233304217458\n",
      "    - cur_epsilon: 0.0010050444398075342\n",
      "    - cur_epsilon: 0.0008115823729895055\n",
      "    - cur_epsilon: 0.0006553599960170686\n",
      "    last_target_update_ts: 51860160\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: 229.23390197753906\n",
      "        mean_q: -66.2193374633789\n",
      "        mean_td_error: -3.3612608909606934\n",
      "        min_q: -149.9809112548828\n",
      "        model: {}\n",
      "    learner_queue:\n",
      "      size_count: 18018\n",
      "      size_mean: 0.28\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 1.0\n",
      "      - 2.0\n",
      "      size_std: 0.530659966456864\n",
      "    num_steps_sampled: 132350\n",
      "    num_steps_trained: 51888960\n",
      "    num_target_updates: 1637\n",
      "    num_weight_syncs: 316\n",
      "    replay_shard_0:\n",
      "      add_batch_time_ms: 24.209\n",
      "      policy_default_policy:\n",
      "        added_count: 33800\n",
      "        est_size_bytes: 22400000\n",
      "        num_entries: 25000\n",
      "        sampled_count: 13069440\n",
      "      replay_time_ms: 354.506\n",
      "      update_priorities_time_ms: 705.937\n",
      "  iterations_since_restore: 10\n",
      "  node_ip: 10.42.1.113\n",
      "  num_healthy_workers: 31\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 99.99379779099407\n",
      "    ram_util_percent: 39.668096856414614\n",
      "  pid: 2336\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.22079250720164564\n",
      "    mean_env_wait_ms: 3850.2920529126077\n",
      "    mean_inference_ms: 7.130592863299069\n",
      "    mean_raw_obs_processing_ms: 2.3237147166273395\n",
      "  time_since_restore: 16527.706469535828\n",
      "  time_this_iter_s: 1658.1062986850739\n",
      "  time_total_s: 16527.706469535828\n",
      "  timers:\n",
      "    learner_dequeue_time_ms: 155.327\n",
      "    learner_grad_throughput: 26698.85\n",
      "    learner_grad_time_ms: 107.87\n",
      "    learner_overall_throughput: 10940.462\n",
      "    learner_overall_time_ms: 263.243\n",
      "  timestamp: 1619127420\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 132350\n",
      "  training_iteration: 10\n",
      "  trial_id: 40c8b_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-22 21:37:01,512\tWARNING util.py:151 -- Checkpointing the experiment state took 0.680 s, which may be a performance bottleneck. Please ensure the `TUNE_GLOBAL_CHECKPOINT_S` environment variable is something significantly higher than this duration to ensure compute time is mostly spent on the main training loop.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 99.8/251.4 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 32/32 CPUs, 0/0 GPUs, 0.0/15.09 GiB heap, 0.0/5.18 GiB objects<br>Result logdir: /Raytest/Raytest/ray_results/experiment_apex6<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name      </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>APEX_40c8b_00000</td><td>RUNNING </td><td>10.42.1.113:2336</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         16527.7</td><td style=\"text-align: right;\">132350</td><td style=\"text-align: right;\">-36806.2</td><td style=\"text-align: right;\">            -34190.9</td><td style=\"text-align: right;\">            -38824.9</td><td style=\"text-align: right;\">              2880</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am in second callback. Got result: {}\n",
      "Result for APEX_40c8b_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-04-22_22-02-49\n",
      "  done: false\n",
      "  episode_len_mean: 2880.0\n",
      "  episode_reward_max: -34190.85600000016\n",
      "  episode_reward_mean: -36806.15018181814\n",
      "  episode_reward_min: -38824.871999999894\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 11\n",
      "  experiment_id: d21118775ed24ec1819dd8ebeb7c9122\n",
      "  hostname: raytest3-644cc68dc4-mcsqh\n",
      "  info:\n",
      "    exploration_infos:\n",
      "    - cur_epsilon: 0.0\n",
      "    - cur_epsilon: 0.4000000059604645\n",
      "    - cur_epsilon: 0.3230035603046417\n",
      "    - cur_epsilon: 0.26082825660705566\n",
      "    - cur_epsilon: 0.21062114834785461\n",
      "    - cur_epsilon: 0.17007845640182495\n",
      "    - cur_epsilon: 0.13733987510204315\n",
      "    - cur_epsilon: 0.11090317368507385\n",
      "    - cur_epsilon: 0.0895553007721901\n",
      "    - cur_epsilon: 0.07231670618057251\n",
      "    - cur_epsilon: 0.058396387845277786\n",
      "    - cur_epsilon: 0.047155603766441345\n",
      "    - cur_epsilon: 0.03807856887578964\n",
      "    - cur_epsilon: 0.03074878640472889\n",
      "    - cur_epsilon: 0.024829918518662453\n",
      "    - cur_epsilon: 0.020050380378961563\n",
      "    - cur_epsilon: 0.01619086228311062\n",
      "    - cur_epsilon: 0.013074264861643314\n",
      "    - cur_epsilon: 0.010557586327195168\n",
      "    - cur_epsilon: 0.008525344543159008\n",
      "    - cur_epsilon: 0.006884292233735323\n",
      "    - cur_epsilon: 0.005559127312153578\n",
      "    - cur_epsilon: 0.00448904512450099\n",
      "    - cur_epsilon: 0.003624943783506751\n",
      "    - cur_epsilon: 0.002927174558863044\n",
      "    - cur_epsilon: 0.0023637195117771626\n",
      "    - cur_epsilon: 0.0019087246619164944\n",
      "    - cur_epsilon: 0.0015413122018799186\n",
      "    - cur_epsilon: 0.0012446233304217458\n",
      "    - cur_epsilon: 0.0010050444398075342\n",
      "    - cur_epsilon: 0.0008115823729895055\n",
      "    - cur_epsilon: 0.0006553599960170686\n",
      "    last_target_update_ts: 58227840\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: 198.62554931640625\n",
      "        mean_q: -74.30974578857422\n",
      "        mean_td_error: -5.039217472076416\n",
      "        min_q: -150.5517578125\n",
      "        model: {}\n",
      "    learner_queue:\n",
      "      size_count: 20220\n",
      "      size_mean: 0.3\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 1.0\n",
      "      - 2.0\n",
      "      size_std: 0.49999999999999994\n",
      "    num_steps_sampled: 143900\n",
      "    num_steps_trained: 58233600\n",
      "    num_target_updates: 1838\n",
      "    num_weight_syncs: 345\n",
      "    replay_shard_0:\n",
      "      add_batch_time_ms: 16.282\n",
      "      policy_default_policy:\n",
      "        added_count: 36700\n",
      "        est_size_bytes: 22400000\n",
      "        num_entries: 25000\n",
      "        sampled_count: 14662080\n",
      "      replay_time_ms: 907.556\n",
      "      update_priorities_time_ms: 2094.894\n",
      "  iterations_since_restore: 11\n",
      "  node_ip: 10.42.1.113\n",
      "  num_healthy_workers: 31\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 99.98293903548681\n",
      "    ram_util_percent: 39.544540491355775\n",
      "  pid: 2336\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.22079250720164564\n",
      "    mean_env_wait_ms: 3850.2920529126077\n",
      "    mean_inference_ms: 7.130592863299069\n",
      "    mean_raw_obs_processing_ms: 2.3237147166273395\n",
      "  time_since_restore: 18076.066523075104\n",
      "  time_this_iter_s: 1548.3600535392761\n",
      "  time_total_s: 18076.066523075104\n",
      "  timers:\n",
      "    learner_dequeue_time_ms: 655.968\n",
      "    learner_grad_throughput: 9084.253\n",
      "    learner_grad_time_ms: 317.032\n",
      "    learner_overall_throughput: 2959.781\n",
      "    learner_overall_time_ms: 973.045\n",
      "  timestamp: 1619128969\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 143900\n",
      "  training_iteration: 11\n",
      "  trial_id: 40c8b_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 100.9/251.4 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 32/32 CPUs, 0/0 GPUs, 0.0/15.09 GiB heap, 0.0/5.18 GiB objects<br>Result logdir: /Raytest/Raytest/ray_results/experiment_apex6<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name      </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>APEX_40c8b_00000</td><td>RUNNING </td><td>10.42.1.113:2336</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         18076.1</td><td style=\"text-align: right;\">143900</td><td style=\"text-align: right;\">-36806.2</td><td style=\"text-align: right;\">            -34190.9</td><td style=\"text-align: right;\">            -38824.9</td><td style=\"text-align: right;\">              2880</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am in second callback. Got result: {}\n",
      "Result for APEX_40c8b_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-04-22_22-36-32\n",
      "  done: false\n",
      "  episode_len_mean: 2880.0\n",
      "  episode_reward_max: -34190.85600000016\n",
      "  episode_reward_mean: -36806.15018181814\n",
      "  episode_reward_min: -38824.871999999894\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 11\n",
      "  experiment_id: d21118775ed24ec1819dd8ebeb7c9122\n",
      "  hostname: raytest3-644cc68dc4-mcsqh\n",
      "  info:\n",
      "    exploration_infos:\n",
      "    - cur_epsilon: 0.0\n",
      "    - cur_epsilon: 0.4000000059604645\n",
      "    - cur_epsilon: 0.3230035603046417\n",
      "    - cur_epsilon: 0.26082825660705566\n",
      "    - cur_epsilon: 0.21062114834785461\n",
      "    - cur_epsilon: 0.17007845640182495\n",
      "    - cur_epsilon: 0.13733987510204315\n",
      "    - cur_epsilon: 0.11090317368507385\n",
      "    - cur_epsilon: 0.0895553007721901\n",
      "    - cur_epsilon: 0.07231670618057251\n",
      "    - cur_epsilon: 0.058396387845277786\n",
      "    - cur_epsilon: 0.047155603766441345\n",
      "    - cur_epsilon: 0.03807856887578964\n",
      "    - cur_epsilon: 0.03074878640472889\n",
      "    - cur_epsilon: 0.024829918518662453\n",
      "    - cur_epsilon: 0.020050380378961563\n",
      "    - cur_epsilon: 0.01619086228311062\n",
      "    - cur_epsilon: 0.013074264861643314\n",
      "    - cur_epsilon: 0.010557586327195168\n",
      "    - cur_epsilon: 0.008525344543159008\n",
      "    - cur_epsilon: 0.006884292233735323\n",
      "    - cur_epsilon: 0.005559127312153578\n",
      "    - cur_epsilon: 0.00448904512450099\n",
      "    - cur_epsilon: 0.003624943783506751\n",
      "    - cur_epsilon: 0.002927174558863044\n",
      "    - cur_epsilon: 0.0023637195117771626\n",
      "    - cur_epsilon: 0.0019087246619164944\n",
      "    - cur_epsilon: 0.0015413122018799186\n",
      "    - cur_epsilon: 0.0012446233304217458\n",
      "    - cur_epsilon: 0.0010050444398075342\n",
      "    - cur_epsilon: 0.0008115823729895055\n",
      "    - cur_epsilon: 0.0006553599960170686\n",
      "    last_target_update_ts: 65039040\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: 231.17800903320312\n",
      "        mean_q: -75.8599853515625\n",
      "        mean_td_error: -4.5289387702941895\n",
      "        min_q: -150.6603546142578\n",
      "        model: {}\n",
      "    learner_queue:\n",
      "      size_count: 22589\n",
      "      size_mean: 0.16\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 1.0\n",
      "      - 1.0\n",
      "      size_std: 0.36660605559646714\n",
      "    num_steps_sampled: 155450\n",
      "    num_steps_trained: 65056320\n",
      "    num_target_updates: 2053\n",
      "    num_weight_syncs: 374\n",
      "    replay_shard_0:\n",
      "      add_batch_time_ms: 31.933\n",
      "      policy_default_policy:\n",
      "        added_count: 39200\n",
      "        est_size_bytes: 22400000\n",
      "        num_entries: 25000\n",
      "        sampled_count: 16349760\n",
      "      replay_time_ms: 508.422\n",
      "      update_priorities_time_ms: 1029.562\n",
      "  iterations_since_restore: 12\n",
      "  node_ip: 10.42.1.113\n",
      "  num_healthy_workers: 31\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 99.99467270194984\n",
      "    ram_util_percent: 40.84853760445682\n",
      "  pid: 2336\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.22079250720164564\n",
      "    mean_env_wait_ms: 3850.2920529126077\n",
      "    mean_inference_ms: 7.130592863299069\n",
      "    mean_raw_obs_processing_ms: 2.3237147166273395\n",
      "  time_since_restore: 20099.11221075058\n",
      "  time_this_iter_s: 2023.045687675476\n",
      "  time_total_s: 20099.11221075058\n",
      "  timers:\n",
      "    learner_dequeue_time_ms: 243.527\n",
      "    learner_grad_throughput: 22895.888\n",
      "    learner_grad_time_ms: 125.787\n",
      "    learner_overall_throughput: 7797.234\n",
      "    learner_overall_time_ms: 369.362\n",
      "  timestamp: 1619130992\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 155450\n",
      "  training_iteration: 12\n",
      "  trial_id: 40c8b_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 104.0/251.4 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 32/32 CPUs, 0/0 GPUs, 0.0/15.09 GiB heap, 0.0/5.18 GiB objects<br>Result logdir: /Raytest/Raytest/ray_results/experiment_apex6<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name      </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>APEX_40c8b_00000</td><td>RUNNING </td><td>10.42.1.113:2336</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         20099.1</td><td style=\"text-align: right;\">155450</td><td style=\"text-align: right;\">-36806.2</td><td style=\"text-align: right;\">            -34190.9</td><td style=\"text-align: right;\">            -38824.9</td><td style=\"text-align: right;\">              2880</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am in second callback. Got result: {}\n",
      "Result for APEX_40c8b_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-04-22_23-06-41\n",
      "  done: false\n",
      "  episode_len_mean: 2880.0\n",
      "  episode_reward_max: -34190.85600000016\n",
      "  episode_reward_mean: -36806.15018181814\n",
      "  episode_reward_min: -38824.871999999894\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 11\n",
      "  experiment_id: d21118775ed24ec1819dd8ebeb7c9122\n",
      "  hostname: raytest3-644cc68dc4-mcsqh\n",
      "  info:\n",
      "    exploration_infos:\n",
      "    - cur_epsilon: 0.0\n",
      "    - cur_epsilon: 0.4000000059604645\n",
      "    - cur_epsilon: 0.3230035603046417\n",
      "    - cur_epsilon: 0.26082825660705566\n",
      "    - cur_epsilon: 0.21062114834785461\n",
      "    - cur_epsilon: 0.17007845640182495\n",
      "    - cur_epsilon: 0.13733987510204315\n",
      "    - cur_epsilon: 0.11090317368507385\n",
      "    - cur_epsilon: 0.0895553007721901\n",
      "    - cur_epsilon: 0.07231670618057251\n",
      "    - cur_epsilon: 0.058396387845277786\n",
      "    - cur_epsilon: 0.047155603766441345\n",
      "    - cur_epsilon: 0.03807856887578964\n",
      "    - cur_epsilon: 0.03074878640472889\n",
      "    - cur_epsilon: 0.024829918518662453\n",
      "    - cur_epsilon: 0.020050380378961563\n",
      "    - cur_epsilon: 0.01619086228311062\n",
      "    - cur_epsilon: 0.013074264861643314\n",
      "    - cur_epsilon: 0.010557586327195168\n",
      "    - cur_epsilon: 0.008525344543159008\n",
      "    - cur_epsilon: 0.006884292233735323\n",
      "    - cur_epsilon: 0.005559127312153578\n",
      "    - cur_epsilon: 0.00448904512450099\n",
      "    - cur_epsilon: 0.003624943783506751\n",
      "    - cur_epsilon: 0.002927174558863044\n",
      "    - cur_epsilon: 0.0023637195117771626\n",
      "    - cur_epsilon: 0.0019087246619164944\n",
      "    - cur_epsilon: 0.0015413122018799186\n",
      "    - cur_epsilon: 0.0012446233304217458\n",
      "    - cur_epsilon: 0.0010050444398075342\n",
      "    - cur_epsilon: 0.0008115823729895055\n",
      "    - cur_epsilon: 0.0006553599960170686\n",
      "    last_target_update_ts: 72293760\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: 251.0296173095703\n",
      "        mean_q: -66.25298309326172\n",
      "        mean_td_error: -3.3904926776885986\n",
      "        min_q: -150.8350830078125\n",
      "        model: {}\n",
      "    learner_queue:\n",
      "      size_count: 25110\n",
      "      size_mean: 0.3\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 1.0\n",
      "      - 1.0\n",
      "      size_std: 0.458257569495584\n",
      "    num_steps_sampled: 167000\n",
      "    num_steps_trained: 72316800\n",
      "    num_target_updates: 2282\n",
      "    num_weight_syncs: 403\n",
      "    replay_shard_0:\n",
      "      add_batch_time_ms: 20.091\n",
      "      policy_default_policy:\n",
      "        added_count: 42200\n",
      "        est_size_bytes: 22400000\n",
      "        num_entries: 25000\n",
      "        sampled_count: 18210240\n",
      "      replay_time_ms: 1046.051\n",
      "      update_priorities_time_ms: 1985.765\n",
      "  iterations_since_restore: 13\n",
      "  node_ip: 10.42.1.113\n",
      "  num_healthy_workers: 31\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 99.98682774746686\n",
      "    ram_util_percent: 40.8317614964926\n",
      "  pid: 2336\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.22079250720164564\n",
      "    mean_env_wait_ms: 3850.2920529126077\n",
      "    mean_inference_ms: 7.130592863299069\n",
      "    mean_raw_obs_processing_ms: 2.3237147166273395\n",
      "  time_since_restore: 21908.35612344742\n",
      "  time_this_iter_s: 1809.2439126968384\n",
      "  time_total_s: 21908.35612344742\n",
      "  timers:\n",
      "    learner_dequeue_time_ms: 388.656\n",
      "    learner_grad_throughput: 11552.81\n",
      "    learner_grad_time_ms: 249.29\n",
      "    learner_overall_throughput: 4514.157\n",
      "    learner_overall_time_ms: 637.993\n",
      "  timestamp: 1619132801\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 167000\n",
      "  training_iteration: 13\n",
      "  trial_id: 40c8b_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 103.4/251.4 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 32/32 CPUs, 0/0 GPUs, 0.0/15.09 GiB heap, 0.0/5.18 GiB objects<br>Result logdir: /Raytest/Raytest/ray_results/experiment_apex6<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name      </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>APEX_40c8b_00000</td><td>RUNNING </td><td>10.42.1.113:2336</td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">         21908.4</td><td style=\"text-align: right;\">167000</td><td style=\"text-align: right;\">-36806.2</td><td style=\"text-align: right;\">            -34190.9</td><td style=\"text-align: right;\">            -38824.9</td><td style=\"text-align: right;\">              2880</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2320)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2320)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2320)\u001b[0m [0, -35179.10800000002, -28650.66799999996]\n",
      "\u001b[2m\u001b[36m(pid=2332)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2332)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2332)\u001b[0m [0, -32142.135999999875, -21976.540000000005]\n",
      "\u001b[2m\u001b[36m(pid=2289)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2289)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2289)\u001b[0m [0, -35655.32399999989, -28525.096]\n",
      "\u001b[2m\u001b[36m(pid=2285)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2285)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2285)\u001b[0m [0, -34190.85600000016, -32448.880000000016]\n",
      "\u001b[2m\u001b[36m(pid=2287)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2287)\u001b[0m Loading configuration ... \n",
      "\u001b[2m\u001b[36m(pid=2287)\u001b[0m done.\n",
      "\u001b[2m\u001b[36m(pid=2287)\u001b[0m [0, -33610.327999999994, -31109.33200000007]\n",
      "\u001b[2m\u001b[36m(pid=2330)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2330)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2330)\u001b[0m [0, -32399.699999999884, -33277.16399999993]\n",
      "\u001b[2m\u001b[36m(pid=2301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2301)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2301)\u001b[0m [0, -36976.89600000002, -27287.10000000009]\n",
      "\u001b[2m\u001b[36m(pid=2300)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2300)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2300)\u001b[0m [0, -32197.943999999992, -23785.81600000003]\n",
      "\u001b[2m\u001b[36m(pid=2282)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2282)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2282)\u001b[0m [0, -33344.976, -35274.23200000008]\n",
      "\u001b[2m\u001b[36m(pid=2318)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2318)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2318)\u001b[0m [0, -33839.92400000001, -29185.211999999927]\n",
      "\u001b[2m\u001b[36m(pid=2334)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2334)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2334)\u001b[0m [0, -36127.58000000004, -33617.015999999945]\n",
      "\u001b[2m\u001b[36m(pid=2327)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2327)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2327)\u001b[0m [0, -32619.000000000084, -34463.33999999978]\n",
      "\u001b[2m\u001b[36m(pid=2305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2305)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2305)\u001b[0m [0, -35051.15999999992, -27070.776000000056]\n",
      "\u001b[2m\u001b[36m(pid=2293)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2293)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2293)\u001b[0m [0, -34719.38000000016, -34403.13600000013]\n",
      "\u001b[2m\u001b[36m(pid=2292)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2292)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2284)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2284)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2292)\u001b[0m [0, -36141.031999999934, -32580.75200000004]\n",
      "\u001b[2m\u001b[36m(pid=2284)\u001b[0m [0, -36046.4520000001, -29922.244000000064]\n",
      "I am in second callback. Got result: {}\n",
      "Result for APEX_40c8b_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-04-22_23-32-42\n",
      "  done: false\n",
      "  episode_len_mean: 2880.0\n",
      "  episode_reward_max: -28650.66799999996\n",
      "  episode_reward_mean: -35477.6645333333\n",
      "  episode_reward_min: -38824.871999999894\n",
      "  episodes_this_iter: 4\n",
      "  episodes_total: 15\n",
      "  experiment_id: d21118775ed24ec1819dd8ebeb7c9122\n",
      "  hostname: raytest3-644cc68dc4-mcsqh\n",
      "  info:\n",
      "    exploration_infos:\n",
      "    - cur_epsilon: 0.0\n",
      "    - cur_epsilon: 0.4000000059604645\n",
      "    - cur_epsilon: 0.3230035603046417\n",
      "    - cur_epsilon: 0.26082825660705566\n",
      "    - cur_epsilon: 0.21062114834785461\n",
      "    - cur_epsilon: 0.17007845640182495\n",
      "    - cur_epsilon: 0.13733987510204315\n",
      "    - cur_epsilon: 0.11090317368507385\n",
      "    - cur_epsilon: 0.0895553007721901\n",
      "    - cur_epsilon: 0.07231670618057251\n",
      "    - cur_epsilon: 0.058396387845277786\n",
      "    - cur_epsilon: 0.047155603766441345\n",
      "    - cur_epsilon: 0.03807856887578964\n",
      "    - cur_epsilon: 0.03074878640472889\n",
      "    - cur_epsilon: 0.024829918518662453\n",
      "    - cur_epsilon: 0.020050380378961563\n",
      "    - cur_epsilon: 0.01619086228311062\n",
      "    - cur_epsilon: 0.013074264861643314\n",
      "    - cur_epsilon: 0.010557586327195168\n",
      "    - cur_epsilon: 0.008525344543159008\n",
      "    - cur_epsilon: 0.006884292233735323\n",
      "    - cur_epsilon: 0.005559127312153578\n",
      "    - cur_epsilon: 0.00448904512450099\n",
      "    - cur_epsilon: 0.003624943783506751\n",
      "    - cur_epsilon: 0.002927174558863044\n",
      "    - cur_epsilon: 0.0023637195117771626\n",
      "    - cur_epsilon: 0.0019087246619164944\n",
      "    - cur_epsilon: 0.0015413122018799186\n",
      "    - cur_epsilon: 0.0012446233304217458\n",
      "    - cur_epsilon: 0.0010050444398075342\n",
      "    - cur_epsilon: 0.0008115823729895055\n",
      "    - cur_epsilon: 0.0006553599960170686\n",
      "    last_target_update_ts: 78122880\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: 240.0470733642578\n",
      "        mean_q: -58.374549865722656\n",
      "        mean_td_error: -3.05728816986084\n",
      "        min_q: -147.98678588867188\n",
      "        model: {}\n",
      "    learner_queue:\n",
      "      size_count: 27132\n",
      "      size_mean: 0.22\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 1.0\n",
      "      - 1.0\n",
      "      size_std: 0.41424630354415964\n",
      "    num_steps_sampled: 178550\n",
      "    num_steps_trained: 78140160\n",
      "    num_target_updates: 2466\n",
      "    num_weight_syncs: 435\n",
      "    replay_shard_0:\n",
      "      add_batch_time_ms: 20.84\n",
      "      policy_default_policy:\n",
      "        added_count: 44700\n",
      "        est_size_bytes: 22400000\n",
      "        num_entries: 25000\n",
      "        sampled_count: 19696320\n",
      "      replay_time_ms: 1117.058\n",
      "      update_priorities_time_ms: 2374.977\n",
      "  iterations_since_restore: 14\n",
      "  node_ip: 10.42.1.113\n",
      "  num_healthy_workers: 31\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 99.97698555956678\n",
      "    ram_util_percent: 41.31660649819495\n",
      "  pid: 2336\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.22335167800006814\n",
      "    mean_env_wait_ms: 3806.2455661935455\n",
      "    mean_inference_ms: 7.11599268230324\n",
      "    mean_raw_obs_processing_ms: 2.331694632894529\n",
      "  time_since_restore: 23469.20320558548\n",
      "  time_this_iter_s: 1560.8470821380615\n",
      "  time_total_s: 23469.20320558548\n",
      "  timers:\n",
      "    learner_dequeue_time_ms: 591.423\n",
      "    learner_grad_throughput: 9535.721\n",
      "    learner_grad_time_ms: 302.022\n",
      "    learner_overall_throughput: 3223.318\n",
      "    learner_overall_time_ms: 893.489\n",
      "  timestamp: 1619134362\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 178550\n",
      "  training_iteration: 14\n",
      "  trial_id: 40c8b_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 103.3/251.4 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 32/32 CPUs, 0/0 GPUs, 0.0/15.09 GiB heap, 0.0/5.18 GiB objects<br>Result logdir: /Raytest/Raytest/ray_results/experiment_apex6<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name      </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>APEX_40c8b_00000</td><td>RUNNING </td><td>10.42.1.113:2336</td><td style=\"text-align: right;\">    14</td><td style=\"text-align: right;\">         23469.2</td><td style=\"text-align: right;\">178550</td><td style=\"text-align: right;\">-35477.7</td><td style=\"text-align: right;\">            -28650.7</td><td style=\"text-align: right;\">            -38824.9</td><td style=\"text-align: right;\">              2880</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2283)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2283)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2296)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2296)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2281)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2281)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2296)\u001b[0m [0, -32732.987999999987, -26298.891999999996]\n",
      "\u001b[2m\u001b[36m(pid=2283)\u001b[0m [0, -38095.69200000007, -32515.576000000172]\n",
      "\u001b[2m\u001b[36m(pid=2295)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2281)\u001b[0m [0, -37499.47199999996, -34147.092000000084]\n",
      "\u001b[2m\u001b[36m(pid=2295)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2298)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2298)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2286)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2286)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2295)\u001b[0m [0, -32016.084, -33057.147999999856]\n",
      "\u001b[2m\u001b[36m(pid=2298)\u001b[0m [0, -32108.683999999947, -34034.59599999983]\n",
      "\u001b[2m\u001b[36m(pid=2290)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2290)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2286)\u001b[0m [0, -35142.13599999992, -33147.20400000004]\n",
      "\u001b[2m\u001b[36m(pid=2290)\u001b[0m [0, -37412.03999999967, -30451.28000000028]\n",
      "\u001b[2m\u001b[36m(pid=2288)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2288)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2288)\u001b[0m [0, -33656.53600000012, -33633.26800000006]\n",
      "\u001b[2m\u001b[36m(pid=2310)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2310)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2310)\u001b[0m [0, -31777.859999999968, -29251.13600000003]\n",
      "\u001b[2m\u001b[36m(pid=2314)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2314)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2299)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2299)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2299)\u001b[0m [0, -38824.871999999894, -34052.97199999988]\n",
      "\u001b[2m\u001b[36m(pid=2280)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2280)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2280)\u001b[0m [0, -36657.05200000004, -33164.32800000009]\n",
      "\u001b[2m\u001b[36m(pid=2308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2308)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2308)\u001b[0m [0, -37665.248000000014, -38091.73999999992]\n",
      "I am in second callback. Got result: {}\n",
      "Result for APEX_40c8b_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-04-22_23-48-11\n",
      "  done: false\n",
      "  episode_len_mean: 2880.0\n",
      "  episode_reward_max: -28525.096\n",
      "  episode_reward_mean: -34909.79242105261\n",
      "  episode_reward_min: -38824.871999999894\n",
      "  episodes_this_iter: 4\n",
      "  episodes_total: 19\n",
      "  experiment_id: d21118775ed24ec1819dd8ebeb7c9122\n",
      "  hostname: raytest3-644cc68dc4-mcsqh\n",
      "  info:\n",
      "    exploration_infos:\n",
      "    - cur_epsilon: 0.0\n",
      "    - cur_epsilon: 0.4000000059604645\n",
      "    - cur_epsilon: 0.3230035603046417\n",
      "    - cur_epsilon: 0.26082825660705566\n",
      "    - cur_epsilon: 0.21062114834785461\n",
      "    - cur_epsilon: 0.17007845640182495\n",
      "    - cur_epsilon: 0.13733987510204315\n",
      "    - cur_epsilon: 0.11090317368507385\n",
      "    - cur_epsilon: 0.0895553007721901\n",
      "    - cur_epsilon: 0.07231670618057251\n",
      "    - cur_epsilon: 0.058396387845277786\n",
      "    - cur_epsilon: 0.047155603766441345\n",
      "    - cur_epsilon: 0.03807856887578964\n",
      "    - cur_epsilon: 0.03074878640472889\n",
      "    - cur_epsilon: 0.024829918518662453\n",
      "    - cur_epsilon: 0.020050380378961563\n",
      "    - cur_epsilon: 0.01619086228311062\n",
      "    - cur_epsilon: 0.013074264861643314\n",
      "    - cur_epsilon: 0.010557586327195168\n",
      "    - cur_epsilon: 0.008525344543159008\n",
      "    - cur_epsilon: 0.006884292233735323\n",
      "    - cur_epsilon: 0.005559127312153578\n",
      "    - cur_epsilon: 0.00448904512450099\n",
      "    - cur_epsilon: 0.003624943783506751\n",
      "    - cur_epsilon: 0.002927174558863044\n",
      "    - cur_epsilon: 0.0023637195117771626\n",
      "    - cur_epsilon: 0.0019087246619164944\n",
      "    - cur_epsilon: 0.0015413122018799186\n",
      "    - cur_epsilon: 0.0012446233304217458\n",
      "    - cur_epsilon: 0.0010050444398075342\n",
      "    - cur_epsilon: 0.0008115823729895055\n",
      "    - cur_epsilon: 0.0006553599960170686\n",
      "    last_target_update_ts: 81322560\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: 242.01992797851562\n",
      "        mean_q: -40.894927978515625\n",
      "        mean_td_error: -4.518837928771973\n",
      "        min_q: -149.3204345703125\n",
      "        model: {}\n",
      "    learner_queue:\n",
      "      size_count: 28243\n",
      "      size_mean: 0.48\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 1.0\n",
      "      - 2.0\n",
      "      size_std: 0.6079473661428265\n",
      "    num_steps_sampled: 190100\n",
      "    num_steps_trained: 81339840\n",
      "    num_target_updates: 2567\n",
      "    num_weight_syncs: 464\n",
      "    replay_shard_0:\n",
      "      add_batch_time_ms: 9.356\n",
      "      policy_default_policy:\n",
      "        added_count: 47050\n",
      "        est_size_bytes: 22400000\n",
      "        num_entries: 25000\n",
      "        sampled_count: 20522880\n",
      "      replay_time_ms: 851.232\n",
      "      update_priorities_time_ms: 1950.133\n",
      "  iterations_since_restore: 15\n",
      "  node_ip: 10.42.1.113\n",
      "  num_healthy_workers: 31\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 99.97787878787878\n",
      "    ram_util_percent: 40.53401515151515\n",
      "  pid: 2336\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.22029863158970506\n",
      "    mean_env_wait_ms: 3802.4739687259125\n",
      "    mean_inference_ms: 7.119877452970426\n",
      "    mean_raw_obs_processing_ms: 2.34782129644409\n",
      "  time_since_restore: 24398.16011285782\n",
      "  time_this_iter_s: 928.9569072723389\n",
      "  time_total_s: 24398.16011285782\n",
      "  timers:\n",
      "    learner_dequeue_time_ms: 424.659\n",
      "    learner_grad_throughput: 11343.813\n",
      "    learner_grad_time_ms: 253.883\n",
      "    learner_overall_throughput: 4244.125\n",
      "    learner_overall_time_ms: 678.585\n",
      "  timestamp: 1619135291\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 190100\n",
      "  training_iteration: 15\n",
      "  trial_id: 40c8b_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 100.0/251.4 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 32/32 CPUs, 0/0 GPUs, 0.0/15.09 GiB heap, 0.0/5.18 GiB objects<br>Result logdir: /Raytest/Raytest/ray_results/experiment_apex6<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name      </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>APEX_40c8b_00000</td><td>RUNNING </td><td>10.42.1.113:2336</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         24398.2</td><td style=\"text-align: right;\">190100</td><td style=\"text-align: right;\">-34909.8</td><td style=\"text-align: right;\">            -28525.1</td><td style=\"text-align: right;\">            -38824.9</td><td style=\"text-align: right;\">              2880</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2313)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2313)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2313)\u001b[0m [0, -37938.45199999979, -35572.61999999994]\n",
      "\u001b[2m\u001b[36m(pid=2294)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2294)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2294)\u001b[0m [0, -38233.66800000016, -37915.800000000294]\n",
      "I am in second callback. Got result: {}\n",
      "Result for APEX_40c8b_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-04-23_00-04-50\n",
      "  done: false\n",
      "  episode_len_mean: 2880.0\n",
      "  episode_reward_max: -28525.096\n",
      "  episode_reward_mean: -34905.03657142855\n",
      "  episode_reward_min: -38824.871999999894\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 21\n",
      "  experiment_id: d21118775ed24ec1819dd8ebeb7c9122\n",
      "  hostname: raytest3-644cc68dc4-mcsqh\n",
      "  info:\n",
      "    exploration_infos:\n",
      "    - cur_epsilon: 0.0\n",
      "    - cur_epsilon: 0.4000000059604645\n",
      "    - cur_epsilon: 0.3230035603046417\n",
      "    - cur_epsilon: 0.26082825660705566\n",
      "    - cur_epsilon: 0.21062114834785461\n",
      "    - cur_epsilon: 0.17007845640182495\n",
      "    - cur_epsilon: 0.13733987510204315\n",
      "    - cur_epsilon: 0.11090317368507385\n",
      "    - cur_epsilon: 0.0895553007721901\n",
      "    - cur_epsilon: 0.07231670618057251\n",
      "    - cur_epsilon: 0.058396387845277786\n",
      "    - cur_epsilon: 0.047155603766441345\n",
      "    - cur_epsilon: 0.03807856887578964\n",
      "    - cur_epsilon: 0.03074878640472889\n",
      "    - cur_epsilon: 0.024829918518662453\n",
      "    - cur_epsilon: 0.020050380378961563\n",
      "    - cur_epsilon: 0.01619086228311062\n",
      "    - cur_epsilon: 0.013074264861643314\n",
      "    - cur_epsilon: 0.010557586327195168\n",
      "    - cur_epsilon: 0.008525344543159008\n",
      "    - cur_epsilon: 0.006884292233735323\n",
      "    - cur_epsilon: 0.005559127312153578\n",
      "    - cur_epsilon: 0.00448904512450099\n",
      "    - cur_epsilon: 0.003624943783506751\n",
      "    - cur_epsilon: 0.002927174558863044\n",
      "    - cur_epsilon: 0.0023637195117771626\n",
      "    - cur_epsilon: 0.0019087246619164944\n",
      "    - cur_epsilon: 0.0015413122018799186\n",
      "    - cur_epsilon: 0.0012446233304217458\n",
      "    - cur_epsilon: 0.0010050444398075342\n",
      "    - cur_epsilon: 0.0008115823729895055\n",
      "    - cur_epsilon: 0.0006553599960170686\n",
      "    last_target_update_ts: 85314240\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: 261.23779296875\n",
      "        mean_q: -46.93389892578125\n",
      "        mean_td_error: -1.9261469841003418\n",
      "        min_q: -145.3275909423828\n",
      "        model: {}\n",
      "    learner_queue:\n",
      "      size_count: 29625\n",
      "      size_mean: 0.46\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 1.0\n",
      "      - 2.0\n",
      "      size_std: 0.5730619512757762\n",
      "    num_steps_sampled: 201650\n",
      "    num_steps_trained: 85317120\n",
      "    num_target_updates: 2693\n",
      "    num_weight_syncs: 493\n",
      "    replay_shard_0:\n",
      "      add_batch_time_ms: 34.231\n",
      "      policy_default_policy:\n",
      "        added_count: 49650\n",
      "        est_size_bytes: 22400000\n",
      "        num_entries: 25000\n",
      "        sampled_count: 21539520\n",
      "      replay_time_ms: 348.258\n",
      "      update_priorities_time_ms: 761.642\n",
      "  iterations_since_restore: 16\n",
      "  node_ip: 10.42.1.113\n",
      "  num_healthy_workers: 31\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 99.98743824982358\n",
      "    ram_util_percent: 39.86923076923077\n",
      "  pid: 2336\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.21937135196387486\n",
      "    mean_env_wait_ms: 3799.894105972016\n",
      "    mean_inference_ms: 7.109916768567696\n",
      "    mean_raw_obs_processing_ms: 2.335036750283076\n",
      "  time_since_restore: 25396.574497699738\n",
      "  time_this_iter_s: 998.414384841919\n",
      "  time_total_s: 25396.574497699738\n",
      "  timers:\n",
      "    learner_dequeue_time_ms: 82.59\n",
      "    learner_grad_throughput: 16775.166\n",
      "    learner_grad_time_ms: 171.682\n",
      "    learner_overall_throughput: 11324.505\n",
      "    learner_overall_time_ms: 254.316\n",
      "  timestamp: 1619136290\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 201650\n",
      "  training_iteration: 16\n",
      "  trial_id: 40c8b_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 101.1/251.4 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 32/32 CPUs, 0/0 GPUs, 0.0/15.09 GiB heap, 0.0/5.18 GiB objects<br>Result logdir: /Raytest/Raytest/ray_results/experiment_apex6<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name      </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>APEX_40c8b_00000</td><td>RUNNING </td><td>10.42.1.113:2336</td><td style=\"text-align: right;\">    16</td><td style=\"text-align: right;\">         25396.6</td><td style=\"text-align: right;\">201650</td><td style=\"text-align: right;\">  -34905</td><td style=\"text-align: right;\">            -28525.1</td><td style=\"text-align: right;\">            -38824.9</td><td style=\"text-align: right;\">              2880</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am in second callback. Got result: {}\n",
      "Result for APEX_40c8b_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-04-23_00-30-11\n",
      "  done: false\n",
      "  episode_len_mean: 2880.0\n",
      "  episode_reward_max: -28525.096\n",
      "  episode_reward_mean: -35041.88945454544\n",
      "  episode_reward_min: -38824.871999999894\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 22\n",
      "  experiment_id: d21118775ed24ec1819dd8ebeb7c9122\n",
      "  hostname: raytest3-644cc68dc4-mcsqh\n",
      "  info:\n",
      "    exploration_infos:\n",
      "    - cur_epsilon: 0.0\n",
      "    - cur_epsilon: 0.4000000059604645\n",
      "    - cur_epsilon: 0.3230035603046417\n",
      "    - cur_epsilon: 0.26082825660705566\n",
      "    - cur_epsilon: 0.21062114834785461\n",
      "    - cur_epsilon: 0.17007845640182495\n",
      "    - cur_epsilon: 0.13733987510204315\n",
      "    - cur_epsilon: 0.11090317368507385\n",
      "    - cur_epsilon: 0.0895553007721901\n",
      "    - cur_epsilon: 0.07231670618057251\n",
      "    - cur_epsilon: 0.058396387845277786\n",
      "    - cur_epsilon: 0.047155603766441345\n",
      "    - cur_epsilon: 0.03807856887578964\n",
      "    - cur_epsilon: 0.03074878640472889\n",
      "    - cur_epsilon: 0.024829918518662453\n",
      "    - cur_epsilon: 0.020050380378961563\n",
      "    - cur_epsilon: 0.01619086228311062\n",
      "    - cur_epsilon: 0.013074264861643314\n",
      "    - cur_epsilon: 0.010557586327195168\n",
      "    - cur_epsilon: 0.008525344543159008\n",
      "    - cur_epsilon: 0.006884292233735323\n",
      "    - cur_epsilon: 0.005559127312153578\n",
      "    - cur_epsilon: 0.00448904512450099\n",
      "    - cur_epsilon: 0.003624943783506751\n",
      "    - cur_epsilon: 0.002927174558863044\n",
      "    - cur_epsilon: 0.0023637195117771626\n",
      "    - cur_epsilon: 0.0019087246619164944\n",
      "    - cur_epsilon: 0.0015413122018799186\n",
      "    - cur_epsilon: 0.0012446233304217458\n",
      "    - cur_epsilon: 0.0010050444398075342\n",
      "    - cur_epsilon: 0.0008115823729895055\n",
      "    - cur_epsilon: 0.0006553599960170686\n",
      "    last_target_update_ts: 90509760\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: 177.7423858642578\n",
      "        mean_q: -63.13739013671875\n",
      "        mean_td_error: -3.3191776275634766\n",
      "        min_q: -143.6544647216797\n",
      "        model: {}\n",
      "    learner_queue:\n",
      "      size_count: 31427\n",
      "      size_mean: 0.44\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 1.0\n",
      "      - 2.0\n",
      "      size_std: 0.6374950980203691\n",
      "    num_steps_sampled: 213250\n",
      "    num_steps_trained: 90509760\n",
      "    num_target_updates: 2857\n",
      "    num_weight_syncs: 523\n",
      "    replay_shard_0:\n",
      "      add_batch_time_ms: 8.128\n",
      "      policy_default_policy:\n",
      "        added_count: 52450\n",
      "        est_size_bytes: 22400000\n",
      "        num_entries: 25000\n",
      "        sampled_count: 22803840\n",
      "      replay_time_ms: 788.849\n",
      "      update_priorities_time_ms: 1308.138\n",
      "  iterations_since_restore: 17\n",
      "  node_ip: 10.42.1.113\n",
      "  num_healthy_workers: 31\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 99.99120777417862\n",
      "    ram_util_percent: 40.334798704303566\n",
      "  pid: 2336\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.21962553443907182\n",
      "    mean_env_wait_ms: 3803.22558471809\n",
      "    mean_inference_ms: 7.1020977557967635\n",
      "    mean_raw_obs_processing_ms: 2.3635119550099954\n",
      "  time_since_restore: 26918.21599841118\n",
      "  time_this_iter_s: 1521.641500711441\n",
      "  time_total_s: 26918.21599841118\n",
      "  timers:\n",
      "    learner_dequeue_time_ms: 406.853\n",
      "    learner_grad_throughput: 11093.132\n",
      "    learner_grad_time_ms: 259.62\n",
      "    learner_overall_throughput: 4320.958\n",
      "    learner_overall_time_ms: 666.519\n",
      "  timestamp: 1619137811\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 213250\n",
      "  training_iteration: 17\n",
      "  trial_id: 40c8b_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 101.2/251.4 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 32/32 CPUs, 0/0 GPUs, 0.0/15.09 GiB heap, 0.0/5.18 GiB objects<br>Result logdir: /Raytest/Raytest/ray_results/experiment_apex6<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name      </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>APEX_40c8b_00000</td><td>RUNNING </td><td>10.42.1.113:2336</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         26918.2</td><td style=\"text-align: right;\">213250</td><td style=\"text-align: right;\">-35041.9</td><td style=\"text-align: right;\">            -28525.1</td><td style=\"text-align: right;\">            -38824.9</td><td style=\"text-align: right;\">              2880</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am in second callback. Got result: {}\n",
      "Result for APEX_40c8b_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-04-23_00-53-33\n",
      "  done: false\n",
      "  episode_len_mean: 2880.0\n",
      "  episode_reward_max: -28525.096\n",
      "  episode_reward_mean: -35041.889454545446\n",
      "  episode_reward_min: -38824.871999999894\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 22\n",
      "  experiment_id: d21118775ed24ec1819dd8ebeb7c9122\n",
      "  hostname: raytest3-644cc68dc4-mcsqh\n",
      "  info:\n",
      "    exploration_infos:\n",
      "    - cur_epsilon: 0.0\n",
      "    - cur_epsilon: 0.4000000059604645\n",
      "    - cur_epsilon: 0.3230035603046417\n",
      "    - cur_epsilon: 0.26082825660705566\n",
      "    - cur_epsilon: 0.21062114834785461\n",
      "    - cur_epsilon: 0.17007845640182495\n",
      "    - cur_epsilon: 0.13733987510204315\n",
      "    - cur_epsilon: 0.11090317368507385\n",
      "    - cur_epsilon: 0.0895553007721901\n",
      "    - cur_epsilon: 0.07231670618057251\n",
      "    - cur_epsilon: 0.058396387845277786\n",
      "    - cur_epsilon: 0.047155603766441345\n",
      "    - cur_epsilon: 0.03807856887578964\n",
      "    - cur_epsilon: 0.03074878640472889\n",
      "    - cur_epsilon: 0.024829918518662453\n",
      "    - cur_epsilon: 0.020050380378961563\n",
      "    - cur_epsilon: 0.01619086228311062\n",
      "    - cur_epsilon: 0.013074264861643314\n",
      "    - cur_epsilon: 0.010557586327195168\n",
      "    - cur_epsilon: 0.008525344543159008\n",
      "    - cur_epsilon: 0.006884292233735323\n",
      "    - cur_epsilon: 0.005559127312153578\n",
      "    - cur_epsilon: 0.00448904512450099\n",
      "    - cur_epsilon: 0.003624943783506751\n",
      "    - cur_epsilon: 0.002927174558863044\n",
      "    - cur_epsilon: 0.0023637195117771626\n",
      "    - cur_epsilon: 0.0019087246619164944\n",
      "    - cur_epsilon: 0.0015413122018799186\n",
      "    - cur_epsilon: 0.0012446233304217458\n",
      "    - cur_epsilon: 0.0010050444398075342\n",
      "    - cur_epsilon: 0.0008115823729895055\n",
      "    - cur_epsilon: 0.0006553599960170686\n",
      "    last_target_update_ts: 96370560\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: 265.3569030761719\n",
      "        mean_q: -64.4615249633789\n",
      "        mean_td_error: -3.9164083003997803\n",
      "        min_q: -140.57196044921875\n",
      "        model: {}\n",
      "    learner_queue:\n",
      "      size_count: 33466\n",
      "      size_mean: 0.5\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 1.1000000000000014\n",
      "      - 3.0\n",
      "      size_std: 0.7280109889280518\n",
      "    num_steps_sampled: 224800\n",
      "    num_steps_trained: 96376320\n",
      "    num_target_updates: 3042\n",
      "    num_weight_syncs: 550\n",
      "    replay_shard_0:\n",
      "      add_batch_time_ms: 30.515\n",
      "      policy_default_policy:\n",
      "        added_count: 55450\n",
      "        est_size_bytes: 22400000\n",
      "        num_entries: 25000\n",
      "        sampled_count: 24249600\n",
      "      replay_time_ms: 795.561\n",
      "      update_priorities_time_ms: 1812.486\n",
      "  iterations_since_restore: 18\n",
      "  node_ip: 10.42.1.113\n",
      "  num_healthy_workers: 31\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 99.96752136752137\n",
      "    ram_util_percent: 39.49532428355957\n",
      "  pid: 2336\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.21962553443907176\n",
      "    mean_env_wait_ms: 3803.22558471809\n",
      "    mean_inference_ms: 7.1020977557967635\n",
      "    mean_raw_obs_processing_ms: 2.363511955009996\n",
      "  time_since_restore: 28319.6535282135\n",
      "  time_this_iter_s: 1401.4375298023224\n",
      "  time_total_s: 28319.6535282135\n",
      "  timers:\n",
      "    learner_dequeue_time_ms: 235.42\n",
      "    learner_grad_throughput: 10563.811\n",
      "    learner_grad_time_ms: 272.629\n",
      "    learner_overall_throughput: 5668.255\n",
      "    learner_overall_time_ms: 508.093\n",
      "  timestamp: 1619139213\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 224800\n",
      "  training_iteration: 18\n",
      "  trial_id: 40c8b_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 98.6/251.4 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 32/32 CPUs, 0/0 GPUs, 0.0/15.09 GiB heap, 0.0/5.18 GiB objects<br>Result logdir: /Raytest/Raytest/ray_results/experiment_apex6<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name      </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>APEX_40c8b_00000</td><td>RUNNING </td><td>10.42.1.113:2336</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         28319.7</td><td style=\"text-align: right;\">224800</td><td style=\"text-align: right;\">-35041.9</td><td style=\"text-align: right;\">            -28525.1</td><td style=\"text-align: right;\">            -38824.9</td><td style=\"text-align: right;\">              2880</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am in second callback. Got result: {}\n",
      "Result for APEX_40c8b_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-04-23_01-18-02\n",
      "  done: false\n",
      "  episode_len_mean: 2880.0\n",
      "  episode_reward_max: -28525.096\n",
      "  episode_reward_mean: -35041.889454545446\n",
      "  episode_reward_min: -38824.871999999894\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 22\n",
      "  experiment_id: d21118775ed24ec1819dd8ebeb7c9122\n",
      "  hostname: raytest3-644cc68dc4-mcsqh\n",
      "  info:\n",
      "    exploration_infos:\n",
      "    - cur_epsilon: 0.0\n",
      "    - cur_epsilon: 0.4000000059604645\n",
      "    - cur_epsilon: 0.3230035603046417\n",
      "    - cur_epsilon: 0.26082825660705566\n",
      "    - cur_epsilon: 0.21062114834785461\n",
      "    - cur_epsilon: 0.17007845640182495\n",
      "    - cur_epsilon: 0.13733987510204315\n",
      "    - cur_epsilon: 0.11090317368507385\n",
      "    - cur_epsilon: 0.0895553007721901\n",
      "    - cur_epsilon: 0.07231670618057251\n",
      "    - cur_epsilon: 0.058396387845277786\n",
      "    - cur_epsilon: 0.047155603766441345\n",
      "    - cur_epsilon: 0.03807856887578964\n",
      "    - cur_epsilon: 0.03074878640472889\n",
      "    - cur_epsilon: 0.024829918518662453\n",
      "    - cur_epsilon: 0.020050380378961563\n",
      "    - cur_epsilon: 0.01619086228311062\n",
      "    - cur_epsilon: 0.013074264861643314\n",
      "    - cur_epsilon: 0.010557586327195168\n",
      "    - cur_epsilon: 0.008525344543159008\n",
      "    - cur_epsilon: 0.006884292233735323\n",
      "    - cur_epsilon: 0.005559127312153578\n",
      "    - cur_epsilon: 0.00448904512450099\n",
      "    - cur_epsilon: 0.003624943783506751\n",
      "    - cur_epsilon: 0.002927174558863044\n",
      "    - cur_epsilon: 0.0023637195117771626\n",
      "    - cur_epsilon: 0.0019087246619164944\n",
      "    - cur_epsilon: 0.0015413122018799186\n",
      "    - cur_epsilon: 0.0012446233304217458\n",
      "    - cur_epsilon: 0.0010050444398075342\n",
      "    - cur_epsilon: 0.0008115823729895055\n",
      "    - cur_epsilon: 0.0006553599960170686\n",
      "    last_target_update_ts: 102769920\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: 223.54730224609375\n",
      "        mean_q: -63.30828857421875\n",
      "        mean_td_error: -3.330958127975464\n",
      "        min_q: -140.22311401367188\n",
      "        model: {}\n",
      "    learner_queue:\n",
      "      size_count: 35686\n",
      "      size_mean: 0.26\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 1.0\n",
      "      - 2.0\n",
      "      size_std: 0.482078831727758\n",
      "    num_steps_sampled: 236350\n",
      "    num_steps_trained: 102775680\n",
      "    num_target_updates: 3244\n",
      "    num_weight_syncs: 580\n",
      "    replay_shard_0:\n",
      "      add_batch_time_ms: 22.496\n",
      "      policy_default_policy:\n",
      "        added_count: 58150\n",
      "        est_size_bytes: 22400000\n",
      "        num_entries: 25000\n",
      "        sampled_count: 25865280\n",
      "      replay_time_ms: 950.152\n",
      "      update_priorities_time_ms: 2512.597\n",
      "  iterations_since_restore: 19\n",
      "  node_ip: 10.42.1.113\n",
      "  num_healthy_workers: 31\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 99.94887290167867\n",
      "    ram_util_percent: 40.40964028776979\n",
      "  pid: 2336\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.21962553443907176\n",
      "    mean_env_wait_ms: 3803.22558471809\n",
      "    mean_inference_ms: 7.1020977557967635\n",
      "    mean_raw_obs_processing_ms: 2.363511955009996\n",
      "  time_since_restore: 29787.937525510788\n",
      "  time_this_iter_s: 1468.283997297287\n",
      "  time_total_s: 29787.937525510788\n",
      "  timers:\n",
      "    learner_dequeue_time_ms: 447.52\n",
      "    learner_grad_throughput: 10075.655\n",
      "    learner_grad_time_ms: 285.837\n",
      "    learner_overall_throughput: 3926.892\n",
      "    learner_overall_time_ms: 733.404\n",
      "  timestamp: 1619140682\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 236350\n",
      "  training_iteration: 19\n",
      "  trial_id: 40c8b_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 104.5/251.4 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 32/32 CPUs, 0/0 GPUs, 0.0/15.09 GiB heap, 0.0/5.18 GiB objects<br>Result logdir: /Raytest/Raytest/ray_results/experiment_apex6<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name      </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>APEX_40c8b_00000</td><td>RUNNING </td><td>10.42.1.113:2336</td><td style=\"text-align: right;\">    19</td><td style=\"text-align: right;\">         29787.9</td><td style=\"text-align: right;\">236350</td><td style=\"text-align: right;\">-35041.9</td><td style=\"text-align: right;\">            -28525.1</td><td style=\"text-align: right;\">            -38824.9</td><td style=\"text-align: right;\">              2880</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am in second callback. Got result: {}\n",
      "Result for APEX_40c8b_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-04-23_01-44-51\n",
      "  done: false\n",
      "  episode_len_mean: 2880.0\n",
      "  episode_reward_max: -28525.096\n",
      "  episode_reward_mean: -35041.889454545446\n",
      "  episode_reward_min: -38824.871999999894\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 22\n",
      "  experiment_id: d21118775ed24ec1819dd8ebeb7c9122\n",
      "  hostname: raytest3-644cc68dc4-mcsqh\n",
      "  info:\n",
      "    exploration_infos:\n",
      "    - cur_epsilon: 0.0\n",
      "    - cur_epsilon: 0.4000000059604645\n",
      "    - cur_epsilon: 0.3230035603046417\n",
      "    - cur_epsilon: 0.26082825660705566\n",
      "    - cur_epsilon: 0.21062114834785461\n",
      "    - cur_epsilon: 0.17007845640182495\n",
      "    - cur_epsilon: 0.13733987510204315\n",
      "    - cur_epsilon: 0.11090317368507385\n",
      "    - cur_epsilon: 0.0895553007721901\n",
      "    - cur_epsilon: 0.07231670618057251\n",
      "    - cur_epsilon: 0.058396387845277786\n",
      "    - cur_epsilon: 0.047155603766441345\n",
      "    - cur_epsilon: 0.03807856887578964\n",
      "    - cur_epsilon: 0.03074878640472889\n",
      "    - cur_epsilon: 0.024829918518662453\n",
      "    - cur_epsilon: 0.020050380378961563\n",
      "    - cur_epsilon: 0.01619086228311062\n",
      "    - cur_epsilon: 0.013074264861643314\n",
      "    - cur_epsilon: 0.010557586327195168\n",
      "    - cur_epsilon: 0.008525344543159008\n",
      "    - cur_epsilon: 0.006884292233735323\n",
      "    - cur_epsilon: 0.005559127312153578\n",
      "    - cur_epsilon: 0.00448904512450099\n",
      "    - cur_epsilon: 0.003624943783506751\n",
      "    - cur_epsilon: 0.002927174558863044\n",
      "    - cur_epsilon: 0.0023637195117771626\n",
      "    - cur_epsilon: 0.0019087246619164944\n",
      "    - cur_epsilon: 0.0015413122018799186\n",
      "    - cur_epsilon: 0.0012446233304217458\n",
      "    - cur_epsilon: 0.0010050444398075342\n",
      "    - cur_epsilon: 0.0008115823729895055\n",
      "    - cur_epsilon: 0.0006553599960170686\n",
      "    last_target_update_ts: 109676160\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: 230.40223693847656\n",
      "        mean_q: -60.73690414428711\n",
      "        mean_td_error: -1.608948826789856\n",
      "        min_q: -143.95370483398438\n",
      "        model: {}\n",
      "    learner_queue:\n",
      "      size_count: 38083\n",
      "      size_mean: 0.34\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 1.0\n",
      "      - 2.0\n",
      "      size_std: 0.5141984052872977\n",
      "    num_steps_sampled: 247900\n",
      "    num_steps_trained: 109676160\n",
      "    num_target_updates: 3462\n",
      "    num_weight_syncs: 609\n",
      "    replay_shard_0:\n",
      "      add_batch_time_ms: 18.869\n",
      "      policy_default_policy:\n",
      "        added_count: 60500\n",
      "        est_size_bytes: 22400000\n",
      "        num_entries: 25000\n",
      "        sampled_count: 27607680\n",
      "      replay_time_ms: 916.561\n",
      "      update_priorities_time_ms: 1604.967\n",
      "  iterations_since_restore: 20\n",
      "  node_ip: 10.42.1.113\n",
      "  num_healthy_workers: 31\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 99.97745183887916\n",
      "    ram_util_percent: 32.42556917688266\n",
      "  pid: 2336\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.21962553443907176\n",
      "    mean_env_wait_ms: 3803.22558471809\n",
      "    mean_inference_ms: 7.1020977557967635\n",
      "    mean_raw_obs_processing_ms: 2.363511955009996\n",
      "  time_since_restore: 31397.140381336212\n",
      "  time_this_iter_s: 1609.2028558254242\n",
      "  time_total_s: 31397.140381336212\n",
      "  timers:\n",
      "    learner_dequeue_time_ms: 408.556\n",
      "    learner_grad_throughput: 10257.303\n",
      "    learner_grad_time_ms: 280.776\n",
      "    learner_overall_throughput: 4177.687\n",
      "    learner_overall_time_ms: 689.377\n",
      "  timestamp: 1619142291\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 247900\n",
      "  training_iteration: 20\n",
      "  trial_id: 40c8b_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 74.2/251.4 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 32/32 CPUs, 0/0 GPUs, 0.0/15.09 GiB heap, 0.0/5.18 GiB objects<br>Result logdir: /Raytest/Raytest/ray_results/experiment_apex6<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name      </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>APEX_40c8b_00000</td><td>RUNNING </td><td>10.42.1.113:2336</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         31397.1</td><td style=\"text-align: right;\">247900</td><td style=\"text-align: right;\">-35041.9</td><td style=\"text-align: right;\">            -28525.1</td><td style=\"text-align: right;\">            -38824.9</td><td style=\"text-align: right;\">              2880</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2330)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2330)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2330)\u001b[0m [0, -32399.699999999884, -33277.16399999993, -29370.736000000128]\n",
      "\u001b[2m\u001b[36m(pid=2332)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2332)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2332)\u001b[0m [0, -32142.135999999875, -21976.540000000005, -23530.672000000006]\n",
      "\u001b[2m\u001b[36m(pid=2320)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2320)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2320)\u001b[0m [0, -35179.10800000002, -28650.66799999996, -36039.075999999826]\n",
      "I am in second callback. Got result: {}\n",
      "Result for APEX_40c8b_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-04-23_02-09-01\n",
      "  done: false\n",
      "  episode_len_mean: 2880.0\n",
      "  episode_reward_max: -28525.096\n",
      "  episode_reward_mean: -35041.889454545446\n",
      "  episode_reward_min: -38824.871999999894\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 22\n",
      "  experiment_id: d21118775ed24ec1819dd8ebeb7c9122\n",
      "  hostname: raytest3-644cc68dc4-mcsqh\n",
      "  info:\n",
      "    exploration_infos:\n",
      "    - cur_epsilon: 0.0\n",
      "    - cur_epsilon: 0.4000000059604645\n",
      "    - cur_epsilon: 0.3230035603046417\n",
      "    - cur_epsilon: 0.26082825660705566\n",
      "    - cur_epsilon: 0.21062114834785461\n",
      "    - cur_epsilon: 0.17007845640182495\n",
      "    - cur_epsilon: 0.13733987510204315\n",
      "    - cur_epsilon: 0.11090317368507385\n",
      "    - cur_epsilon: 0.0895553007721901\n",
      "    - cur_epsilon: 0.07231670618057251\n",
      "    - cur_epsilon: 0.058396387845277786\n",
      "    - cur_epsilon: 0.047155603766441345\n",
      "    - cur_epsilon: 0.03807856887578964\n",
      "    - cur_epsilon: 0.03074878640472889\n",
      "    - cur_epsilon: 0.024829918518662453\n",
      "    - cur_epsilon: 0.020050380378961563\n",
      "    - cur_epsilon: 0.01619086228311062\n",
      "    - cur_epsilon: 0.013074264861643314\n",
      "    - cur_epsilon: 0.010557586327195168\n",
      "    - cur_epsilon: 0.008525344543159008\n",
      "    - cur_epsilon: 0.006884292233735323\n",
      "    - cur_epsilon: 0.005559127312153578\n",
      "    - cur_epsilon: 0.00448904512450099\n",
      "    - cur_epsilon: 0.003624943783506751\n",
      "    - cur_epsilon: 0.002927174558863044\n",
      "    - cur_epsilon: 0.0023637195117771626\n",
      "    - cur_epsilon: 0.0019087246619164944\n",
      "    - cur_epsilon: 0.0015413122018799186\n",
      "    - cur_epsilon: 0.0012446233304217458\n",
      "    - cur_epsilon: 0.0010050444398075342\n",
      "    - cur_epsilon: 0.0008115823729895055\n",
      "    - cur_epsilon: 0.0006553599960170686\n",
      "    last_target_update_ts: 116677440\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: 232.99041748046875\n",
      "        mean_q: -58.365787506103516\n",
      "        mean_td_error: -4.930750370025635\n",
      "        min_q: -146.57276916503906\n",
      "        model: {}\n",
      "    learner_queue:\n",
      "      size_count: 40514\n",
      "      size_mean: 0.24\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 1.0\n",
      "      - 2.0\n",
      "      size_std: 0.47159304490206383\n",
      "    num_steps_sampled: 259450\n",
      "    num_steps_trained: 116677440\n",
      "    num_target_updates: 3683\n",
      "    num_weight_syncs: 634\n",
      "    replay_shard_0:\n",
      "      add_batch_time_ms: 16.441\n",
      "      policy_default_policy:\n",
      "        added_count: 63700\n",
      "        est_size_bytes: 22400000\n",
      "        num_entries: 25000\n",
      "        sampled_count: 29324160\n",
      "      replay_time_ms: 779.638\n",
      "      update_priorities_time_ms: 1516.903\n",
      "  iterations_since_restore: 21\n",
      "  node_ip: 10.42.1.113\n",
      "  num_healthy_workers: 31\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 99.95371179039302\n",
      "    ram_util_percent: 29.783745754488113\n",
      "  pid: 2336\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.21962553443907176\n",
      "    mean_env_wait_ms: 3803.22558471809\n",
      "    mean_inference_ms: 7.1020977557967635\n",
      "    mean_raw_obs_processing_ms: 2.363511955009996\n",
      "  time_since_restore: 32847.587918281555\n",
      "  time_this_iter_s: 1450.447536945343\n",
      "  time_total_s: 32847.587918281555\n",
      "  timers:\n",
      "    learner_dequeue_time_ms: 259.91\n",
      "    learner_grad_throughput: 10422.529\n",
      "    learner_grad_time_ms: 276.324\n",
      "    learner_overall_throughput: 5370.307\n",
      "    learner_overall_time_ms: 536.282\n",
      "  timestamp: 1619143741\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 259450\n",
      "  training_iteration: 21\n",
      "  trial_id: 40c8b_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 75.8/251.4 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 32/32 CPUs, 0/0 GPUs, 0.0/15.09 GiB heap, 0.0/5.18 GiB objects<br>Result logdir: /Raytest/Raytest/ray_results/experiment_apex6<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name      </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>APEX_40c8b_00000</td><td>RUNNING </td><td>10.42.1.113:2336</td><td style=\"text-align: right;\">    21</td><td style=\"text-align: right;\">         32847.6</td><td style=\"text-align: right;\">259450</td><td style=\"text-align: right;\">-35041.9</td><td style=\"text-align: right;\">            -28525.1</td><td style=\"text-align: right;\">            -38824.9</td><td style=\"text-align: right;\">              2880</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2289)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2289)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2301)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2289)\u001b[0m [0, -35655.32399999989, -28525.096, -32575.111999999877]\n",
      "\u001b[2m\u001b[36m(pid=2301)\u001b[0m [0, -36976.89600000002, -27287.10000000009, -30140.52799999997]\n",
      "\u001b[2m\u001b[36m(pid=2305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2305)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2305)\u001b[0m [0, -35051.15999999992, -27070.776000000056, -28083.39200000001]\n",
      "\u001b[2m\u001b[36m(pid=2318)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2318)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2318)\u001b[0m [0, -33839.92400000001, -29185.211999999927, -23035.828000000027]\n",
      "\u001b[2m\u001b[36m(pid=2285)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2285)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2285)\u001b[0m [0, -34190.85600000016, -32448.880000000016, -31280.15599999982]\n",
      "\u001b[2m\u001b[36m(pid=2314)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2314)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2296)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2296)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2314)\u001b[0m [0, -33841.65599999999, -32665.016000000123, -24385.17599999997]\n",
      "\u001b[2m\u001b[36m(pid=2296)\u001b[0m [0, -32732.987999999987, -26298.891999999996, -26172.86000000007]\n",
      "\u001b[2m\u001b[36m(pid=2310)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2310)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2310)\u001b[0m [0, -31777.859999999968, -29251.13600000003, -24705.07200000004]\n",
      "\u001b[2m\u001b[36m(pid=2282)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2282)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2282)\u001b[0m [0, -33344.976, -35274.23200000008, -24428.996000000072]\n",
      "\u001b[2m\u001b[36m(pid=2295)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2295)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2300)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2300)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2295)\u001b[0m [0, -32016.084, -33057.147999999856, -25752.163999999942]\n",
      "\u001b[2m\u001b[36m(pid=2300)\u001b[0m [0, -32197.943999999992, -23785.81600000003, -28301.591999999786]\n",
      "\u001b[2m\u001b[36m(pid=2284)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2284)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2284)\u001b[0m [0, -36046.4520000001, -29922.244000000064, -31035.59199999997]\n",
      "\u001b[2m\u001b[36m(pid=2281)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2281)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2281)\u001b[0m [0, -37499.47199999996, -34147.092000000084, -32845.956000000086]\n",
      "\u001b[2m\u001b[36m(pid=2292)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2334)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2292)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2334)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2334)\u001b[0m [0, -36127.58000000004, -33617.015999999945, -30915.83200000012]\n",
      "\u001b[2m\u001b[36m(pid=2292)\u001b[0m [0, -36141.031999999934, -32580.75200000004, -31540.30400000018]\n",
      "\u001b[2m\u001b[36m(pid=2327)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2327)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2327)\u001b[0m [0, -32619.000000000084, -34463.33999999978, -25749.79600000002]\n",
      "\u001b[2m\u001b[36m(pid=2287)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2287)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2287)\u001b[0m [0, -33610.327999999994, -31109.33200000007, -32038.803999999975]\n",
      "\u001b[2m\u001b[36m(pid=2290)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2290)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2290)\u001b[0m [0, -37412.03999999967, -30451.28000000028, -33355.396000000044]\n",
      "\u001b[2m\u001b[36m(pid=2293)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2293)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2293)\u001b[0m [0, -34719.38000000016, -34403.13600000013, -28011.188000000133]\n",
      "\u001b[2m\u001b[36m(pid=2288)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2288)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2308)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2288)\u001b[0m [0, -33656.53600000012, -33633.26800000006, -29113.484000000117]\n",
      "\u001b[2m\u001b[36m(pid=2286)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2286)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2308)\u001b[0m [0, -37665.248000000014, -38091.73999999992, -28403.039999999935]\n",
      "\u001b[2m\u001b[36m(pid=2286)\u001b[0m [0, -35142.13599999992, -33147.20400000004, -32227.836000000014]\n",
      "\u001b[2m\u001b[36m(pid=2298)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2298)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2298)\u001b[0m [0, -32108.683999999947, -34034.59599999983, -26893.15599999991]\n",
      "I am in second callback. Got result: {}\n",
      "Result for APEX_40c8b_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-04-23_02-27-28\n",
      "  done: false\n",
      "  episode_len_mean: 2880.0\n",
      "  episode_reward_max: -28403.039999999935\n",
      "  episode_reward_mean: -34262.54799999999\n",
      "  episode_reward_min: -38824.871999999894\n",
      "  episodes_this_iter: 8\n",
      "  episodes_total: 30\n",
      "  experiment_id: d21118775ed24ec1819dd8ebeb7c9122\n",
      "  hostname: raytest3-644cc68dc4-mcsqh\n",
      "  info:\n",
      "    exploration_infos:\n",
      "    - cur_epsilon: 0.0\n",
      "    - cur_epsilon: 0.4000000059604645\n",
      "    - cur_epsilon: 0.3230035603046417\n",
      "    - cur_epsilon: 0.26082825660705566\n",
      "    - cur_epsilon: 0.21062114834785461\n",
      "    - cur_epsilon: 0.17007845640182495\n",
      "    - cur_epsilon: 0.13733987510204315\n",
      "    - cur_epsilon: 0.11090317368507385\n",
      "    - cur_epsilon: 0.0895553007721901\n",
      "    - cur_epsilon: 0.07231670618057251\n",
      "    - cur_epsilon: 0.058396387845277786\n",
      "    - cur_epsilon: 0.047155603766441345\n",
      "    - cur_epsilon: 0.03807856887578964\n",
      "    - cur_epsilon: 0.03074878640472889\n",
      "    - cur_epsilon: 0.024829918518662453\n",
      "    - cur_epsilon: 0.020050380378961563\n",
      "    - cur_epsilon: 0.01619086228311062\n",
      "    - cur_epsilon: 0.013074264861643314\n",
      "    - cur_epsilon: 0.010557586327195168\n",
      "    - cur_epsilon: 0.008525344543159008\n",
      "    - cur_epsilon: 0.006884292233735323\n",
      "    - cur_epsilon: 0.005559127312153578\n",
      "    - cur_epsilon: 0.00448904512450099\n",
      "    - cur_epsilon: 0.003624943783506751\n",
      "    - cur_epsilon: 0.002927174558863044\n",
      "    - cur_epsilon: 0.0023637195117771626\n",
      "    - cur_epsilon: 0.0019087246619164944\n",
      "    - cur_epsilon: 0.0015413122018799186\n",
      "    - cur_epsilon: 0.0012446233304217458\n",
      "    - cur_epsilon: 0.0010050444398075342\n",
      "    - cur_epsilon: 0.0008115823729895055\n",
      "    - cur_epsilon: 0.0006553599960170686\n",
      "    last_target_update_ts: 121461120\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: 223.4840087890625\n",
      "        mean_q: -54.813785552978516\n",
      "        mean_td_error: -3.9777276515960693\n",
      "        min_q: -148.70504760742188\n",
      "        model: {}\n",
      "    learner_queue:\n",
      "      size_count: 42181\n",
      "      size_mean: 0.22\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 1.0\n",
      "      - 1.0\n",
      "      size_std: 0.4142463035441596\n",
      "    num_steps_sampled: 271000\n",
      "    num_steps_trained: 121481280\n",
      "    num_target_updates: 3834\n",
      "    num_weight_syncs: 666\n",
      "    replay_shard_0:\n",
      "      add_batch_time_ms: 22.83\n",
      "      policy_default_policy:\n",
      "        added_count: 66450\n",
      "        est_size_bytes: 22400000\n",
      "        num_entries: 25000\n",
      "        sampled_count: 30548160\n",
      "      replay_time_ms: 816.347\n",
      "      update_priorities_time_ms: 1560.187\n",
      "  iterations_since_restore: 22\n",
      "  node_ip: 10.42.1.113\n",
      "  num_healthy_workers: 31\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 99.72763659466327\n",
      "    ram_util_percent: 30.064739517153743\n",
      "  pid: 2336\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.22026713653703403\n",
      "    mean_env_wait_ms: 3762.075752185114\n",
      "    mean_inference_ms: 7.060091131386187\n",
      "    mean_raw_obs_processing_ms: 2.380253145989641\n",
      "  time_since_restore: 33954.351353645325\n",
      "  time_this_iter_s: 1106.7634353637695\n",
      "  time_total_s: 33954.351353645325\n",
      "  timers:\n",
      "    learner_dequeue_time_ms: 348.48\n",
      "    learner_grad_throughput: 8301.382\n",
      "    learner_grad_time_ms: 346.93\n",
      "    learner_overall_throughput: 4141.16\n",
      "    learner_overall_time_ms: 695.457\n",
      "  timestamp: 1619144848\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 271000\n",
      "  training_iteration: 22\n",
      "  trial_id: 40c8b_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 74.0/251.4 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 32/32 CPUs, 0/0 GPUs, 0.0/15.09 GiB heap, 0.0/5.18 GiB objects<br>Result logdir: /Raytest/Raytest/ray_results/experiment_apex6<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name      </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>APEX_40c8b_00000</td><td>RUNNING </td><td>10.42.1.113:2336</td><td style=\"text-align: right;\">    22</td><td style=\"text-align: right;\">         33954.4</td><td style=\"text-align: right;\">271000</td><td style=\"text-align: right;\">-34262.5</td><td style=\"text-align: right;\">              -28403</td><td style=\"text-align: right;\">            -38824.9</td><td style=\"text-align: right;\">              2880</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2299)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2299)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2299)\u001b[0m [0, -38824.871999999894, -34052.97199999988, -27636.648000000056]\n",
      "\u001b[2m\u001b[36m(pid=2283)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2283)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2283)\u001b[0m [0, -38095.69200000007, -32515.576000000172, -34104.724000000046]\n",
      "\u001b[2m\u001b[36m(pid=2313)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2313)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2294)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2294)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2313)\u001b[0m [0, -37938.45199999979, -35572.61999999994, -30939.07999999992]\n",
      "\u001b[2m\u001b[36m(pid=2294)\u001b[0m [0, -38233.66800000016, -37915.800000000294, -32352.39600000004]\n",
      "\u001b[2m\u001b[36m(pid=2280)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2280)\u001b[0m Loading configuration ... done.\n",
      "\u001b[2m\u001b[36m(pid=2280)\u001b[0m [0, -36657.05200000004, -33164.32800000009, -36050.3839999998]\n",
      "I am in second callback. Got result: {}\n",
      "Result for APEX_40c8b_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-04-23_02-40-18\n",
      "  done: false\n",
      "  episode_len_mean: 2880.0\n",
      "  episode_reward_max: -27636.648000000056\n",
      "  episode_reward_mean: -33903.1686060606\n",
      "  episode_reward_min: -38824.871999999894\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 33\n",
      "  experiment_id: d21118775ed24ec1819dd8ebeb7c9122\n",
      "  hostname: raytest3-644cc68dc4-mcsqh\n",
      "  info:\n",
      "    exploration_infos:\n",
      "    - cur_epsilon: 0.0\n",
      "    - cur_epsilon: 0.4000000059604645\n",
      "    - cur_epsilon: 0.3230035603046417\n",
      "    - cur_epsilon: 0.26082825660705566\n",
      "    - cur_epsilon: 0.21062114834785461\n",
      "    - cur_epsilon: 0.17007845640182495\n",
      "    - cur_epsilon: 0.13733987510204315\n",
      "    - cur_epsilon: 0.11090317368507385\n",
      "    - cur_epsilon: 0.0895553007721901\n",
      "    - cur_epsilon: 0.07231670618057251\n",
      "    - cur_epsilon: 0.058396387845277786\n",
      "    - cur_epsilon: 0.047155603766441345\n",
      "    - cur_epsilon: 0.03807856887578964\n",
      "    - cur_epsilon: 0.03074878640472889\n",
      "    - cur_epsilon: 0.024829918518662453\n",
      "    - cur_epsilon: 0.020050380378961563\n",
      "    - cur_epsilon: 0.01619086228311062\n",
      "    - cur_epsilon: 0.013074264861643314\n",
      "    - cur_epsilon: 0.010557586327195168\n",
      "    - cur_epsilon: 0.008525344543159008\n",
      "    - cur_epsilon: 0.006884292233735323\n",
      "    - cur_epsilon: 0.005559127312153578\n",
      "    - cur_epsilon: 0.00448904512450099\n",
      "    - cur_epsilon: 0.003624943783506751\n",
      "    - cur_epsilon: 0.002927174558863044\n",
      "    - cur_epsilon: 0.0023637195117771626\n",
      "    - cur_epsilon: 0.0019087246619164944\n",
      "    - cur_epsilon: 0.0015413122018799186\n",
      "    - cur_epsilon: 0.0012446233304217458\n",
      "    - cur_epsilon: 0.0010050444398075342\n",
      "    - cur_epsilon: 0.0008115823729895055\n",
      "    - cur_epsilon: 0.0006553599960170686\n",
      "    last_target_update_ts: 124882560\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: 250.54965209960938\n",
      "        mean_q: -42.065677642822266\n",
      "        mean_td_error: -3.604804754257202\n",
      "        min_q: -147.94558715820312\n",
      "        model: {}\n",
      "    learner_queue:\n",
      "      size_count: 43364\n",
      "      size_mean: 0.16\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 1.0\n",
      "      - 1.0\n",
      "      size_std: 0.36660605559646714\n",
      "    num_steps_sampled: 282550\n",
      "    num_steps_trained: 124885440\n",
      "    num_target_updates: 3942\n",
      "    num_weight_syncs: 693\n",
      "    replay_shard_0:\n",
      "      add_batch_time_ms: 8.773\n",
      "      policy_default_policy:\n",
      "        added_count: 68800\n",
      "        est_size_bytes: 22400000\n",
      "        num_entries: 25000\n",
      "        sampled_count: 31383360\n",
      "      replay_time_ms: 490.512\n",
      "      update_priorities_time_ms: 872.727\n",
      "  iterations_since_restore: 23\n",
      "  node_ip: 10.42.1.113\n",
      "  num_healthy_workers: 31\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 99.97114155251141\n",
      "    ram_util_percent: 29.46885844748858\n",
      "  pid: 2336\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.21864603066745708\n",
      "    mean_env_wait_ms: 3760.5408235508626\n",
      "    mean_inference_ms: 7.0413013164037\n",
      "    mean_raw_obs_processing_ms: 2.372499515200576\n",
      "  time_since_restore: 34724.56109547615\n",
      "  time_this_iter_s: 770.2097418308258\n",
      "  time_total_s: 34724.56109547615\n",
      "  timers:\n",
      "    learner_dequeue_time_ms: 149.75\n",
      "    learner_grad_throughput: 23806.216\n",
      "    learner_grad_time_ms: 120.977\n",
      "    learner_overall_throughput: 10636.249\n",
      "    learner_overall_time_ms: 270.772\n",
      "  timestamp: 1619145618\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 282550\n",
      "  training_iteration: 23\n",
      "  trial_id: 40c8b_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 73.0/251.4 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 32/32 CPUs, 0/0 GPUs, 0.0/15.09 GiB heap, 0.0/5.18 GiB objects<br>Result logdir: /Raytest/Raytest/ray_results/experiment_apex6<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name      </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>APEX_40c8b_00000</td><td>RUNNING </td><td>10.42.1.113:2336</td><td style=\"text-align: right;\">    23</td><td style=\"text-align: right;\">         34724.6</td><td style=\"text-align: right;\">282550</td><td style=\"text-align: right;\">-33903.2</td><td style=\"text-align: right;\">            -27636.6</td><td style=\"text-align: right;\">            -38824.9</td><td style=\"text-align: right;\">              2880</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ray\n",
    "import ray.tune  as tune\n",
    "from ray.tune import Callback\n",
    "from ray.rllib.utils import merge_dicts\n",
    "from ray.rllib.agents.dqn.dqn import calculate_rr_weights, \\\n",
    "    DEFAULT_CONFIG as DQN_CONFIG, DQNTrainer, validate_config\n",
    "# env = gym.make('CartPole-v0')\n",
    "\n",
    "\n",
    "class MyCallback(Callback):\n",
    "    def on_trial_start(self, iteration, trials, trial, **info):\n",
    "        print(f\"I am in callback. This is iteration {iteration} inside trial {trial}\")\n",
    "#         dateTimeObj = datetime.datetime.now()\n",
    "#         dateTimeObj = dateTimeObj.strftime(\"%d-%b-%Y-%H-%M-%S-%f\")\n",
    "#         with open( \"./Raytest/ray_results/\"+dateTimeObj+\".csv\" , 'a', newline='') as csv_file:\n",
    "#                 header = ['rewards', 'throughput','drawback']\n",
    "#                 writer = csv.DictWriter(csv_file, fieldnames = header)\n",
    "#                 writer.writeheader()\n",
    "#         print(info)\n",
    "    def on_trial_result(self, iteration, trials, trial, result, **info):\n",
    "        print(\"I am in second callback. Got result:\", info)\n",
    "#         with open( \"./Raytest/ray_results/\"+str(trial)+\".csv\" , 'a', newline='') as csv_file:\n",
    "#             header = ['rewards']\n",
    "#             writer = csv.DictWriter(csv_file, fieldnames = header)\n",
    "#             writer.writeheader()\n",
    "#             writer.writerow({'rewards': result[\"episode_reward_mean\"]})\n",
    "            \n",
    "\n",
    "def trial_name_id(trial):\n",
    "    return f\"{trial.trainable_name}_{trial.trial_id}\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ray.shutdown()\n",
    "    ray.init(\n",
    "#              object_store_memory=int(1e9),  # 4gb\n",
    "#              redis_max_memory=int(1e9)  #2gb\n",
    "             )\n",
    "    experiment_spec = tune.Experiment(\n",
    "        trial_name_creator=trial_name_id,\n",
    "        name = \"experiment_apex6\",\n",
    "        run = \"APEX\",\n",
    "        local_dir = \"./Raytest/ray_results\",\n",
    "        checkpoint_freq = 3,\n",
    "        checkpoint_at_end = True,\n",
    "        log_to_file=True,\n",
    "        config = {\n",
    "#         \"optimizer\": merge_dicts(\n",
    "#             DQN_CONFIG[\"optimizer\"], {\n",
    "#                 \"max_weight_sync_delay\": 400,\n",
    "#                 \"num_replay_buffer_shards\": 4,\n",
    "#                 \"debug\": False\n",
    "#             }),\n",
    "#         \"n_step\": 3,\n",
    "        \n",
    "            \"adam_epsilon\": 1e-8,\n",
    "            # If not None, clip gradients during optimization at this value\n",
    "            \n",
    "        \"num_gpus\": 0,\n",
    "        \"dueling\": True,\n",
    "        \"double_q\": True,\n",
    "        \"num_workers\": 31,\n",
    "        \"buffer_size\": 100000,\n",
    "        \"framework\": \"tf\",\n",
    "        \"learning_starts\": 28800, #2160\n",
    "        \"train_batch_size\": 2880,\n",
    "#             \"num_samples\": 20,\n",
    "        \"rollout_fragment_length\": 50,\n",
    "        \"target_network_update_freq\": 28800,\n",
    "        \"prioritized_replay\": True,\n",
    "        \"timesteps_per_iteration\":11520, #2880\n",
    "#         \"exploration_config\": {\"type\": \"PerWorkerEpsilonGreedy\"},\n",
    "#         \"worker_side_prioritization\": True,\n",
    "#         \"min_iter_time_s\": 30,\n",
    "        # If set, this will fix the ratio of replayed from a buffer and learned\n",
    "        # on timesteps to sampled from an environment and stored in the replay\n",
    "        # buffer timesteps. Otherwise, replay will proceed as fast as possible.\n",
    "#         \"training_intensity\": None,\n",
    "         \"worker_side_prioritization\": True,\n",
    "         \"lr\": 5e-4,\n",
    "        \"gamma\": 0.9,\n",
    "\n",
    "            \n",
    "            \"env\": MyEnv3 ,\n",
    "\n",
    "            \n",
    "            }\n",
    "        \n",
    "        )\n",
    "    results = tune.run_experiments(experiment_spec, \n",
    "                                  callbacks=[MyCallback()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len([1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
    "       1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1.,\n",
    "       0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
    "       1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
    "       0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "       1., 0., 0., 1., 0., 0.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
