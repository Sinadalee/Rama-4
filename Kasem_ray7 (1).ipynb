{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "junction_id = {'KLONGTEI': 'cluster_1892287670_272491964_272492178',\n",
    "      'RAMA4': 'cluster_272488163_282390730_66263210_66263222',\n",
    "      'NARANONG': 'cluster_272488164_272492179_3457051443_61907354',\n",
    "      'SUNLAKAKHON': 'gneJ83',\n",
    "      'KASEMRAT': 'cluster_272448137_272555800_272555808_7660045934_7710268409',\n",
    "      'ATTHAKAWI_RAMA4' : '270329335'}\n",
    "junction_name = list(junction_id.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gym\n",
    "# from gym import error, spaces\n",
    "import gym\n",
    "import csv\n",
    "import os, sys\n",
    "sys.path.append(os.path.join('/home/ring/sumo-svn/', 'tools'))\n",
    "import traci\n",
    "import traci.constants as tc\n",
    "import numpy as np\n",
    "from sumolib import checkBinary\n",
    "import datetime\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import copy\n",
    "import random\n",
    "import pandas as pd\n",
    "from multiprocessing.pool import ThreadPool\n",
    "from itertools import zip_longest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "namelane_csv = pd.read_csv('namelane_KASEMRAT.csv')\n",
    "namelane_df = pd.DataFrame(namelane_csv, columns = ['name' , 'id'])\n",
    "NAME = namelane_df.set_index('name')\n",
    "ID = namelane_df.set_index('id')\n",
    "if NAME.loc['KASEMRAT_EB_0_0_XSXX','id'] == '459551209#3_0':\n",
    "    print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name\n",
       "KASEMRAT_EB_0_0_XSXX                      459551209#3_0\n",
       "KASEMRAT_EB_0_1_XSXX                      459551209#3_1\n",
       "KASEMRAT_EB_0_2_XSXX                      459551209#3_2\n",
       "KASEMRAT_EB_0_3_XSRT                      459551209#3_3\n",
       "KASEMRAT_EB_1_0_LSXX                      459551209#0_0\n",
       "                                              ...      \n",
       "MASUKGRIDLOCK_ATTHAKAWI_SB_2_1_LXXX        27702347#6_1\n",
       "MASUKGRIDLOCK_ATTHAKAWI_SB_1_0_LSXT        27702347#4_0\n",
       "MASUKGRIDLOCK_ATTHAKAWI_SB_2_0_LXXX        27702347#6_0\n",
       "MASUKGRIDLOCK_SUKHUMVUT22_SB_0_0_XSXX    -453669106#1_0\n",
       "MASUKGRIDLOCK_SUKHUMVUT24_SB_0_0_XSXX     328942767#2_0\n",
       "Name: id, Length: 425, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NAME.loc[:,'id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RAMA4_WB_2_3_XSXX'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ID.loc['820373198#0_3', 'name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "namedetector_csv = pd.read_csv('namedetector_KASEMRAT_flow.csv')\n",
    "namedetector_df = pd.DataFrame(namedetector_csv, columns = ['name' , 'id'])\n",
    "NAME_D = namedetector_df.set_index('name')\n",
    "ID_D = namedetector_df.set_index('id')\n",
    "listdetector = open(\"namedetector_KASEMRAT_flow.txt\", \"r\")\n",
    "detector = {}\n",
    "for l in listdetector:\n",
    "    l = l.strip().split(' ')\n",
    "    if len(l)> 1:\n",
    "        d = []\n",
    "        for detec in l[2:]:\n",
    "            if type(NAME_D.loc[detec,'id']) == str:\n",
    "                d.append(NAME_D.loc[detec,'id'])\n",
    "            else : d.append(NAME_D.loc[detec,'id'][0])\n",
    "    if str(l[0])!= '':\n",
    "        detector[str(l[0])] = d\n",
    "list_detector= list(detector.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RAMA4_EB_1_4_XSXX</th>\n",
       "      <td>D459492917#0_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KLONGTEI_EB_0_0_XSXX</th>\n",
       "      <td>D825786400_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KLONGTEI_EB_0_1_XSXX</th>\n",
       "      <td>D825786400_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KLONGTEI_EB_0_2_XSXX</th>\n",
       "      <td>D825786400_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KLONGTEI_EB_0_3_XSXX</th>\n",
       "      <td>D825786400_3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  id\n",
       "name                                \n",
       "RAMA4_EB_1_4_XSXX     D459492917#0_4\n",
       "KLONGTEI_EB_0_0_XSXX    D825786400_0\n",
       "KLONGTEI_EB_0_1_XSXX    D825786400_1\n",
       "KLONGTEI_EB_0_2_XSXX    D825786400_2\n",
       "KLONGTEI_EB_0_3_XSXX    D825786400_3"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NAME_D.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(NAME_D.loc['KLONGTEI_EB_0_0_XSXX','id'])\n",
    "# for i in range(len(list(detector.keys()))):\n",
    "#     print(i , list(detector.keys())[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hot_encoding_current_phase():\n",
    "    number_phase = [4,9,7,5,4,3]\n",
    "    current_phase = [traci.trafficlight.getPhase(junction_id[key]) for key in junction_id.keys()]\n",
    "#     current_phase = [0,2,1,1,1,1]\n",
    "    hot_encoding_current_phase = np.array([])\n",
    "    for i in range(len(current_phase)):\n",
    "        binary_phase = np.zeros(number_phase[i])\n",
    "        binary_phase[current_phase[i]] = 1\n",
    "        hot_encoding_current_phase = np.concatenate((hot_encoding_current_phase, binary_phase), axis=None)\n",
    "    return current_phase, hot_encoding_current_phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ID.loc['']#, '820373198#0', '820373196#0', '482209831#0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_state_attention(current_phase, hot_encoding_current_phase):\n",
    "#     current_phase = [KLONGTEI phase, RAMA4 phase,NARANONG phase, SUNLAKAKHON phase, KASEMRAT phase, ATTHAKAWI_RAMA4 phase]\n",
    "    MAP_RAMA4 = {0: ['RAMA4_EB_FPX_TP1', 'KASEMRAT_EB_FPX_TP2_RAMA4', 'NARANONG_SW_FPX_TP1'],\n",
    "                 1: ['RAMA4_EB_FP1_TP3', 'RAMA4_NB_FPX_TP5'],\n",
    "                 2: ['RAMA4_WB_FP2_TP4', 'RAMA4_EB_FPX_TP1', 'RAMA4_NB_FPX_TP5'],\n",
    "                3: ['RAMA4_EB_FP3_TP2', 'RAMA4_WB_FP3_TP2', 'RAMA4_EB_FPX_TP1', 'RAMA4_NB_FPX_TP5' ],\n",
    "                4: ['RAMA4_SB_FP4_TP5', 'RAMA4_EB_FPX_TP1', 'RAMA4_NB_FPX_TP5' ],\n",
    "                5: ['RAMA4_NB_FP5_TP1', 'RAMA4_EB_FPX_TP1'],\n",
    "                6: ['KASEMRAT_EB_FPX_TP2_RAMA4'],\n",
    "                7: ['KASEMRAT_EB_FPX_TP2_RAMA4'],\n",
    "                8: ['KASEMRAT_EB_FPX_TP2_RAMA4']}\n",
    "    MAP_KLONGTEI = {0: ['NARANONG_SB_FP5_TP6', 'RAMA4_EB_FP1_TP3'],\n",
    "                    1: ['RAMA4_EB_FP3_TP2', 'RAMA4_EB_FP1_TP3'],\n",
    "                    2: ['KLONGTEI_NB_FP3_TPX'],\n",
    "                   3: ['RAMA4_EB_FP3_TP2',  'RAMA4_EB_FP1_TP3'] }\n",
    "    MAP_NARANONG = {0: ['RAMA4_NB_FPX_TP5'],\n",
    "                1: ['NARANONG_SB_FP1_TP2', 'NARANONG_EB_FP1_TP2', 'NARANONG_WB_FPX_TP2', 'NARANONG_WB_FPX_TP2'],\n",
    "                2: ['NARANONG_WB_FP2_TP3', 'NARANONG_WB_FP2_TP3_FLOW', 'NARANONG_SW_FPX_TP1', 'NARANONG_WB_FPX_TP2'],\n",
    "                3: ['NARANONG_EB_FP3_TP4', 'NARANONG_SW_FPX_TP1', 'NARANONG_WB_FPX_TP2'],\n",
    "                4: ['NARANONG_WB_FP4_TP5', 'NARANONG_SW_FPX_TP1', 'NARANONG_WB_FPX_TP2'],\n",
    "                5: ['NARANONG_SB_FP5_TP6', 'NARANONG_SW_FPX_TP1', 'NARANONG_WB_FPX_TP2'], \n",
    "                6: ['NARANONG_NB_FP6_TP1', 'NARANONG_SW_FPX_TP1', 'NARANONG_WB_FPX_TP2'] }\n",
    "    MAP_SUNLAKAKHON = {0: ['NARANONG_EB_FP3_TP4'],\n",
    "                    1: ['SUNLAKAKHON_SB_FP1_TPX'],\n",
    "                    2: ['SUNLAKAKHON_NB_FP2_TP3', 'SUNLAKAKHON_SB_FPX_TP1'],\n",
    "                    3:['SUNLAKAKHON_EB_FP3_TP4', 'SUNLAKAKHON_WB_FP3_TP4', 'SUNLAKAKHON_SB_FPX_TP1'],\n",
    "                    4:['SUNLAKAKHON_SB_FP4_TP1', 'SUNLAKAKHON_SB_FPX_TP1'] }\n",
    "    MAP_KASEMRAT = {0: ['SUNLAKAKHON_SB_FPX_TP1', 'MASUKGRIDLOCK_ARI_NB_FPX_TP2'],\n",
    "                    1:['KASEMRAT_EB_FPX_TP2', 'KASEMRAT_NB_FPX_TP3'],\n",
    "                    2:['KASEMRAT_EB_FP2_TP1', 'KASEMRAT_NB_FPX_TP3'],\n",
    "                    3:['KASEMRAT_EB_FPX_TP2'] }\n",
    "    MAP_ATTHAKAWI_RAMA4 = {0: ['KASEMRAT_EB_FPX_TP2'],\n",
    "                           1: ['MASUKGRIDLOCK_SUKHUMVUT_FPX_TP2', 'MASUKGRIDLOCK_ARI_NB_FPX_TP2' ],\n",
    "                          2:['KASEMRAT_EB_FPX_TP2_RAMA4']}\n",
    "    MAP = [MAP_KLONGTEI, MAP_RAMA4, MAP_NARANONG, MAP_SUNLAKAKHON,  MAP_KASEMRAT, MAP_ATTHAKAWI_RAMA4]\n",
    "    state_attention = np.zeros(31)\n",
    "    for i in range(len(current_phase)):\n",
    "        for e in MAP[i][current_phase[i]]:\n",
    "            occupancy = get_occupancy_average_percent(detector[e]) \n",
    "            Index_detector = list_detector.index(e) \n",
    "            state_attention[Index_detector] = occupancy\n",
    "#     print(state_attention)\n",
    "    state = np.concatenate((state_attention, hot_encoding_current_phase), axis=None)\n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reset the environment\n",
    "def start():\n",
    "    sumoBinary = checkBinary('sumo')\n",
    "    traci.start([sumoBinary, \"-c\", \"KASEMRAT-SUMO-UsingBookNetFile/osm.sumocfg\",\n",
    "                             \"--tripinfo-output\", \"tripinfo.xml\", '--start','true','--quit-on-end','true','--time-to-teleport','-1',\n",
    "                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_occupancy_average_percent(detector_id): \n",
    "    #get occupancy average for all detector in list of detector_id and scale by (Vehicle Length + MinimumGap)/MinimumGap \n",
    "    #Vehicle Length = 4.62 MinimumGap = 2.37\n",
    "    occupancy = (sum([traci.lanearea.getLastStepOccupancy(e) for e in detector_id])/len(detector_id))*((4.62+2.37)/4.62)\n",
    "    return occupancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_throughput():\n",
    "    loopID = traci.inductionloop.getIDList()\n",
    "    throughput = sum([traci.inductionloop.getLastStepVehicleNumber(i) for i in loopID])  #if traci.inductionloop.getLastStepMeanSpeed(i) > 0\n",
    "    return throughput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_backlog():\n",
    "#     laneID = traci.lane.getIDList()\n",
    "    backlog = sum([traci.lanearea.getLastStepVehicleNumber(i) for i in NAME.loc[:,'id']])\n",
    "    return backlog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reward():\n",
    "    throughput = 0\n",
    "    for i in range(5):\n",
    "        traci.simulationStep()\n",
    "        throughput += get_throughput()\n",
    "    \n",
    "    backlog = get_backlog()\n",
    "    reward = throughput - 0.004*backlog\n",
    "    return reward, throughput, backlog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_phase = [4,9,7,5,4,3]\n",
    "def set_current_phase(action, current_phase):\n",
    "    if action < 4:\n",
    "        phase = action\n",
    "        current_phase[0] = phase\n",
    "    elif action < 13:\n",
    "        phase = (action-4)\n",
    "        current_phase[1] = phase\n",
    "    elif action < 20:\n",
    "        phase = (action-13)\n",
    "        current_phase[2] = phase\n",
    "    elif action < 25:\n",
    "        phase = (action-20)\n",
    "        current_phase[3] = phase\n",
    "    elif action < 29:\n",
    "        phase = (action-25)\n",
    "        current_phase[4] = phase\n",
    "    else:\n",
    "        phase = (action-29)\n",
    "        current_phase[5] = phase\n",
    "    for i in range (6):\n",
    "        traci.trafficlight.setPhase(junction_id[junction_name[i]], current_phase[i])\n",
    "    if current_phase[5] == 2:\n",
    "        traci.lane.setAllowed(NAME.loc['MASUKGRIDLOCK_ATTHAKAWI_SB_1_0_LSXT', 'id'], ['passenger'])\n",
    "        traci.lane.setAllowed(NAME.loc['MASUKGRIDLOCK_ATTHAKAWI_SB_2_0_LXXX', 'id'], ['passenger'])\n",
    "        traci.lane.setAllowed(NAME.loc['MASUKGRIDLOCK_ATTHAKAWI_SB_0_0_XSRT', 'id'], ['passenger'])\n",
    "    elif current_phase[5] == 1:\n",
    "        traci.lane.setDisallowed(NAME.loc['MASUKGRIDLOCK_ATTHAKAWI_SB_1_0_LSXT', 'id'], ['passenger'])\n",
    "        traci.lane.setDisallowed(NAME.loc['MASUKGRIDLOCK_ATTHAKAWI_SB_2_0_LXXX', 'id'], ['passenger'])\n",
    "        traci.lane.setDisallowed(NAME.loc['MASUKGRIDLOCK_ATTHAKAWI_SB_0_0_XSRT', 'id'], ['passenger'])\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2021-04-0621:13:35.521287'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(str(datetime.datetime.now()).split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_memory = []\n",
    "def plot_durations():\n",
    "    print('show')\n",
    "    plt.figure(2)\n",
    "    plt.clf()\n",
    "    durations_t = torch.tensor(reward_memory, dtype=torch.float)\n",
    "    plt.title('Training...')\n",
    "    plt.xlabel('Step')\n",
    "    plt.ylabel('Reward')\n",
    "    plt.plot(durations_t.numpy())\n",
    "    # Take 100 episode averages and plot them too\n",
    "    if len(durations_t) >= 100:\n",
    "        means = durations_t.unfold(0, 100, 1).mean(1).view(-1)\n",
    "        means = torch.cat((torch.zeros(99), means))\n",
    "        plt.plot(means.numpy())\n",
    "\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyEnv3(gym.Env):\n",
    "    def __init__(self, env_config):\n",
    "        self.count = 0\n",
    "        self.reward = 0\n",
    "        self.rewards = 0\n",
    "        self.throughputs = 0\n",
    "        self.backlogs = 0\n",
    "        self.current_phase = [1,1,1,1,1,1]\n",
    "        self.done = False\n",
    "        self.reward_memory = []\n",
    "        self.action_space = gym.spaces.Discrete(32)\n",
    "        self.observation_space = gym.spaces.Box(low=-1, high=200, shape=(63,), dtype=np.float16)\n",
    "        dateTimeObj = datetime.datetime.now()\n",
    "        self.dateTimeObj = dateTimeObj.strftime(\"%d-%b-%Y-%H-%M-%S\")\n",
    "        with open( \"./Raytest/ray_results/\"+self.dateTimeObj+\".csv\" , 'a', newline='') as csv_file:\n",
    "                header = ['rewards', 'throughput','backlog']\n",
    "                writer = csv.DictWriter(csv_file, fieldnames = header)\n",
    "                writer.writeheader()\n",
    "        \n",
    "    def reset(self):\n",
    "        \n",
    "        self.reward_memory.append(self.rewards)\n",
    "        self.count = 0\n",
    "        start()\n",
    "        self.reward = 0\n",
    "        self.rewards = 0\n",
    "        self.throughputs = 0\n",
    "        self.backlogs = 0\n",
    "        print(self.reward_memory)\n",
    "        current_phase, hot_encoding_current_phase = get_hot_encoding_current_phase()\n",
    "        state = get_state_attention(current_phase, hot_encoding_current_phase)\n",
    "#         print(state)\n",
    "        self.done = False\n",
    "        self.current_phase = current_phase\n",
    "        if len(self.reward_memory)%100 == 0:\n",
    "            print('memory',self.reward_memory[-10:])\n",
    "        return state \n",
    "    \n",
    "    \n",
    "    def step(self, action):\n",
    "        set_current_phase(action, self.current_phase)\n",
    "#         print(action)\n",
    "        current_phase, hot_encoding_current_phase = get_hot_encoding_current_phase()\n",
    "        self.reward, throughput, backlog= get_reward()\n",
    "        self.rewards += self.reward\n",
    "        self.throughputs += throughput\n",
    "        self.backlogs += backlog\n",
    "        state = get_state_attention(current_phase, hot_encoding_current_phase)\n",
    "        if np.isnan(self.reward) == True:\n",
    "            print('HELP', type(self.reward))\n",
    "        self.count += 1\n",
    "        self.current_phase = current_phase\n",
    "#         print('count', self.count)\n",
    "        self.done = False\n",
    "        if self.count >= 2880: #2880\n",
    "            traci.close()\n",
    "            self.done = True\n",
    "            with open( \"Raytest/ray_results/\"+self.dateTimeObj+\".csv\" , 'a', newline='') as csv_file:\n",
    "                header = ['rewards', 'throughput','backlog']\n",
    "                writer = csv.DictWriter(csv_file, fieldnames = header)\n",
    "                writer.writerow({'rewards': self.rewards, \n",
    "                                 'throughput': self.throughputs,\n",
    "                                'backlog': self.backlogs})\n",
    "\n",
    "        \n",
    "        return_state = np.array(state).astype(np.float16)\n",
    "#         print(return_state)\n",
    "        info = {\"throughput\": throughput,\n",
    "                \"backlog\":backlog\n",
    "                }\n",
    "        info = {**info}\n",
    "#         print(info)\n",
    "        return return_state , self.reward, self.done, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asd\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(\"asd\")\n",
    "    env = MyEnv3(env_config=None)\n",
    "\n",
    "    for i_episode in range(1):\n",
    "        observation = env.reset()\n",
    "        for t in range(3000):\n",
    "            # env.render()\n",
    "#             print(observation)\n",
    "            action = env.action_space.sample()\n",
    "            # print('action' ,action)\n",
    "            observation, reward, done, info = env.step(action)\n",
    "            if done:\n",
    "                print(\"Episode finished after {} timesteps\")\n",
    "                break\n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == \"__main__\":\n",
    "#     print(\"asd\")\n",
    "#     env = MyEnv3(env_config=None)\n",
    "\n",
    "#     for i_episode in range(1):\n",
    "#         observation = env.reset()\n",
    "#         for t in range(1000):\n",
    "#             # env.render()\n",
    "# #             print(observation)\n",
    "#             action = env.action_space.sample()\n",
    "# #             print('action' ,action)\n",
    "#             observation, reward, done, info = env.step(action)\n",
    "#             if done:\n",
    "#                 print(\"Episode finished after {} timesteps\")\n",
    "#                 break\n",
    "#     env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# traci.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sinad\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-06 21:24:35,420\tINFO services.py:1172 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n"
     ]
    },
    {
     "ename": "TuneError",
     "evalue": "Insufficient cluster resources to launch trial: trial requested 16 CPUs, 0 GPUs, but the cluster has only 8 CPUs, 0 GPUs, 1.81 GiB heap, 0.59 GiB objects (1.0 node:192.168.1.123). \n\nYou can adjust the resource requests of RLlib agents by setting `num_workers`, `num_gpus`, and other configs. See the DEFAULT_CONFIG defined by each agent for more info.\n\nThe config of this agent is: {'adam_epsilon': 1e-08, 'num_gpus': 0, 'dueling': False, 'double_q': False, 'num_workers': 15, 'buffer_size': 100000, 'framework': 'tf', 'learning_starts': 28800, 'train_batch_size': 540, 'rollout_fragment_length': 50, 'target_network_update_freq': 540, 'prioritized_replay': True, 'timesteps_per_iteration': 2880, 'worker_side_prioritization': False, 'lr': 0.0005, 'gamma': 0.7, 'env': <class '__main__.MyEnv3'>} ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTuneError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-9dd4695a98d2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m         )\n\u001b[1;32m---> 89\u001b[1;33m     results = tune.run_experiments(experiment_spec, \n\u001b[0m\u001b[0;32m     90\u001b[0m                                   callbacks=[MyCallback()])\n",
      "\u001b[1;32mc:\\users\\sinad\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\ray\\tune\\tune.py\u001b[0m in \u001b[0;36mrun_experiments\u001b[1;34m(experiments, scheduler, server_port, verbose, progress_reporter, resume, queue_trials, reuse_actors, trial_executor, raise_on_failed_trial, concurrent, callbacks)\u001b[0m\n\u001b[0;32m    490\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mconcurrent\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 492\u001b[1;33m         return run(\n\u001b[0m\u001b[0;32m    493\u001b[0m             \u001b[0mexperiments\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    494\u001b[0m             \u001b[0mserver_port\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mserver_port\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sinad\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\ray\\tune\\tune.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(run_or_experiment, name, metric, mode, stop, time_budget_s, config, resources_per_trial, num_samples, local_dir, search_alg, scheduler, keep_checkpoints_num, checkpoint_score_attr, checkpoint_freq, checkpoint_at_end, verbose, progress_reporter, log_to_file, trial_name_creator, trial_dirname_creator, sync_config, export_formats, max_failures, fail_fast, restore, server_port, resume, queue_trials, reuse_actors, trial_executor, raise_on_failed_trial, callbacks, loggers, ray_auto_init, run_errored_only, global_checkpoint_period, with_server, upload_dir, sync_to_cloud, sync_to_driver, sync_on_checkpoint)\u001b[0m\n\u001b[0;32m    419\u001b[0m     \u001b[0mtune_start\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    420\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mrunner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_finished\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 421\u001b[1;33m         \u001b[0mrunner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    422\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhas_verbosity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mVerbosity\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mV1_EXPERIMENT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    423\u001b[0m             \u001b[0m_report_progress\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrunner\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprogress_reporter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sinad\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\ray\\tune\\trial_runner.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    402\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_events\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# blocking\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    403\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 404\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrial_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_no_available_trials\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    405\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    406\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stop_experiment_if_needed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sinad\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\ray\\tune\\trial_executor.py\u001b[0m in \u001b[0;36mon_no_available_trials\u001b[1;34m(self, trial_runner)\u001b[0m\n\u001b[0;32m    183\u001b[0m                             \u001b[1;34m\"cluster scales up or resources become available. \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m                         )\n\u001b[1;32m--> 185\u001b[1;33m                     raise TuneError(\n\u001b[0m\u001b[0;32m    186\u001b[0m                         \u001b[1;34m\"Insufficient cluster resources to launch trial: \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m                         \u001b[1;34mf\"trial requested {resource_string}, but the cluster \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTuneError\u001b[0m: Insufficient cluster resources to launch trial: trial requested 16 CPUs, 0 GPUs, but the cluster has only 8 CPUs, 0 GPUs, 1.81 GiB heap, 0.59 GiB objects (1.0 node:192.168.1.123). \n\nYou can adjust the resource requests of RLlib agents by setting `num_workers`, `num_gpus`, and other configs. See the DEFAULT_CONFIG defined by each agent for more info.\n\nThe config of this agent is: {'adam_epsilon': 1e-08, 'num_gpus': 0, 'dueling': False, 'double_q': False, 'num_workers': 15, 'buffer_size': 100000, 'framework': 'tf', 'learning_starts': 28800, 'train_batch_size': 540, 'rollout_fragment_length': 50, 'target_network_update_freq': 540, 'prioritized_replay': True, 'timesteps_per_iteration': 2880, 'worker_side_prioritization': False, 'lr': 0.0005, 'gamma': 0.7, 'env': <class '__main__.MyEnv3'>} "
     ]
    }
   ],
   "source": [
    "import ray\n",
    "import ray.tune  as tune\n",
    "from ray.tune import Callback\n",
    "from ray.rllib.utils import merge_dicts\n",
    "from ray.rllib.agents.dqn.dqn import calculate_rr_weights, \\\n",
    "    DEFAULT_CONFIG as DQN_CONFIG, DQNTrainer, validate_config\n",
    "# env = gym.make('CartPole-v0')\n",
    "\n",
    "\n",
    "class MyCallback(Callback):\n",
    "    def on_trial_start(self, iteration, trials, trial, **info):\n",
    "        print(f\"I am in callback. This is iteration {iteration} inside trial {trial}\")\n",
    "#         dateTimeObj = datetime.datetime.now()\n",
    "#         dateTimeObj = dateTimeObj.strftime(\"%d-%b-%Y-%H-%M-%S-%f\")\n",
    "#         with open( \"./Raytest/ray_results/\"+dateTimeObj+\".csv\" , 'a', newline='') as csv_file:\n",
    "#                 header = ['rewards', 'throughput','backlog']\n",
    "#                 writer = csv.DictWriter(csv_file, fieldnames = header)\n",
    "#                 writer.writeheader()\n",
    "#         print(info)\n",
    "    def on_trial_result(self, iteration, trials, trial, result, **info):\n",
    "        print(\"I am in second callback. Got result:\", info)\n",
    "#         with open( \"./Raytest/ray_results/\"+str(trial)+\".csv\" , 'a', newline='') as csv_file:\n",
    "#             header = ['rewards']\n",
    "#             writer = csv.DictWriter(csv_file, fieldnames = header)\n",
    "#             writer.writeheader()\n",
    "#             writer.writerow({'rewards': result[\"episode_reward_mean\"]})\n",
    "            \n",
    "\n",
    "def trial_name_id(trial):\n",
    "    return f\"{trial.trainable_name}_{trial.trial_id}\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ray.shutdown()\n",
    "    ray.init(\n",
    "#              object_store_memory=int(1e9),  # 4gb\n",
    "#              redis_max_memory=int(1e9)  #2gb\n",
    "             )\n",
    "    experiment_spec = tune.Experiment(\n",
    "        trial_name_creator=trial_name_id,\n",
    "        name = \"experiment_apex6\",\n",
    "        run = \"APEX\",\n",
    "        local_dir = \"./Raytest/ray_results\",\n",
    "        checkpoint_freq = 3,\n",
    "        checkpoint_at_end = True,\n",
    "        log_to_file=True,\n",
    "        config = {\n",
    "#         \"optimizer\": merge_dicts(\n",
    "#             DQN_CONFIG[\"optimizer\"], {\n",
    "#                 \"max_weight_sync_delay\": 400,\n",
    "#                 \"num_replay_buffer_shards\": 4,\n",
    "#                 \"debug\": False\n",
    "#             }),\n",
    "#         \"n_step\": 3,\n",
    "        \n",
    "            \"adam_epsilon\": 1e-8,\n",
    "            # If not None, clip gradients during optimization at this value\n",
    "            \n",
    "        \"num_gpus\": 0,\n",
    "        \"dueling\": False,\n",
    "        \"double_q\": False,\n",
    "        \"num_workers\": 15,\n",
    "        \"buffer_size\": 100000,\n",
    "        \"framework\": \"tf\",\n",
    "        \"learning_starts\": 28800, #2160\n",
    "        \"train_batch_size\": 540,\n",
    "#             \"num_samples\": 20,\n",
    "        \"rollout_fragment_length\": 50,\n",
    "        \"target_network_update_freq\": 540,\n",
    "        \"prioritized_replay\": True,\n",
    "        \"timesteps_per_iteration\": 2880, #2880\n",
    "#         \"exploration_config\": {\"type\": \"PerWorkerEpsilonGreedy\"},\n",
    "#         \"worker_side_prioritization\": True,\n",
    "#         \"min_iter_time_s\": 30,\n",
    "        # If set, this will fix the ratio of replayed from a buffer and learned\n",
    "        # on timesteps to sampled from an environment and stored in the replay\n",
    "        # buffer timesteps. Otherwise, replay will proceed as fast as possible.\n",
    "#         \"training_intensity\": None,\n",
    "         \"worker_side_prioritization\": False,\n",
    "         \"lr\": 5e-4,\n",
    "            \"gamma\": 0.7,\n",
    "\n",
    "            \n",
    "            \"env\": MyEnv3 ,\n",
    "\n",
    "            \n",
    "            }\n",
    "        \n",
    "        )\n",
    "    results = tune.run_experiments(experiment_spec, \n",
    "                                  callbacks=[MyCallback()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
    "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
    "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 7.80548386e-311,\n",
    "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
    "       0.00000000e+000, 0.00000000e+000, 7.80548386e-311, 0.00000000e+000,\n",
    "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
    "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
    "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
    "       0.00000000e+000, 1.00000000e+000, 0.00000000e+000, 1.00000000e+000,\n",
    "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
    "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
    "       0.00000000e+000, 1.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
    "       0.00000000e+000, 0.00000000e+000, 1.00000000e+000, 0.00000000e+000,\n",
    "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
    "       0.00000000e+000, 1.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
    "       0.00000000e+000, 1.00000000e+000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
    "       0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "       1., 0., 0., 1., 0., 0.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
